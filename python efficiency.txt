efficient
1. fast
2. allocates resources efficiently

python focus on readability
pythonic code uses best principles and less verbose

pythons design philosophy
The Zen of Python
1. beautiful is better than ugly
2. explicit is better than implicit
3. simple is better than complex
4. complex is better than complicated
5. flat is better than nested
6. sparse is better than dense
7. reability counts
8. special cases arn't spect enough to break rules
9. although practicality beats purity
10. errors should never pass silently
11. unless explicity silenced
12. in the face of ambiquity, refuse the temptation to guess

# Print the list created by using list comprehension
best_list = [name for name in names if len(name) >= 6]
print(best_list)

PEP: Python Enhancement Proposals

Python has a design philosophy that emphasizes readability


>>>>>>>>>>>>Building with built-ins

the python standard library is part of every standard installation

list, tuple, set, dict

print(), len(), range(), round(), enumerate(), map(), zip()

>>>>>>range

nums=range(0,11)  #up to 11 but not including 11
nums_list=list(nums)

even_nums=range(2,11,2)
even_nums_list=list(even_nums)

>>>>>>>>enumerate

letters=['a','b','c','d']

indexed_letters=enumerate(letters)

index_letters_list=list(indexed_letters)

creates a sequnce of indexed values.

indexed_letters=enumerate(letters, start=5)

#the index will start with the value 5

>>>>>> map

#map applies a function to each element in a list

nums=[1.5, 2.3, 3.4, 4.6, 5.0]

rnd_nums=map(round,nums)

print(list(rnd_nums))

#map can be used with a lambda function

sqrd_nums = map(lamda x: x**2, nums)

print(list(sqrd_nums))


>>>> sample >>> range  >> odd numbers


# Create a range object that goes from 0 to 5
nums = range(5)
print(type(nums))

# Convert nums to a list
nums_list = list(nums)
print(nums_list)

# Create a new list of odd numbers from 1 to 11 by unpacking a range object
nums_list2 = [*range(1,12,2)]
print(nums_list2)

[0, 1, 2, 3, 4]
[1, 3, 5, 7, 9]

>>>> sample >>> enumerate >>> unpack and enumeration

# Rewrite the for loop to use enumerate
indexed_names = []
for i,name in enumerate(names):
    index_name = (i,name)
    indexed_names.append(index_name) 
print(indexed_names)

# Rewrite the above for loop using list comprehension
indexed_names_comp = [(i,name) for i,name in enumerate(names)]
print(indexed_names_comp)

# Unpack an enumerate object with a starting index of one
indexed_names_unpack = [*enumerate(names, start=1)]
print(indexed_names_unpack)

>>>>>>>sample  >>>> map results in a packed object that must be unpacked like enumerate must be unpacked


# Use map to apply str.upper to each element in names
names_map  = map(str.upper, names)

print(names_map)
# Print the type of the names_map
print(type(names_map))

# Unpack names_map into a list
names_uppercase = [*names_map]

# Print the list created above
print(names_uppercase)


>>>>>>>>>>>The power of Numpy arrays

import numppy as np

nums_np_ints=np.array([1,2.5,3])

nums_np_ints.dtype

numpy arrays are more efficient than numpy lists

nums=[-2,-1,0,1,2]
nums**2

#numpy vectorize operations

nums_np = np.array([-2,-1,0,1,2])

nums_np **2

<<<<<2d arrays

nums2=[[1,2,3],
	[4,5,6]]

num2[0][1]
[row[0] for row in nums2]

pos=[num for num in nums if num>0]

<<<array

nums2_np=np.array(num2)

nums2_np[0,1]

nums2_np[:,0]

#filtering using an array

mask=nums_np>0

nums_np[mask]

>>>>>> sample >>> slicing arrays

# Print second row of nums
print(nums[1,:])

# Print all elements of nums that are greater than six
print(nums[nums > 6])

# Double every element of nums
nums_dbl = nums * 2
print(nums_dbl)

# Replace the third column of nums
nums[:,2] = nums[:,2] + 1
print(nums)

>>>> sample >>> unpack an range into a list

# Create a list of arrival times
arrival_times = [*range(10, 60, 10)]
print(arrival_times)

# Convert arrival_times to an array and update the times
arrival_times_np = np.array(arrival_times)
new_times = arrival_times_np - 3.0

print(new_times)

>>>>>>>>> sample >>> use an enumerate to create and indexed tuple >>> use the index as a lookup

# Create a list of arrival times
arrival_times = [*range(10,60,10)]

# Convert arrival_times to an array and update the times
arrival_times_np = np.array(arrival_times)
new_times = arrival_times_np - 3

# Use list comprehension and enumerate to pair guests to new times
guest_arrivals = [(names[index],time) for index,time in enumerate(new_times)]

print(guest_arrivals)


# Map the welcome_guest function to each (guest,time) pair
welcome_map = map(welcome_guest, guest_arrivals)

guest_welcomes = [*welcome_map]
print(*guest_welcomes, sep='\n')

>>>>>>>>>>>>>>>>Run time

picking code with optimal efficiency

%timeit

%lsmagic

import numpy as np

%timeit rand_nums = np.random.rand(1000)

#setting the number of runs -r and/or loops -n

%timeit -r2 -n10 rand_nums = np.random.rand(1000)

#apply timing to a code block
%%timeit
	for i in range(10):
		print(i)

times=%timeit -o rand_nums = np.random.rand(1000)

times.timings
times.best
times.worst

formal_list=list()
formal_dict=dict()
formal_tuple=tuple()

or

literal_list=[]
literal_dict={}
literal_tuple=()

f_time=%timeit -o formal_dict=dict()
l_time=%timeit -o literal_dict={}

diff=(f_time.average - l_time.average) *(10**9)

print('l_time better then f_time by {} ns'.format(diff))

ns	nanosecond	10-9
µs (us)	microsecond	10-6
ms	millisecond	10-3
s	second	100

>>>>> sample

time1=%timeit -o nums_list_comp = [num for num in range(51)]
print(nums_list_comp)
 
# Create a list of integers (0-50) by unpacking range
time2=%timeit -o nums_unpack = [*range(51)]
print(nums_unpack)

diff=(time1.average - time2.average) *(10**9)

print('time1 vs time2 {} ns'.format(diff))


>>>>>>timing a large code base through code profiling

1. detailed stats on frequency and duration of function calls

2. line by line analyses

3. package line_profiler
pip install line_profiler
conda install -c anaconda line_profilery



heros=['batman','superman','wonder woman']
hts=np.array([188.0,191.0,183.0])
wts=np.array([95.0,101.0,74.0])

def convert_units(heros, heights, weights):
	new_hts=[ht*0.39370 for ht in heights]
	new_wts=[wt*2.20462 for wt in weights]
	
	hero_data={}

	for i, hero in enumerate(heros):
		hero_data[hero]=(new_hts[i],new_wts[i])

	return hero_data

convert_units(heros,hts, wts)

>>>>>>>>>>>>>>load line profiler into the session

%load_ext line_profiler
%lprun -f convert_units convert_units(heros,hts, wts)

-f profile a function
and then the exact function we want to call


generates a table of the statistics


>>>>>>>>>>>code profiling for memory usage

import sys

num_list = [*range(1000)]
sys.getsizeof(nums_list)

conda install -c anaconda memory_profiler


>>>>>>>>>>>>>>using memory profiler

%reload_ext memory_profiler

%mprun -f convert_units convert_units(heros, hts, wts)

functions must be imported when using memory_profilerin physical files



%load_ext memory_profiler

%mprun -f convert_units convert_units(heroes,hts, wts)



>>>sample  >>> using the memory profiler


Use the command from hero_funcs import convert_units to load the function you'd like to profile.
press
1

Use %load_ext memory_profiler to load the memory_profiler within your IPython session.
press
2

Use %mprun -f convert_units convert_units(heroes, hts, wts) to get line-by-line memory allocations. 


>>>>>sample  running the memory profiler
%load_ext memory_profiler

%mprun -f calc_bmi_lists calc_bmi_lists(sample_indices, hts, wts):

# Use get_publisher_heroes() to gather Star Wars heroes
star_wars_heroes = get_publisher_heroes(heroes, publishers, 'George Lucas')

print(star_wars_heroes)
print(type(star_wars_heroes))

# Use get_publisher_heroes_np() to gather Star Wars heroes
star_wars_heroes_np = get_publisher_heroes_np(heroes, publishers, 'George Lucas')

print(star_wars_heroes_np)
print(type(star_wars_heroes_np))


>>>>>>>>>>>>Combining, counting, and iterating

combining objects

names=['a','b','c']
hps=[45,39,41]

combined_zip=zip(names,hps)

('a', 45) ('b', 39) ('c', 41)

>>>>>>>>collection module

1. namedTuple
2. deque
3. Counter
4. OrderedDict
defaultDict


>>>>>>Counter

from collections import Counter
types_counts=Counter(poke_types)

mylist=['a','a','a','b','b','c']
types_counts=Counter(mylist)
print(types_counts)

>>>>>>>>>>>>>>itertools
1. count
2. cycle
3. repeat
4. accumulate
5. chain
6. zip_longest

combination generators: product, permutations, combinations

fruit_types=['apple','banana', 'orange','pear']

from itertools import combinations
combos_obj=combinations(fruit_types,2)


>>>>> sample >>> zip two lists together

# Combine all three lists together
names_types = [*zip(names,primary_types,secondary_types)]

print(*names_types[:5], sep='\n')


>>>> sample >>>> counter

# Collect the count of primary types
type_count = Counter(primary_types)
print(type_count, '\n')

# Collect the count of generations
gen_count = Counter(generations)
print(gen_count, '\n')


>>>>>> sample >>>> iterative tools >>> find all combinations

 # Import combinations from itertools
from itertools import combinations

# Create a combination object with pairs of Pokémon
combos_obj = combinations(pokemon, 2)
print(type(combos_obj), '\n')

# Convert combos_obj to a list by unpacking
combos_2 = [*combos_obj]
print(combos_2, '\n')

# Collect all possible combinations of 4 Pokémon directly into a list
combos_4 = [*combinations(pokemon,4)]
print(combos_4)

# Use list comprehension to get each Pokémon's starting letter
starting_letters = [name[0] for name in names]

# Collect the count of Pokémon for each starting_letter
starting_letters_count = Counter(starting_letters)
print(starting_letters_count)


>>>>>>>>>>>>>> SET theory

set theory is used to compare two objects for similarities or differences


sets:
1. intersection
2. difference
3. symmetric_difference
4. union

list_a=['apple','orange', 'kiwi', 'watermelon']
list_b=['banana', 'orange', 'apple','cantelope']


set_a=set(list_a)
set_b=set(list_b)

result=set_a.intersection(set_b)

diff=set_a.difference(set_b)

#exists in one of the sets but not both (compliment union combination)

set_a.symmetric_difference(set_b)

#unique combinations

set_a.union(set_b)

finding a member is faster for sets

"orange" in results

set lists are unique

set(list) creates a list of unique values

>>>>> sample >>> sets

# Convert both lists to sets
ash_set = set(ash_pokedex)
misty_set = set(misty_pokedex)

# Find the Pokémon that exist in both sets
both = ash_set.intersection(misty_set)
print(both)

# Find the Pokémon that Ash has and Misty does not have
ash_only = ash_set.difference(misty_set)
print(ash_only)

# Find the Pokémon that are in only one set (not both)
unique_to_set = ash_set.symmetric_difference(misty_set)
print(unique_to_set)


>>>> sample >>> unique names

uniq_names_func = set(names)
print(len(uniq_names_func))


>>>>> sample >>> test unique names

# Use find_unique_items() to collect unique Pokémon names
uniq_names_func = find_unique_items(names)
print(len(uniq_names_func))

# Convert the names list to a set to collect unique Pokémon names
uniq_names_set = set(names)
print(len(uniq_names_set))

# Check that both unique collections are equivalent
print(sorted(uniq_names_func) == sorted(uniq_names_set))

>>>>>> sample  >>> set efficiency

# Use find_unique_items() to collect unique Pokémon names
uniq_names_func = find_unique_items(names)
print(len(uniq_names_func))

# Convert the names list to a set to collect unique Pokémon names
uniq_names_set = set(names)
print(len(uniq_names_set))

# Check that both unique collections are equivalent
print(sorted(uniq_names_func) == sorted(uniq_names_set))

# Use the best approach to collect unique primary types and generations
uniq_types = set(primary_types)
uniq_gens = set(generations)
print(uniq_types, uniq_gens, sep='\n') 


>>>>>>>>eliminating loops

Looping patterns
1. for
2. while - repeated while a condition is met
3. nested

avoid looping as much as possible when writing efficient code

idom: flat is better than nested


stats=[
    [90,92,75,60],
    [25,20,15,90],
    [65,130,60,75]
]
#list comprehension
totals=[sum(row) for row in stats]
print(totals)
#map
totals=[*map(sum,stats)]
print(totals)
print('equivalent results')

#numpy allow operations to be applied to entire arrays all at once

myarray=np.array(stats)
avgs=myarray.mean(axis=1)
print(avgs)
totals=myarray.sum(axis=1)
print(totals)


>>>>>>>>> sample  zip and map

# Collect Pokémon that belong to generation 1 or generation 2
gen1_gen2_pokemon = [name for name,gen in zip(poke_names, poke_gens) if gen < 2]

print (gen1_gen2_pokemon)

# Create a map object that stores the name lengths
name_lengths_map = map(len, gen1_gen2_pokemon)

# Combine gen1_gen2_pokemon and name_lengths_map into a list
gen1_gen2_name_lengths = [*zip(gen1_gen2_pokemon, name_lengths_map)]

print(gen1_gen2_name_lengths_loop[:5])
print(gen1_gen2_name_lengths[:5])

>>>>>>>>>>>>>>>find the top 3 stats

# Create a total stats array
total_stats_np = stats.sum(axis=1)

# Create an average stats array
avg_stats_np = stats.mean(axis=1)

# Combine names, total_stats_np, and avg_stats_np into a list
poke_list_np = [*zip(names, total_stats_np, avg_stats_np)]

print(poke_list_np == poke_list, '\n')
print(poke_list_np[:3])
print(poke_list[:3], '\n')
top_3 = sorted(poke_list_np, key=lambda x: x[1], reverse=True)[:3]
print('3 strongest Pokémon:\n{}'.format(top_3))


>>>>>>>>>>>Writing better loops

analyze what is being done in a loop

1. move one-time calculations above the loop
2. use holistic conversions outside the loop
3. anything that can be done once should be done outside the loop

fruits=['apple','orange','pear']
quantity=np.array([10,15,5])

total_avg=quantity.mean()

for a,b in zip(fruits,quantity):
    #print(a,b)
    if b> total_avg:
        print ("{} fruit {} quantity > {} avg".format(a,b,total_avg))

>>>> converting tuples outside the loop taking advantage of the map unpack

my_tuples=[]
for a_tuple in zip(fruits,quantity):        
    my_tuples.append(a_tuple)
    
print([*map(list,my_tuples)])


>>>>>>>>>>>>sample counter and percentages

# Import Counter
from collections import Counter

# Collect the count of each generation
gen_counts = Counter(generations)

# Improve for loop by moving one calculation above the loop
total_count = len(generations)

for gen,count in gen_counts.items():
    gen_percent = round(count / total_count * 100, 2)
    print('generation {}: count = {:3} percentage = {}'
          .format(gen, count, gen_percent))

>>>>>> sample  combination and map unpack to a list

# Collect all possible pairs using combinations()
possible_pairs = [*combinations(pokemon_types, 2)]

# Create an empty list called enumerated_tuples
enumerated_tuples = []

# Append each enumerated_pair_tuple to the empty list above
for i,pair in enumerate(possible_pairs, 1):
    enumerated_pair_tuple = (i,) + pair
    enumerated_tuples.append(enumerated_pair_tuple)

# Convert all tuples in enumerated_tuples to a list
enumerated_pairs = [*map(list, enumerated_tuples)]
print(enumerated_pairs)

>>>> scores

# Calculate the total HP avg and total HP standard deviation
hp_avg = hps.mean()
hp_std = hps.std()

# Use NumPy to eliminate the previous for loop
z_scores = (hps - hp_avg)/hp_std

# Combine names, hps, and z_scores
poke_zscores2 = [*zip(names, hps, z_scores)]
print(*poke_zscores2[:3], sep='\n')

# Use list comprehension with the same logic as the highest_hp_pokemon code block
highest_hp_pokemon2 = [(name, hp,z_score) for name,hp,z_score in poke_zscores2 if z_score > 2]
print(*highest_hp_pokemon2, sep='\n')


>>>>>>>>>>   pandas


win percentage is calculated by dividing the wins by the total games played

def calc_win_perc(wins, games_played):
	win_percent=wins/games_played
	return np.round(win_percent,2)


win_perc_list=[]

for i in range(len(baseball_df)):
	row=baseball_df.iloc[i]
	wins=rows['W']
	games_played=row['G']
	win_perc= calc_win_perc(wins,games_played)
	win_perc_list.append(win_perc)

baseball_df['WP']=win_perc_list

>>>>>>>>>iterrows()

win_perc_list=[]
for i, row in baseball_df.iterrows():
	wins=row['W']
	games_played=row['G']
	win_perc= calc_win_perc(wins,games_played)
	win_perc_list.append(win_perc)

baseball_df['WP']=win_perc_list


# Iterate over pit_df and print each row
for i,row in pit_df.iterrows():
    print(i)
    print(row)
    print(type(row))


for row_tuple in pit_df.iterrows():
    print(row_tuple)
    print(type(row_tuple))

>>>>>>>>>itertuples

for row_tuple in team_wins_df.itertuples():
    print(row_tuple)

iterrows returns each row as a tuple

row[index] to access the values

>>>> named tuple

filter=team_wins_df['Team']=='CIN'
for row_tuple in team_wins_df[filter].itertuples():
    print(row_tuple.Team,row_tuple.Year,row_tuple.Wins,row_tuple.WinPerc2)

each tuple has an index attribute

itertuple is much faster than iterrows() because of the method it stores each rows data.

tuples data are accessed by dot notation.


>>>> sample >>> itertuples

# Loop over the DataFrame and print each row
for row_tuple in rangers_df.itertuples():
  print(row_tuple)

>>>>> sample itertuples tuple dot notation access

for row in rangers_df.itertuples():
  i = row.Index
  year = row.Year
  wins = row.W
  print(i, year, wins)

>>>>> sample made the playoffs

# Loop over the DataFrame and print each row's Index, Year and Wins (W)
for row in rangers_df.itertuples():
  i = row.Index
  year = row.Year
  wins = row.W
  
  # Check if rangers made Playoffs (1 means yes; 0 means no)
  if row.Playoffs == 1:
    print(i,year,wins)

>>>>>>> sample  >>> run differential

run_diffs = []

# Loop over the DataFrame and calculate each row's run differential
for row in yankees_df.itertuples():
    
    runs_scored = row.RS
    runs_allowed = row.RA

    run_diff = calc_run_diff(runs_scored,runs_allowed)
    
    run_diffs.append(run_diff)
print(run_diffs)

# Append new column
yankees_df['RD'] = run_diffs
print(yankees_df)

max_rd=yankees_df['RD'].max()

print(max_rd)
filter=yankees_df['RD']==max_rd
print(yankees_df[filter])

>>>>>>>>>>>>>alternative to loop in pandas


def calc_run_diff(runs_scored, runs_allowed):
    run_diff = runs_scored - runs_allowed
    return run_diff


run_diffs_apply=df.apply(lambda row: calc_run_diff(row['RS'],row['RA']),axis=1)

0=columns
1=rows

df['RD']=run_diffs_apply
print(df)


>>>> sample >>> sum all columns

# Gather sum of all columns
stat_totals = rays_df.apply(sum, axis=0)
print(stat_totals)

# Gather total runs scored in all games per year
total_runs_scored = rays_df[['RS', 'RA']].apply(sum, axis=1)
print(total_runs_scored)

# Convert numeric playoffs to text by applying text_playoffs()
textual_playoffs = rays_df.apply(lambda row: text_playoffs(row['Playoffs']), axis=1)
print(textual_playoffs)

# Display the first five rows of the DataFrame
print(dbacks_df.head())

# Create a win percentage Series 
win_percs = dbacks_df.apply(lambda row: calc_win_perc(row['W'], row['G']), axis=1)
print(win_percs, '\n')


# Append a new column to dbacks_df
dbacks_df['WP'] = win_percs
print(dbacks_df, '\n')

# Display dbacks_df where WP is greater than 0.50
print(dbacks_df[dbacks_df['WP'] >= 0.50])


>>>>>>>>>>>>>>>>>>>>optimal pandas iterating

eliminating loops when using pandas 


pandas is built on numpy

arrays allow for vectorizing functions

wins_np=baseball_df['W'].values

returns the columns values as a numpy array

baseball_df['RS'].values - baseball_df['RA'].values

>>>>>>>>>> sample >>>>>

# Use the W array and G array to calculate win percentages
win_percs_np = calc_win_perc(baseball_df['W'].values, baseball_df['G'].values)

# Append a new column to baseball_df that stores all win percentages
baseball_df['WP'] = win_percs_np

print(baseball_df.head())

>>>>>>> sample >>> 36 miliseconds


%%timeit
win_perc_preds_loop = []

# Use a loop and .itertuples() to collect each row's predicted win percentage
for row in baseball_df.itertuples():
    runs_scored = row.RS
    runs_allowed = row.RA
    win_perc_pred = predict_win_perc(runs_scored, runs_allowed)
    win_perc_preds_loop.append(win_perc_pred)


# Apply predict_win_perc to each row of the DataFrame
win_perc_preds_apply = baseball_df.apply(lambda row: predict_win_perc(row['RS'], row['RA']), axis=1)

# Calculate the win percentage predictions using NumPy arrays
win_perc_preds_np = predict_win_perc(baseball_df['RS'].values, baseball_df['RA'].values)
baseball_df['WP_preds'] = win_perc_preds_np
print(baseball_df.head())


































