{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8ec5337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding,Flatten,Dropout, Dense, Concatenate, TimeDistributed, Bidirectional,Attention\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import linear_model\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "607672cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=8):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return np.array(dataX), np.array(dataY)\n",
    "\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    "\n",
    "def timeseries_to_supervised(data, lag=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
    "    columns.append(df)\n",
    "    df = concat(columns, axis=1)\n",
    "    return df\n",
    "\n",
    "def scale(train, test):\n",
    "    # fit scaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(train)\n",
    "    # transform train\n",
    "    train = train.reshape(train.shape[0], train.shape[1])\n",
    "    train_scaled = scaler.transform(train)\n",
    "    # transform test\n",
    "    test = test.reshape(test.shape[0], test.shape[1])\n",
    "    test_scaled = scaler.transform(test)\n",
    "    return scaler, train_scaled, test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9f63752e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
      "0         0    2   0.455     0.365   0.095        0.5140          0.2245   \n",
      "1         1    2   0.350     0.265   0.090        0.2255          0.0995   \n",
      "2         2    0   0.530     0.420   0.135        0.6770          0.2565   \n",
      "3         3    2   0.440     0.365   0.125        0.5160          0.2155   \n",
      "4         4    1   0.330     0.255   0.080        0.2050          0.0895   \n",
      "...     ...  ...     ...       ...     ...           ...             ...   \n",
      "4172   4172    0   0.565     0.450   0.165        0.8870          0.3700   \n",
      "4173   4173    2   0.590     0.440   0.135        0.9660          0.4390   \n",
      "4174   4174    2   0.600     0.475   0.205        1.1760          0.5255   \n",
      "4175   4175    0   0.625     0.485   0.150        1.0945          0.5310   \n",
      "4176   4176    2   0.710     0.555   0.195        1.9485          0.9455   \n",
      "\n",
      "      Viscera weight  Shell weight  Rings        Age  \n",
      "0             0.1010        0.1500     15  10.000000  \n",
      "1             0.0485        0.0700      7   4.666667  \n",
      "2             0.1415        0.2100      9   6.000000  \n",
      "3             0.1140        0.1550     10   6.666667  \n",
      "4             0.0395        0.0550      7   4.666667  \n",
      "...              ...           ...    ...        ...  \n",
      "4172          0.2390        0.2490     11   7.333333  \n",
      "4173          0.2145        0.2605     10   6.666667  \n",
      "4174          0.2875        0.3080      9   6.000000  \n",
      "4175          0.2610        0.2960     10   6.666667  \n",
      "4176          0.3765        0.4950     12   8.000000  \n",
      "\n",
      "[4177 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('abalone.data',names=['Sex'\n",
    ",'Length'\n",
    ",'Diameter'\n",
    ",'Height'\n",
    ",'Whole weight'\n",
    ",'Shucked weight'\n",
    ",'Viscera weight'\n",
    ",'Shell weight'\n",
    ",'Rings'])\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df['Age']=df['Rings'].apply(lambda x: x/1.5)\n",
    "\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "df['Sex']=encoder.fit_transform(df['Sex'])\n",
    "print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "dc3262c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.00000000e+00 0.00000000e+00 5.50000000e-01 ... 2.10000000e-01\n",
      "  1.40000000e+01 9.33333333e+00]\n",
      " [1.00000000e+01 0.00000000e+00 5.25000000e-01 ... 1.35000000e-01\n",
      "  1.00000000e+01 6.66666667e+00]\n",
      " [1.10000000e+01 2.00000000e+00 4.30000000e-01 ... 1.90000000e-01\n",
      "  1.10000000e+01 7.33333333e+00]\n",
      " ...\n",
      " [1.25000000e+03 1.00000000e+00 4.00000000e-01 ... 7.50000000e-02\n",
      "  6.00000000e+00 4.00000000e+00]\n",
      " [1.25100000e+03 1.00000000e+00 4.05000000e-01 ... 1.70000000e-01\n",
      "  7.00000000e+00 4.66666667e+00]\n",
      " [1.25200000e+03 1.00000000e+00 4.10000000e-01 ... 8.20000000e-02\n",
      "  6.00000000e+00 4.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "raw_values = df.values\n",
    "#diff_values = difference(raw_values, 1)\n",
    "\n",
    "features=10\n",
    "#supervised = timeseries_to_supervised(diff_values, features)\n",
    "supervised = timeseries_to_supervised(raw_values, features)\n",
    "supervised_values = supervised.values[features:,:]\n",
    "\n",
    "train_size = int(len(df) * 0.70)\n",
    "test_size = len(df) - train_size\n",
    "\n",
    "# split data into train and test-sets\n",
    "train, test = supervised_values[0:-train_size, :], supervised_values[-train_size:, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8a36b769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_lstm(X,time_steps=24, n_features=9,\n",
    "                optimizer = tf.keras.optimizers.Adam,\n",
    "                learning_rate = 0.001,\n",
    "                dropout = 0.5,\n",
    "                n_units_LSTM = 256,\n",
    "                n_units_1 = 200,\n",
    "                batch_size=1\n",
    "              ):\n",
    "    activation2 = 'relu'\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=n_units_LSTM, batch_input_shape=(batch_size, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(units=n_units_1, activation=activation2))\n",
    "    model.add(Dense(units=n_units_1, activation=activation2))\n",
    "    model.add(Dense(units=n_units_1, activation=activation2))\n",
    "    model.add(Dense(units=n_units_1, activation=activation2))\n",
    "    model.add(Dense(units=n_units_1, activation=activation2))\n",
    "    model.add(Dense(1))\n",
    "    optimizer = optimizer(learning_rate=learning_rate)\n",
    "    model.compile(loss='mean_squared_error', \n",
    "                  optimizer=optimizer)\n",
    "    print(model.summary())\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "787fd220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (1, 256)                  386048    \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (1, 256)                  0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (1, 200)                  51400     \n",
      "                                                                 \n",
      " dense_104 (Dense)           (1, 200)                  40200     \n",
      "                                                                 \n",
      " dense_105 (Dense)           (1, 200)                  40200     \n",
      "                                                                 \n",
      " dense_106 (Dense)           (1, 200)                  40200     \n",
      "                                                                 \n",
      " dense_107 (Dense)           (1, 200)                  40200     \n",
      "                                                                 \n",
      " dense_108 (Dense)           (1, 1)                    201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 598,449\n",
      "Trainable params: 598,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/100\n",
      "39/39 [==============================] - 2s 5ms/step - loss: 0.0936\n",
      "Epoch 2/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0844A: 0s - loss: 0.083\n",
      "Epoch 3/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0816\n",
      "Epoch 4/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0811\n",
      "Epoch 5/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0795\n",
      "Epoch 6/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0777\n",
      "Epoch 7/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0808\n",
      "Epoch 8/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0795\n",
      "Epoch 9/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0775\n",
      "Epoch 10/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0777\n",
      "Epoch 11/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0771\n",
      "Epoch 12/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0779\n",
      "Epoch 13/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0772\n",
      "Epoch 14/100\n",
      "39/39 [==============================] - 0s 7ms/step - loss: 0.0800\n",
      "Epoch 15/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0769\n",
      "Epoch 16/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0777\n",
      "Epoch 17/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0777\n",
      "Epoch 18/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 19/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0774\n",
      "Epoch 20/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 21/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0772\n",
      "Epoch 22/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 23/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 24/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 25/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 26/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0776\n",
      "Epoch 27/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0772A: 0s - loss: 0.0\n",
      "Epoch 28/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0769\n",
      "Epoch 29/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0778\n",
      "Epoch 30/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0777\n",
      "Epoch 31/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0770\n",
      "Epoch 32/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 33/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 34/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 35/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0776\n",
      "Epoch 36/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0773\n",
      "Epoch 37/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 38/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0772\n",
      "Epoch 39/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 40/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0772\n",
      "Epoch 41/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0770\n",
      "Epoch 42/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0775\n",
      "Epoch 43/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0771\n",
      "Epoch 44/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 45/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 46/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.071 - 0s 4ms/step - loss: 0.0769\n",
      "Epoch 47/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0770\n",
      "Epoch 48/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 49/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0768\n",
      "Epoch 50/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0773\n",
      "Epoch 51/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0773\n",
      "Epoch 52/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769A: 0s - loss: 0.076\n",
      "Epoch 53/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0771\n",
      "Epoch 54/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 55/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0773A: 0s - loss: 0.07\n",
      "Epoch 56/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 57/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 58/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0774\n",
      "Epoch 59/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0772A: 0s - loss: 0.07\n",
      "Epoch 60/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 61/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 62/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 63/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 64/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 65/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 66/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 67/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 68/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.0778- ETA: 0s - loss: 0.0 - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 69/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 70/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 71/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 72/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 73/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 74/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769A: 0s - loss: 0.074\n",
      "Epoch 75/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 76/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 77/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0770\n",
      "Epoch 78/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 79/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770A: 0s - loss: 0.07\n",
      "Epoch 80/100\n",
      "39/39 [==============================] - 0s 6ms/step - loss: 0.0769\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0768\n",
      "Epoch 82/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0773\n",
      "Epoch 83/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 84/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0770\n",
      "Epoch 85/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0768\n",
      "Epoch 86/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 87/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0770\n",
      "Epoch 88/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 89/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 90/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 91/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770A: 0s - loss: 0.078\n",
      "Epoch 92/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0771\n",
      "Epoch 93/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0771\n",
      "Epoch 94/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 95/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0773\n",
      "Epoch 96/100\n",
      "39/39 [==============================] - ETA: 0s - loss: 0.077 - 0s 5ms/step - loss: 0.0772\n",
      "Epoch 97/100\n",
      "39/39 [==============================] - 0s 4ms/step - loss: 0.0770\n",
      "Epoch 98/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0769\n",
      "Epoch 99/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770\n",
      "Epoch 100/100\n",
      "39/39 [==============================] - 0s 5ms/step - loss: 0.0770A: 0s - loss: 0.07\n"
     ]
    }
   ],
   "source": [
    "#X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.1,random_state=0,shuffle=True)\n",
    "\n",
    "scaler, train_scaled, test_scaled = scale(train, test)\n",
    "\n",
    "X_train, y_train = train_scaled[:, 0:-1], train_scaled[:, -1]\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, X_train.shape[1])\n",
    "\n",
    "X_test, y_test = test_scaled[:, 0:-1], test_scaled[:, -1]\n",
    "X = X_test.reshape(X_test.shape[0], 1, X_test.shape[1])\n",
    "\n",
    "\n",
    "#print(y)\n",
    "model=model_lstm(X_train)    \n",
    "history=model.fit(X_train,y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "58135fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_26\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_24 (LSTM)              (1, 256)                  386048    \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (1, 256)                  0         \n",
      "                                                                 \n",
      " dense_103 (Dense)           (1, 200)                  51400     \n",
      "                                                                 \n",
      " dense_104 (Dense)           (1, 200)                  40200     \n",
      "                                                                 \n",
      " dense_105 (Dense)           (1, 200)                  40200     \n",
      "                                                                 \n",
      " dense_106 (Dense)           (1, 200)                  40200     \n",
      "                                                                 \n",
      " dense_107 (Dense)           (1, 200)                  40200     \n",
      "                                                                 \n",
      " dense_108 (Dense)           (1, 1)                    201       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 598,449\n",
      "Trainable params: 598,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(\"Accuracy\",model.evaluate(X_test,y_test))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('loss accuracy')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "bd4487fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DNISHI~1\\AppData\\Local\\Temp/ipykernel_12900/923052346.py:43: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  Kmodel = KerasClassifier(build_fn=model,\n",
      "WARNING:absl:Found untraced functions such as lstm_cell_24_layer_call_fn, lstm_cell_24_layer_call_and_return_conditional_losses, lstm_cell_24_layer_call_fn, lstm_cell_24_layer_call_and_return_conditional_losses, lstm_cell_24_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9841257b-0382-402a-824d-83fb2e8964e2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://9841257b-0382-402a-824d-83fb2e8964e2/assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x000001F873E7E700> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\DNISHI~1\\AppData\\Local\\Temp/ipykernel_12900/923052346.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     scoring=mse, n_jobs=1)\n\u001b[0;32m     57\u001b[0m \u001b[1;31m#grid_result = grid.fit(X_train, y_train,fit_params=keras_fit_params)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;31m#grid.fit(X_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    803\u001b[0m         \u001b[0mn_splits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_n_splits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 805\u001b[1;33m         \u001b[0mbase_estimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    806\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mnew_object_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_object_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mnew_object_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[0mnew_object\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mnew_object_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mparams_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_object\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mclone\u001b[1;34m(estimator, safe)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"get_params\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msafe\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[1;34m(x, memo, _nil)\u001b[0m\n\u001b[0;32m    151\u001b[0m             \u001b[0mcopier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"__deepcopy__\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcopier\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[0mreductor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m__deepcopy__\u001b[1;34m(self, memo)\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m       new = pickle_utils.deserialize_model_from_bytecode(\n\u001b[1;32m--> 329\u001b[1;33m           *pickle_utils.serialize_model_as_bytecode(self))\n\u001b[0m\u001b[0;32m    330\u001b[0m       \u001b[0mmemo\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\saving\\pickle_utils.py\u001b[0m in \u001b[0;36mserialize_model_as_bytecode\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m           \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTarInfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m           \u001b[0minfo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m           \u001b[0marchive\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarinfo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m   \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36msize\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     97\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;34m\"\"\"Returns the size of the file.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mstat\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    908\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m   \"\"\"\n\u001b[1;32m--> 910\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mstat_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mstat_v2\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0moperation\u001b[0m \u001b[0mfails\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    925\u001b[0m   \"\"\"\n\u001b[1;32m--> 926\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_file_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_to_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    927\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    928\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {\n",
    "                'learning_rate' : [0.01, 0.001, 0.0001],\n",
    "                'n_units_LSTM' : [64,128,256],\n",
    "                'n_units_1' : [50, 100, 150, 200, 250, 300],\n",
    "                'dropout' : [0.1, 0.2, 0.25, 0.5]\n",
    "}\n",
    "#params={\n",
    "#    'batch_size':[1]\n",
    "#}\n",
    "#scorers = {\n",
    "#    'accuracy_score' : make_scorer(accuracy_score)\n",
    "#}\n",
    "#optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "epochs = [10, 50, 100]\n",
    "\n",
    "param_grid = dict(epochs=epochs, optimizer=optimizer)\n",
    "\n",
    "#grid_model = KerasClassifier(build_fn=model_lstm(X_train), verbose=0)\n",
    "#lasso = linear_model.Lasso()\n",
    "#cv = cross_validate(lasso, X_train, y_train,cv=5)\n",
    "#start = datetime.now()\n",
    "#grid = GridSearchCV(estimator = model,                      param_grid = params,                        n_jobs = 1,                        verbose = 1,\n",
    "#                        cv = cv,                         scoring = scorers,                        refit = 'accuracy_score')\n",
    "dropout_rate_opts  = [0, 0.2, 0.5]\n",
    "hidden_layers_opts = [[64, 64, 64, 64], [32, 32, 32, 32, 32], [100, 100, 100]]\n",
    "l2_penalty_opts = [0.01, 0.1, 0.5]\n",
    "keras_param_options = {\n",
    "    'hidden_layers': hidden_layers_opts,\n",
    "    'dropout_rate': dropout_rate_opts,  \n",
    "    'l2_penalty': l2_penalty_opts\n",
    "}\n",
    "early_stop = EarlyStopping(\n",
    "    monitor = 'val_loss', min_delta = 0.1, patience = 5, verbose = 0)\n",
    "\n",
    "callbacks = [early_stop]\n",
    "keras_fit_params = {   \n",
    "    'callbacks': callbacks,\n",
    "    'epochs': 200,\n",
    "    'batch_size': 2048,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "Kmodel = KerasClassifier(build_fn=model, \n",
    "                         verbose=1,epochs=5)\n",
    "\n",
    "mse = make_scorer(mean_squared_error,greater_is_better=False)\n",
    "param_grid = {\n",
    "    'clf__neurons_input':   [20, 25, 30, 35],\n",
    "    'clf__batch_size': [40,60,80,100], \n",
    "    'clf__optimizer': ['Adam', 'Adadelta']}\n",
    "grid = GridSearchCV(Kmodel,\n",
    "                    #param_distributions = keras_param_options,\n",
    "                    param_grid,\n",
    "                    #n_iter=3,\n",
    "                    cv=5,\n",
    "                    scoring=mse, n_jobs=1)\n",
    "#grid_result = grid.fit(X_train, y_train,fit_params=keras_fit_params)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "        \n",
    "#grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f472552",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
