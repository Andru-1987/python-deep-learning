{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deaths by county                            cases deaths\n",
      "                             max    max\n",
      "state    county date                   \n",
      "Colorado Adams  2020-04-10   543     23\n",
      "                2020-04-11   593     25\n",
      "                2020-04-12   647     26\n",
      "                2020-04-13   693     26\n",
      "                2020-04-14   726     27\n",
      "...                          ...    ...\n",
      "Utah     Weber  2020-09-28  4226     31\n",
      "                2020-09-29  4271     31\n",
      "                2020-09-30  4311     31\n",
      "                2020-10-01  4385     31\n",
      "                2020-10-02  4429     32\n",
      "\n",
      "[22420 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\ipykernel_launcher.py:60: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sys import exit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import decomposition\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    \n",
    "df_original = pd.read_csv(\"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\",encoding = \"ISO-8859-1\")\n",
    "df=df_original.copy()\n",
    "\n",
    "#filter=df_original[\"state\"]=='Idaho'\n",
    "filter=df_original[\"state\"].isin(['Colorado','Idaho','Utah'])\n",
    "df_original=df_original[filter]\n",
    "filter=df_original[\"date\"]>='2020-04-10'\n",
    "df_original=df_original[filter]\n",
    "\n",
    "filter=df[\"state\"].isin(['Colorado','Idaho','Utah'])\n",
    "df=df[filter]\n",
    "filter=df[\"date\"]>='2020-04-10'\n",
    "df=df[filter]\n",
    "\n",
    "#col_names=[\"fips\",\"cases\",\"deaths\"]\n",
    "#features_to_scale=df[col_names]\n",
    "#scaler=StandardScaler().fit(features_to_scale.values)\n",
    "#features_to_scale=scaler.transform(features_to_scale.values)\n",
    "#df2=pd.DataFrame(features_to_scale,columns=col_names)\n",
    "#col_names2=[\"county\",\"state\",\"date\"]\n",
    "#buff=df[col_names2]\n",
    "#df3=pd.DataFrame(buff,columns=col_names2)\n",
    "\n",
    "#df=pd.concat([df3,df2])\n",
    "df_original=df_original.sort_values(['county'],ascending=True)\n",
    "#print (df_original['deaths'].sum())\n",
    "#print (df_original['deaths'].max())\n",
    "\n",
    "def pct30(column):\n",
    "        return column.quantile(0.3)\n",
    "\n",
    "#county_counts_sorted=df_original['county'].value_counts()\n",
    "#print(\"Occurrences:\" + str(county_counts_sorted))\n",
    "\n",
    "print(\"deaths by county \" +str(df_original.groupby([\"state\",\"county\",'date'])[\"cases\",\"deaths\"].agg([max])))\n",
    "\n",
    "#results=df_original.pivot_table(index=\"county\",columns='date', values='deaths',fill_value=0, margins=True,aggfunc=[np.mean, np.median])\n",
    "\n",
    "#results=df_original.pivot_table(index=\"county\",columns='date', values='deaths',fill_value=0)\n",
    "#print(results)\n",
    "#print(results.shape)\n",
    "\n",
    "\n",
    "#plt.figure(figsize=(16, 9))\n",
    "#plt.plot( color='r')\n",
    "#plt.title('# of Coronavirus Cases', size=30)\n",
    "#plt.xlabel('county', size=30)\n",
    "#plt.ylabel('date', size=30)\n",
    "#plt.xticks(size=20)\n",
    "#plt.yticks(size=20)\n",
    "#plt.show()\n",
    "\n",
    "#elasticnet = ElasticNet(alpha=0.1, l1_ratio=0.7)\n",
    "#standardScaler=StandardScaler()\n",
    "#pca=decomposition.PCA()\n",
    "#imputer=SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "#elasticnet.fit(X_train, y_train)\n",
    "#y_pred_enet = elasticnet.predict(X_test)\n",
    "\n",
    "#steps = [('imputation', imputer),\n",
    "#         ('scalar', standardScaler),\n",
    "#         ('elasticnet', elasticnet)]\n",
    "#steps = [('pca', pca),\n",
    "#         ('sc', standardScaler),\n",
    "#         ('elasticnet', elasticnet)]\n",
    "\n",
    "          \n",
    "#pipeline = Pipeline(steps)\n",
    "\n",
    "#n_components = list(range(1,X.shape[1]+1,1))\n",
    "#normalize = [True, False]\n",
    "#selection = ['cyclic', 'random']\n",
    "#parameters = dict(pca__n_components=n_components,\n",
    "#                      elasticnet__normalize=normalize,\n",
    "#                      elasticnet__selection=selection)\n",
    "# Create train and test sets\n",
    "\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "\n",
    "#svm_confirmed = SVR(shrinking=True, kernel='poly',gamma=0.01, epsilon=1,degree=8, C=0.1)\n",
    "#svm_confirmed.fit(X_train, y_train)\n",
    "#svm_pred = svm_confirmed.predict(future_forcast)\n",
    "\n",
    "#svm_test_pred = svm_confirmed.predict(X_test)\n",
    "#plt.plot(y_test)\n",
    "#plt.plot(svm_test_pred)\n",
    "#plt.legend(['Test Data', 'SVM Predictions'])\n",
    "#print('MAE:', mean_absolute_error(svm_test_pred, y_test_confirmed))\n",
    "#print('MSE:',mean_squared_error(svm_test_pred, y_test_confirmed))\n",
    "\n",
    "# Create the GridSearchCV object: gm_cv\n",
    "#gm_cv = GridSearchCV(pipeline, parameters)\n",
    "\n",
    "# Fit to the training set\n",
    "#elasticnet.fit(X_train,y_train)\n",
    "\n",
    "# Compute and print the metrics\n",
    "#r2 = gm_cv.score(X_test, y_test)          \n",
    "\n",
    "\n",
    "#mojave_homelessness = homelessness[(homelessness['state']).isin(canu)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        cases                                              \\\n",
      "date               2020-04-10 2020-04-11 2020-04-12 2020-04-13 2020-04-14   \n",
      "state    county                                                             \n",
      "Colorado Adams            543        593        647        693        726   \n",
      "         Alamosa            7          7          7          7          7   \n",
      "         Arapahoe         931        998       1083       1142       1183   \n",
      "         Archuleta          6          6          6          6          6   \n",
      "         Baca               9         10         10         10         10   \n",
      "\n",
      "                                                                           \\\n",
      "date               2020-04-15 2020-04-16 2020-04-17 2020-04-18 2020-04-19   \n",
      "state    county                                                             \n",
      "Colorado Adams            758        805        860        894        915   \n",
      "         Alamosa            7          7          7          7          7   \n",
      "         Arapahoe        1243       1342       1419       1498       1536   \n",
      "         Archuleta          6          6          6          7          7   \n",
      "         Baca              10         10         10         10         10   \n",
      "\n",
      "                    ...     deaths                                   \\\n",
      "date                ... 2020-09-23 2020-09-24 2020-09-25 2020-09-26   \n",
      "state    county     ...                                               \n",
      "Colorado Adams      ...        222        224        225        225   \n",
      "         Alamosa    ...          9          9          9          9   \n",
      "         Arapahoe   ...        371        371        371        372   \n",
      "         Archuleta  ...          0          0          0          0   \n",
      "         Baca       ...          0          0          0          0   \n",
      "\n",
      "                                                                           \\\n",
      "date               2020-09-27 2020-09-28 2020-09-29 2020-09-30 2020-10-01   \n",
      "state    county                                                             \n",
      "Colorado Adams            225        226        227        227        228   \n",
      "         Alamosa            9          9          9          9          9   \n",
      "         Arapahoe         372        372        372        372        373   \n",
      "         Archuleta          0          0          0          0          0   \n",
      "         Baca               0          0          0          0          0   \n",
      "\n",
      "                               \n",
      "date               2020-10-02  \n",
      "state    county                \n",
      "Colorado Adams            230  \n",
      "         Alamosa            9  \n",
      "         Arapahoe         374  \n",
      "         Archuleta          0  \n",
      "         Baca               0  \n",
      "\n",
      "[5 rows x 352 columns]\n",
      "(140, 354)\n"
     ]
    }
   ],
   "source": [
    "results=df_original.pivot_table(index=[\"state\",\"county\"],columns='date', values=['deaths','cases'],fill_value=0)\n",
    "df_results=pd.DataFrame(results.to_records())\n",
    "df_results.reset_index()\n",
    "\n",
    "state_dummy=pd.get_dummies(df_results['state'])\n",
    "county_dummy=pd.get_dummies(df_results['county'])\n",
    "\n",
    "#df_results=pd.concat(df_results,state_dummy,county_dummy)\n",
    "\n",
    "#df_results.index(['state','county'])\n",
    "print(results.head(5))\n",
    "\n",
    "print(df_results.shape)\n",
    "#print(results.isna())\n",
    "#print(df_original)\n",
    "#print(results.head(5))\n",
    "\n",
    "#Print(df_results.head(1000))\n",
    "#X=df_results[:,1]\n",
    "#y=df_results[:,0]\n",
    "#print(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.plot(kind=\"bar\", title=\"deaths by county\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n",
    "\n",
    "df_original.plot(kind=\"bar\", \n",
    "             x=\"county\",\n",
    "             y=\"deaths\",\n",
    "             title=\"deaths by county\",rot=45)\n",
    "#plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n",
    "\n",
    "plt.clf()\n",
    "\n",
    "results.plot(kind=\"scatter\", \n",
    "             x=\"cases\",\n",
    "             y=\"deaths\",\n",
    "             title=\"cases by deaths\",rot=45)\n",
    "#plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n",
    "\n",
    "df_original['deaths'].hist()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.set_index(['state','county'])\n",
    "#df=df[df['deaths']>20]\n",
    "deaths=df['deaths'].tolist()\n",
    "cases=df['cases'].tolist()\n",
    "counties=df['county'].tolist()\n",
    "counties=df.groupby(['state','county'])['deaths'].max()>5\n",
    "#counties=df.groupby(['state','county'])\n",
    "#counties.apply(lambda x: x['deaths'].max()>20)\n",
    "#filtered=counties.filter(lambda x: x>10.)\n",
    "#print(filtered)\n",
    "\n",
    "\n",
    "counties=counties.loc[counties.values==True]\n",
    "#print(counties)\n",
    "counties.reset_index()\n",
    "#print(counties)\n",
    "counties=pd.merge(df,counties,how='inner',on=['state','county'])\n",
    "counties=counties[counties['deaths_y']==True]\n",
    "#print(counties)\n",
    "counties=counties['county'].unique()\n",
    "\n",
    "rows=len(counties)\n",
    "fig,ax = plt.subplots(rows,1)\n",
    "index=0\n",
    "\n",
    "for item in counties:\n",
    "    deaths=df[df['county']==item]\n",
    "    deaths=deaths['deaths'].tolist()\n",
    "    cases=df[df['county']==item]\n",
    "    cases=cases['cases'].tolist()\n",
    "    dates=df[df['county']==item]\n",
    "    #dates=pd.to_datetime(dates['date']).dt.date.unique().tolist()\n",
    "    dates=pd.to_datetime(dates['date']).dt.date.tolist()\n",
    "    #print(dates)\n",
    "    #dates=dates['date'].unique()\n",
    "    ax[index].plot(dates,deaths,label=item)\n",
    "    ax[index].set_title(item)\n",
    " \n",
    "    index+=1\n",
    "    #plt.plot(dates,deaths,label=item)\n",
    "    \n",
    "plt.legend()  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deaths=df.groupby(['state','county'])['deaths'].max().tolist()\n",
    "cases =df.groupby(['state','county'])['cases'].max().tolist()\n",
    "county=df.groupby(['state','county'])['county'].max().tolist()\n",
    "\n",
    "#print(county)\n",
    "#print(deaths)\n",
    "#print(len(county))\n",
    "\n",
    "dict={'county':county,\n",
    "     'deaths':deaths,\n",
    "     'cases':cases}\n",
    "combined=pd.DataFrame(dict)\n",
    "combined=combined.sort_values('deaths',ascending=False)\n",
    "\n",
    "\n",
    "print(combined)\n",
    "\n",
    "\n",
    "# Make scatter plot\n",
    "plt.scatter(deaths,cases)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "deaths=df.groupby(['date'])['deaths'].max()\n",
    "cases =df.groupby(['date'])['cases'].max()\n",
    "\n",
    "correlation = cases.corr(deaths)\n",
    "print(\"The correlation between x and y is %4.2f\" %(correlation))\n",
    "\n",
    "dfx = pd.DataFrame(deaths, columns=['deaths'])\n",
    "\n",
    "# Add a constant to the DataFrame dfx\n",
    "dfx1 = sm.add_constant(dfx)\n",
    "\n",
    "result=sm.OLS(cases,dfx1).fit()\n",
    "\n",
    "\n",
    "#plt.scatter(cases,result)\n",
    "\n",
    "plt.scatter(cases,deaths)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "days_in_future = 20\n",
    "future_forcast = np.array([i for i in range(len(dates)+days_in_future)]).reshape(-1, 1)\n",
    "adjusted_dates = future_forcast[:-20]\n",
    "print(adjusted_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "input_data=np.array([2,3])\n",
    "weights={'node_0':np.array([1,1]),\n",
    "        'node_1':np.array([-1,1]),\n",
    "        'output':np.array([2,-1])}\n",
    "node_0_value=(input_data * weights['node_0']).sum()\n",
    "node_1_value=(input_data * weights['node_1']).sum()\n",
    "\n",
    "hidden_layer_values=np.array([node_0_value,node_1_value])\n",
    "print(hidden_layer_values)\n",
    "\n",
    "output=(hidden_layer_values * weights['output']).sum()\n",
    "print(output)\n",
    "\n",
    "#tanh\n",
    "\n",
    "node_0_value=(input_data * weights['node_0']).sum()\n",
    "node_0_output=np.tanh(node_0_value)\n",
    "node_1_value=(input_data * weights['node_1']).sum()\n",
    "node_1_output=np.tanh(node_1_value)\n",
    "hidden_layer_values=np.array([node_0_output,node_1_output])\n",
    "print(hidden_layer_values)\n",
    "\n",
    "output=(hidden_layer_values * weights['output']).sum()\n",
    "print(output)\n",
    "\n",
    "#adding an activation function\n",
    "#ReLU (Rectified Linear Activation) 0 if x<0 and x if X>0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.datasets import load_iris\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#print(df.keys())\n",
    "filter=df[\"date\"]>='2020-03-1'\n",
    "df_learn=df[filter]\n",
    "#filter=df[\"state\"].isin(['Colorado','Idaho','Utah'])\n",
    "filter=df[\"state\"].isin(['Idaho'])\n",
    "#filter=df[\"county\"].isin(['Arapahoe'])\n",
    "df_learn=df_learn[filter]\n",
    "\n",
    "counties=df_learn.groupby(['state','county'])['deaths'].max()>5\n",
    "counties=counties.loc[counties.values==True]\n",
    "counties.reset_index()\n",
    "df_learn=pd.merge(df_learn,counties,how='inner',on=['state','county'])\n",
    "df_learn=df_learn[df_learn['deaths_y']==True]\n",
    "\n",
    "df_learn=pd.concat([df_learn,pd.get_dummies(df_learn['county'])], axis=1)\n",
    "df_cases=df_learn.pop('cases')\n",
    "df_learn['cases']=df_cases\n",
    "#print(df_learn.shape)\n",
    "#print(df_learn.head(5))\n",
    "\n",
    "dataset=np.nan_to_num(df_learn.values)\n",
    "#print(dataset)\n",
    "last=df_learn.shape[1]\n",
    "predictors=dataset[:,6:last] #counties and cases\n",
    "target=dataset[:,4] #deaths\n",
    "\n",
    "#print(predictors)\n",
    "#print(target)\n",
    "\n",
    "fig,ax = plt.subplots(1,1)\n",
    "ax.scatter(predictors[:,-1],target)\n",
    "plt.show()\n",
    "\n",
    "min_max_scaler= preprocessing.MinMaxScaler()\n",
    "X_scale= min_max_scaler.fit_transform(predictors)\n",
    "#print(X_scale)\n",
    "\n",
    "\n",
    "n_cols=predictors.shape[1]\n",
    "print(n_cols)\n",
    "\n",
    "X_train, X_test, y_train, y_test= train_test_split(X_scale,target,test_size=0.3)\n",
    "\n",
    "early_stopping_monitor=EarlyStopping(patience=3)\n",
    "\n",
    "model=Sequential()\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "#model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "\n",
    "#myOptimizer=SGD(0.1)\n",
    "model.compile(optimizer='sgd', loss='mean_squared_error', metrics=['accuracy'])\n",
    "#model.compile(optimizer=myOptimizer,  metrics=['accuracy'])\n",
    "model.fit(X_train, y_train,callbacks=[early_stopping_monitor],  nb_epoch=3000)\n",
    "\n",
    "predictionResults=model.predict(X_test)\n",
    "\n",
    "index=0\n",
    "for item in predictionResults:\n",
    "    print(str(predictionResults[index])+\":\"+str(y_test[index]))\n",
    "    index+=1\n",
    "\n",
    "svm_confirmed = SVR(shrinking=True, kernel='poly',gamma=0.01, epsilon=1,degree=8, C=0.1)\n",
    "svm_confirmed.fit(X_train, y_train)\n",
    "y_pred=svm_confirmed.predict(X_test)\n",
    "\n",
    "#for i in range(len(y_test)):\n",
    "#        print(\"X=%s, Test Label=%s Predicted=%s\" %(X_test[i],y_test[i],y_pred[i]))\n",
    "        \n",
    "#svm_pred = svm_confirmed.predict(future_forcast)    \n",
    "\n",
    "#plt.plot(hist.history['loss'])\n",
    "#plt.plot(hist.history['val_loss'])\n",
    "#plt.title('Model loss')\n",
    "#plt.ylabel('Loss')\n",
    "#plt.xlabel('Epoch')\n",
    "#plt.legend(['Train', 'Val'])\n",
    "#plt.show()\n",
    "\n",
    "#plt.plot(hist.history['acc'])plt.plot(hist.history['val_acc'])plt.title('Model accuracy')plt.ylabel('Accuracy')plt.xlabel('Epoch')plt.legend(['Train', 'Val'], loc='lower right')plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
