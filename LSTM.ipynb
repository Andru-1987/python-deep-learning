{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.utils import plot_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.layers.merge import Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    56772\n",
      "1      102\n",
      "Name: fraud, dtype: int64\n",
      "10\n",
      "(38105, 1, 30)\n",
      "1\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "url = \"https://raw.githubusercontent.com/dnishimoto/python-deep-learning/master/creditcard.csv\"\n",
    "\n",
    "creditcard = pd.read_csv(url)\n",
    "\n",
    "creditcard.columns = [x.lower() for x in creditcard.columns]\n",
    "creditcard.rename(columns = {'class': 'fraud'}, inplace = True)\n",
    "print(creditcard.fraud.value_counts(dropna = False))\n",
    "\n",
    "X = creditcard.drop(\"fraud\", axis = 1)\n",
    "y = creditcard[\"fraud\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = .33, stratify = y, random_state = 42)\n",
    "\n",
    "samples=1\n",
    "timeSteps=10\n",
    "features=len(creditcard.columns)\n",
    "\n",
    "print (timeSteps)\n",
    "\n",
    "data = np.resize(X_train,(X_train.shape[0],1,X_train.shape[1]))\n",
    "\n",
    "print(data.shape)\n",
    "print(data.shape[1])\n",
    "print(data.shape[2])\n",
    "\n",
    "#data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0])\n",
    "#data = X.reshape(1,5,features)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Samples. One sequence is one sample. A batch is comprised of one or more samples.\n",
    "#Time Steps. One time step is one point of observation in the sample.\n",
    "#Features. One feature is one observation at a time step.\n",
    "\n",
    "\n",
    "\n",
    "#input layer expects a 3D array of data when fitting the model and when making predictions, \n",
    "#even if specific dimensions of the array contain a single value, e.g. one sample or one feature.\n",
    "\n",
    "#The input shape is supposed in the format (no_of_samples,no_of_timesteps,features)\n",
    "\n",
    "#The input to every LSTM layer must be three-dimensional.\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, activation='relu', return_sequences=True,\n",
    "               batch_input_shape=(1,timeSteps, features)))  # returns a sequence of vectors of dimension 32\n",
    "\n",
    "model.add(LSTM(32, return_sequences=True))  # returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plot_model(model, to_file='model.png')\n",
    "img=plt.imread('model.png')\n",
    "plt.imshow(img)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_67_input to have 3 dimensions, but got array with shape (38105, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-96eb5ddec87b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m model.fit(X_train, y_train,\n\u001b[1;32m---> 10\u001b[1;33m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m           \u001b[1;31m#validation_data=(x_val, y_val)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m          )\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_67_input to have 3 dimensions, but got array with shape (38105, 30)"
     ]
    }
   ],
   "source": [
    "# Generate dummy training data\n",
    "#x_train = np.random.random((1000, timesteps, data_dim))\n",
    "#y_train = np.random.random((1000, num_classes))\n",
    "\n",
    "# Generate dummy validation data\n",
    "x_val = np.random.random((100, timesteps, data_dim))\n",
    "y_val = np.random.random((100, num_classes))\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=64, epochs=5,\n",
    "          #validation_data=(x_val, y_val)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected lstm_28_input to have 3 dimensions, but got array with shape (56874, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-951171e70300>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#print(buffer)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0myes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m>=\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mno\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m<\u001b[0m\u001b[1;36m.5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected lstm_28_input to have 3 dimensions, but got array with shape (56874, 30)"
     ]
    }
   ],
   "source": [
    "y_pred=model.predict(X_scaled)\n",
    "buffer=y_pred.flatten()\n",
    "#print(buffer)\n",
    "yes=buffer[buffer>=.5]\n",
    "no=buffer[buffer<.5]\n",
    "print(len(yes))\n",
    "print(len(no))\n",
    "\n",
    "counts=[len(no),len(yes)]\n",
    "plt.bar(range(2),counts)\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xlabel(\"Rejection/Success\")\n",
    "\n",
    "plt.annotate(str(len(no)), xy=(0,len(no)))\n",
    "plt.annotate(str(len(yes)), xy=(1,len(yes)))\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
