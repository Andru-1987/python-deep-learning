good feature structure
neural networks can feature extract
dealing with unstructured data
benefit from convolution neural networks

input layer->hidden layer -> output

the sequential api


from keras.models import Sequential
from keras.layers import Dense


model= Sequential()

model.add(Dense(2, input_shape=(3,),
activation='relu'
))

model.add(Dense(1))

model.summary()

>>>

# Import the Sequential model and Dense layer
from keras.models import Sequential
from keras.layers import Dense

# Create a Sequential model
model= Sequential()

# Add an input layer and a hidden layer with 10 neurons
model.add(Dense(10, input_shape=(10,), activation="relu"))

# Add a 1-neuron output layer
model.add(Dense(1))

# Summarise your model
model.summary()

>> 3 inputs 5 hidden layer 1 output

# Instantiate a new Sequential model
model = Sequential()

# Add a Dense layer with five neurons and three inputs
model.add(Dense(5, input_shape=(3,), activation="relu"))

# Add a final Dense layer with one neuron and no activation
model.add(Dense(1))

>>> input 2 hidden 3 output 1

from keras.layers import Dense

# Instantiate a Sequential model
model = Sequential()

# Build the input and hidden layer
model.add(Dense(3,input_shape=(2,), activation='relu'))

# Add the ouput layer
model.add(Dense(1))
model.summary()

>>>

model.compile(optimizer="adam", loss="mse")
#mse - mean squared error

model.fit(X_train,y_train, epochs=5)

preds=model.predict(X_test)
print(preds)
model.evaluate(X_test,y_test)


>>>>

df=pd.read_csv('wine.data.csv', usecols=['Cultivator', 'Alcohol', 'Malic_Acid', 'Ash', 'Alcalinity_of_Ash',
       'Magnesium', 'Total_Phenols', 'Flavanoids', 'Nonflavanoid_phenols',
       'Proanthocyanins', 'Color_Intensity', 'Hue', 'OD280', 'Proline'])

#rint(df.keys())
#print(df.head())

X = df.drop('Cultivator',axis=1)
y = df['Cultivator']

X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3, random_state=42)


scaler = StandardScaler()

scaler.fit(X_train)

StandardScaler(copy=True, with_mean=True,with_std=True)
X_train=scaler.transform(X_train)
X_test=scaler.transform(X_test)
model= Sequential()

model.add(Dense(13, input_shape=(13,),
#activation='sigmoid'
activation='relu'
))

model.add(Dense(13, activation='relu'))
model.add(Dense(1))

#model.compile(optimizer=Adam(0.01),loss='binary_crossentropy')
model.compile(optimizer=Adam(0.01),loss='mae')

model.summary()

plot_model(model, to_file='model.png')
img=plt.imread('model.png')
plt.imshow(img)
plt.show()

#print(X_train[0])
model.fit(X_train, y_train, epochs=600)

predictions = model.predict(X_test)

y_pos = np.arange(len(predictions))

prediction_result = predictions.flatten().round() 

plt.plot(predictions.round())
#plt.barh(y_pos,list_test)
plt.show()

plt.bar(y_pos,prediction_result, color='green')
plt.bar(y_pos,y_test,color='red',alpha=.6 )

plt.show()

print(model.evaluate(X_test,y_test))

>>>

# Instantiate a Sequential model
model = Sequential()

# Add a Dense layer with 50 neurons and an input of 1 neuron
model.add(Dense(50, input_shape=(1,), activation='relu'))

# Add two Dense layers with 50 neurons and relu activation
model.add(Dense(50, activation='relu'))
model.add(Dense(50,activation='relu'))

# End your model with a Dense layer and no activation
model.add(Dense(1))

# Compile your model
model.compile(optimizer='adam' ,loss  = 'mse')

print("Training started..., this can take a while:")

# Fit your model on your data for 30 epochs
model.fit(time_steps,y_positions, epochs = 30)

# Evaluate your model 
print("Final lost value:",model.evaluate(time_steps, y_positions))

# Predict the twenty minutes orbit
twenty_min_orbit = model.predict(np.arange(-10, 11))

# Plot the twenty minute orbit 
plot_orbit(twenty_min_orbit)







