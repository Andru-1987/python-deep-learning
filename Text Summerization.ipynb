{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from keras.layers import Dense, Flatten,Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding,Flatten,Dropout, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "        \n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "        print(c_outputs, e_outputs)\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "509\n",
      "45\n",
      "Review: I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most. \n",
      "\tSummary: Good Quality Dog Food \n",
      "\n",
      "Review: Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\". \n",
      "\tSummary: Not as Advertised \n",
      "\n",
      "Review: This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch. \n",
      "\tSummary: \"Delight\" says it all \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Reviews.csv\",nrows=10)\n",
    "print(data.columns)\n",
    "df.drop_duplicates(subset=['Text'],inplace=True)  #dropping duplicates\\n\",\n",
    "df.dropna(axis=0,inplace=True)\n",
    "    \n",
    "print(max([len(x) for x in data['Text']]))\n",
    "print(max([len(x) for x in data['Summary']]))\n",
    "for detail,summary in zip(df['Text'][:3],df['Summary'][:3]):\n",
    "    print(\"Review:\",detail,\"\\n\\tSummary:\",summary,\"\\n\")\n",
    "    \n",
    "    \n",
    "data=[]\n",
    "\n",
    "for sent in df['Text']:\n",
    "    # Add sos and eos tokens using string.join\n",
    "    sent_new = \" \".join(['sos', sent, 'eos'])\n",
    "    data.append(sent_new)\n",
    "\n",
    "summary=[]\n",
    "for sent in df['Summary']:\n",
    "    # Add sos and eos tokens using string.join\n",
    "    sent_new = \" \".join(['sos', sent, 'eos'])\n",
    "    summary.append(sent_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    max_len_text=80\n",
    "    max_len_summary=45\n",
    "    latent_dim = 50 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(data,summary,test_size=0.1,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_train    =   x_tokenizer.texts_to_sequences(X_train) \n",
    "x_test   =   x_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "#print(x_tokenizer.sequences_to_texts(x_train))\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_train    =   pad_sequences(x_train,  maxlen=max_len_text, padding='post') \n",
    "x_test   =   pad_sequences(x_test, maxlen=max_len_text, padding='post')\n",
    "\n",
    "x_voc_size   =  len(x_tokenizer.word_index) +1\n",
    "\n",
    "#print(x_train)\n",
    "#print(x_tokenizer.sequences_to_texts(x_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(Y_train))\n",
    "\n",
    "#convert summary sequences into integer sequences\n",
    "y_train    =   y_tokenizer.texts_to_sequences(Y_train) \n",
    "y_test   =   y_tokenizer.texts_to_sequences(Y_test) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_train    =   pad_sequences(y_train, maxlen=max_len_summary, padding='post')\n",
    "y_test   =   pad_sequences(y_test, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "y_voc_size  =   len(y_tokenizer.word_index) +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"attention_layer_3/transpose_5:0\", shape=(?, ?, 50), dtype=float32) Tensor(\"attention_layer_3/transpose_3:0\", shape=(?, ?, 80), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 80)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_4 (Embedding)         (None, 80, 50)       9700        input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_8 (LSTM)                   [(None, 80, 50), (No 20200       embedding_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 80, 50), (No 20200       lstm_8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 50)     1200        input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, 80, 50), (No 20200       lstm_9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_11 (LSTM)                  [(None, None, 50), ( 20200       embedding_5[0][0]                \n",
      "                                                                 lstm_10[0][1]                    \n",
      "                                                                 lstm_10[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer [(None, None, 50), ( 5050        lstm_10[0][0]                    \n",
      "                                                                 lstm_11[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 100)    0           lstm_11[0][0]                    \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, None, 24)     2424        concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 99,174\n",
      "Trainable params: 99,174\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# [[[[[Encoder]]]]]\n",
    "#batch_size=100\n",
    "encoder_inputs = Input(shape=(max_len_text,)) \n",
    "#encoder_inputs = Input(batch_shape=(batch_size, max_len_text, x_voc_size))\n",
    "\n",
    "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
    "#print(enc_emb.shape)\n",
    "\n",
    "#LSTM 1 \n",
    "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "#LSTM 2 \n",
    "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "#LSTM 3 \n",
    "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Set up the [[[[[[[[decoder]]]]]]]]. \n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
    "\n",
    "#print(decoder_outputs)\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "9/9 [==============================] - 3s 363ms/sample - loss: 3.1840 - acc: 0.0051\n",
      "Epoch 2/50\n",
      "9/9 [==============================] - 0s 40ms/sample - loss: 3.0917 - acc: 0.9040\n",
      "Epoch 3/50\n",
      "9/9 [==============================] - 0s 21ms/sample - loss: 2.9690 - acc: 0.9040\n",
      "Epoch 4/50\n",
      "9/9 [==============================] - 0s 20ms/sample - loss: 2.7032 - acc: 0.9040\n",
      "Epoch 5/50\n",
      "9/9 [==============================] - 0s 16ms/sample - loss: 1.9703 - acc: 0.9040\n",
      "Epoch 6/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.9390 - acc: 0.9040\n",
      "Epoch 7/50\n",
      "9/9 [==============================] - 0s 16ms/sample - loss: 0.5574 - acc: 0.9040\n",
      "Epoch 8/50\n",
      "9/9 [==============================] - 0s 17ms/sample - loss: 0.4762 - acc: 0.9040\n",
      "Epoch 9/50\n",
      "9/9 [==============================] - 0s 21ms/sample - loss: 0.4494 - acc: 0.9040\n",
      "Epoch 10/50\n",
      "9/9 [==============================] - 0s 19ms/sample - loss: 0.4337 - acc: 0.9040\n",
      "Epoch 11/50\n",
      "9/9 [==============================] - 0s 16ms/sample - loss: 0.4221 - acc: 0.9040\n",
      "Epoch 12/50\n",
      "9/9 [==============================] - 0s 13ms/sample - loss: 0.4126 - acc: 0.9040\n",
      "Epoch 13/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.4047 - acc: 0.9040\n",
      "Epoch 14/50\n",
      "9/9 [==============================] - 0s 13ms/sample - loss: 0.3981 - acc: 0.9040\n",
      "Epoch 15/50\n",
      "9/9 [==============================] - 0s 13ms/sample - loss: 0.3923 - acc: 0.9040\n",
      "Epoch 16/50\n",
      "9/9 [==============================] - 0s 13ms/sample - loss: 0.3871 - acc: 0.9040\n",
      "Epoch 17/50\n",
      "9/9 [==============================] - 0s 18ms/sample - loss: 0.3825 - acc: 0.9040\n",
      "Epoch 18/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.3783 - acc: 0.9040\n",
      "Epoch 19/50\n",
      "9/9 [==============================] - 0s 16ms/sample - loss: 0.3744 - acc: 0.9040\n",
      "Epoch 20/50\n",
      "9/9 [==============================] - 0s 20ms/sample - loss: 0.3709 - acc: 0.9040\n",
      "Epoch 21/50\n",
      "9/9 [==============================] - 0s 21ms/sample - loss: 0.3677 - acc: 0.9040\n",
      "Epoch 22/50\n",
      "9/9 [==============================] - 0s 15ms/sample - loss: 0.3647 - acc: 0.9040\n",
      "Epoch 23/50\n",
      "9/9 [==============================] - 0s 13ms/sample - loss: 0.3619 - acc: 0.9040\n",
      "Epoch 24/50\n",
      "9/9 [==============================] - 0s 13ms/sample - loss: 0.3593 - acc: 0.9040\n",
      "Epoch 25/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.3567 - acc: 0.9040\n",
      "Epoch 26/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.3544 - acc: 0.9040\n",
      "Epoch 27/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.3519 - acc: 0.9040\n",
      "Epoch 28/50\n",
      "9/9 [==============================] - 0s 17ms/sample - loss: 0.3498 - acc: 0.9040\n",
      "Epoch 29/50\n",
      "9/9 [==============================] - 0s 36ms/sample - loss: 0.3475 - acc: 0.9040\n",
      "Epoch 30/50\n",
      "9/9 [==============================] - 0s 26ms/sample - loss: 0.3455 - acc: 0.9040\n",
      "Epoch 31/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.3433 - acc: 0.9040\n",
      "Epoch 32/50\n",
      "9/9 [==============================] - 0s 17ms/sample - loss: 0.3415 - acc: 0.9040\n",
      "Epoch 33/50\n",
      "9/9 [==============================] - 0s 36ms/sample - loss: 0.3393 - acc: 0.9040\n",
      "Epoch 34/50\n",
      "9/9 [==============================] - 0s 22ms/sample - loss: 0.3376 - acc: 0.9040\n",
      "Epoch 35/50\n",
      "9/9 [==============================] - 0s 28ms/sample - loss: 0.3353 - acc: 0.9040\n",
      "Epoch 36/50\n",
      "9/9 [==============================] - 0s 20ms/sample - loss: 0.3335 - acc: 0.9040\n",
      "Epoch 37/50\n",
      "9/9 [==============================] - 0s 42ms/sample - loss: 0.3310 - acc: 0.9040\n",
      "Epoch 38/50\n",
      "9/9 [==============================] - 0s 28ms/sample - loss: 0.3291 - acc: 0.9040\n",
      "Epoch 39/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.3264 - acc: 0.9066\n",
      "Epoch 40/50\n",
      "9/9 [==============================] - 0s 22ms/sample - loss: 0.3243 - acc: 0.9040\n",
      "Epoch 41/50\n",
      "9/9 [==============================] - 0s 20ms/sample - loss: 0.3214 - acc: 0.9116\n",
      "Epoch 42/50\n",
      "9/9 [==============================] - 0s 13ms/sample - loss: 0.3189 - acc: 0.9040\n",
      "Epoch 43/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.3155 - acc: 0.9116\n",
      "Epoch 44/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.3128 - acc: 0.9040\n",
      "Epoch 45/50\n",
      "9/9 [==============================] - 0s 17ms/sample - loss: 0.3093 - acc: 0.9116\n",
      "Epoch 46/50\n",
      "9/9 [==============================] - 0s 24ms/sample - loss: 0.3068 - acc: 0.9040\n",
      "Epoch 47/50\n",
      "9/9 [==============================] - 0s 25ms/sample - loss: 0.3035 - acc: 0.9116\n",
      "Epoch 48/50\n",
      "9/9 [==============================] - 0s 17ms/sample - loss: 0.3014 - acc: 0.9066\n",
      "Epoch 49/50\n",
      "9/9 [==============================] - 0s 14ms/sample - loss: 0.2982 - acc: 0.9141\n",
      "Epoch 50/50\n",
      "9/9 [==============================] - 0s 19ms/sample - loss: 0.2962 - acc: 0.9066\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/thushv89/attention_keras/blob/master/src/examples/nmt_bidirectional/model.py\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "\n",
    "epochs = 5\n",
    "batch_size = len(x_train)\n",
    "\n",
    "\n",
    "history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,batch_size=128)\n",
    "#history=model.fit([x_train,y_train[:,:-1]],epochs=50,batch_size=128)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sos': 1, 'eos': 2, 'taffy': 3, 'as': 4, 'great': 5, 'dog': 6, 'food': 7, 'good': 8, 'yay': 9, 'barley': 10, 'healthy': 11, 'not': 12, 'advertised': 13, 'just': 14, 'the': 15, 'expensive': 16, 'brands': 17, 'wonderful': 18, 'tasty': 19, 'cough': 20, 'medicine': 21, 'quality': 22, 'nice': 23}\n",
      "Tensor(\"attention_layer_4/transpose_5:0\", shape=(?, ?, 50), dtype=float32) Tensor(\"attention_layer_4/transpose_3:0\", shape=(?, ?, 80), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "reverse_target_word_index=y_tokenizer.index_word\n",
    "reverse_source_word_index=x_tokenizer.index_word\n",
    "reverse_source_index_word=x_tokenizer.word_index\n",
    "target_word_index=y_tokenizer.word_index\n",
    "\n",
    "print(target_word_index)\n",
    "\n",
    "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# Decoder setup\n",
    "# Below tensors will hold the states of the previous time step\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
    "\n",
    "# Get the embeddings of the decoder sequence\n",
    "dec_emb2= dec_emb_layer(decoder_inputs) \n",
    "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "#attention inference\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat) \n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq,n_steps,cardinality):\n",
    "    # Encode the input as state vectors.\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    \n",
    "    #target_seq = np.array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "    # collect predictions\n",
    "    #output = list()\n",
    "    #for t in range(n_steps):\n",
    "        # predict next char\n",
    "        #yhat, h, c = infdec.predict([target_seq] + state)\n",
    "    #    yhat, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        # store prediction\n",
    "    #    output.append(yhat[0,0,:])\n",
    "        # update state\n",
    "    #    state = [h, c]\n",
    "        # update target sequence\n",
    "    #    target_seq = yhat\n",
    "    #return array(output)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    #target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first word of target sequence with the start word.\n",
    "    target_seq[0, 0] = target_word_index['sos']\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    count=0\n",
    "    while not stop_condition:\n",
    "      \n",
    "        count+=1\n",
    "        if count>100:\n",
    "            break\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        output_tokens=output_tokens[0, -1, :].flatten()\n",
    "        print(output_tokens)\n",
    "       # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens)+1\n",
    "        print(sampled_token_index)\n",
    "        print(reverse_target_word_index)\n",
    "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
    "        \n",
    "        decoded_sentence += ' '+sampled_token\n",
    "        \n",
    "        print(decoded_sentence)\n",
    "\n",
    "        # Exit condition: either hit max length or find stop word.\n",
    "        if (len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update internal states\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'target_seq' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-11046492751b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#seq, n_steps, cardinality\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mdecode_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_voc_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#e_out, e_h, e_c = encoder_model.predict(test_seq)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-35-bde688df7ed0>\u001b[0m in \u001b[0;36mdecode_sequence\u001b[1;34m(input_seq, n_steps, cardinality)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;31m# Populate the first word of target sequence with the start word.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mtarget_seq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_word_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sos'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mstop_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdecoded_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'target_seq' referenced before assignment"
     ]
    }
   ],
   "source": [
    "test_text=\"sos flavors eos\"\n",
    "bow=test_text.split(\" \")\n",
    "\n",
    "test_seq=[reverse_source_index_word[word] for word in bow]\n",
    "test_seq =pad_sequences([test_seq], maxlen=max_len_text, padding='post')\n",
    "\n",
    "test_seq=test_seq.reshape(1,max_len_text)   \n",
    "#print(test_seq)\n",
    "#seq, n_steps, cardinality\n",
    "n_steps=6\n",
    "decode_sequence(test_seq,n_steps,x_voc_size)\n",
    "\n",
    "#e_out, e_h, e_c = encoder_model.predict(test_seq)\n",
    "    \n",
    "#target_seq = np.array([0.0 for _ in range(x_voc_size)]).reshape(1, 1, x_voc_size)\n",
    "#yhat, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
