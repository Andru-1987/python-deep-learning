{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "323f0a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent.futures\n",
    "import asyncio\n",
    "import functools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e0cc1414",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"OPENAI_API_KEY.env\", 'r')\n",
    "key = f.readline()\n",
    "f.close()\n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "openai.api_key=key\n",
    "\n",
    "def gpt_response1(sText):\n",
    "    response = openai.Completion.create(\n",
    "      engine=\"text-davinci-003\",\n",
    "      prompt=sText,\n",
    "      temperature=0.7,\n",
    "      max_tokens=600,\n",
    "      top_p=1,\n",
    "      frequency_penalty=0.0,\n",
    "      presence_penalty=0.6,\n",
    "      stop=[\" Human:\", \" AI:\"]\n",
    "    )\n",
    "    content=response.choices[0].text.split('.')\n",
    "    #print(content)\n",
    "    #print(response[\"choices\"])\n",
    "    return response.choices[0].text\n",
    "\n",
    "def gpt_response_sync(sText):\n",
    "    context=\"You are an Lousie the AI assistant.\"\n",
    "    messages = [\n",
    "    {\"role\": \"system\", \"content\": context},\n",
    "    {\"role\": \"user\", \"content\": sText}\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "      engine=\"davinci\",\n",
    "      prompt=f\"Conversation:\\n{context}\\nUser: {sText}\\n\",\n",
    "      #message=messages,\n",
    "      temperature=0.7,\n",
    "      max_tokens=600,\n",
    "      #model=\"text-davinci-003\",\n",
    "      stop=None\n",
    "    )\n",
    "    content=response.choices[0].text.split('.')\n",
    "    #print(content)\n",
    "    #print(response[\"choices\"])\n",
    "    return response.choices[0].text\n",
    "\n",
    "async def generate_response(prompt):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    executor = concurrent.futures.ThreadPoolExecutor()\n",
    "    response = await loop.run_in_executor(executor, functools.partial(gpt_response_sync, prompt))\n",
    "    return response\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b718287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loiuse, Why have black holes become so important to the electric universe proponents\n",
      "?\n",
      "\n",
      "Black holes have become important to electric universe proponents because they are seen as a way to explain the behavior of some galaxies. Electric universe proponents suggest that black holes could act as “anchors” for electrical currents that flow through the galaxy, influencing its shape and dynamics. This allows them to explain the observations of galaxies that are not consistent with the standard model of astrophysics.\n"
     ]
    }
   ],
   "source": [
    "#sText=\"Human: Hi Louise, how are you?\\n You are very smart.\"\n",
    "#sText=\"Human: Louise why do people fear something going wrong while they are talking to another person\"\n",
    "#sText=\"Human: why should we let other tell us about their model of the world when communicating?\"\n",
    "sText=\"Loiuse, Why have black holes become so important to the electric universe proponents\"\n",
    "print(sText)\n",
    "print(gpt_response1(sText))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d7445b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#prompt=input(\"Type in a message: \")\n",
    "#print(prompt)\n",
    "\n",
    "#print(await generate_response(prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50be75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('data.csv')\n",
    "\n",
    "# Extract input and output columns\n",
    "#inputs = data['input_column'].tolist()\n",
    "#outputs = data['output_column'].tolist()\n",
    "\n",
    "#prompt = 'your_prompt_here'\n",
    "\n",
    "# Define the training options\n",
    "#training_options = {\n",
    "#    'model': 'gpt-3.5-turbo',\n",
    "#    'dataset': 'your_dataset_name',\n",
    "#    'file': 'your_file_name',\n",
    "#    'examples': []\n",
    "#}\n",
    "\n",
    "\n",
    "# Add examples to the training options\n",
    "#for i in range(len(inputs)):\n",
    "#    example = {\n",
    "#        'input': inputs[i],\n",
    "#        'output': outputs[i]\n",
    "#    }\n",
    "#    training_options['examples'].append(example)\n",
    "\n",
    "# Fine-tune the model\n",
    "#openai.ChatCompletion.create(**training_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eefa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import openai\n",
    "#import requests\n",
    "\n",
    "#openai.api_key = key\n",
    "\n",
    "# Upload the training file\n",
    "url = \"https://api.openai.com/v1/files\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openai.api_key}\",\n",
    "}\n",
    "data = {\n",
    "    \"purpose\": \"fine-tune\",\n",
    "}\n",
    "files = {\n",
    "    \"file\": (\"training_file.txt\", open(\"path/to/training_file.txt\"), \"text/plain\"),\n",
    "}\n",
    "response = requests.post(url, headers=headers, data=data, files=files)\n",
    "file_id = response.json()[\"id\"]\n",
    "\n",
    "# Start the fine-tuning job\n",
    "url = \"https://api.openai.com/v1/fine_tuning/jobs\"\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {openai.api_key}\",\n",
    "}\n",
    "data = {\n",
    "    \"model\": \"text-davinci-003\",\n",
    "    \"file\": file_id,\n",
    "    \"description\": \"My fine-tuning job\",\n",
    "}\n",
    "response = requests.post(url, headers=headers, json=data)\n",
    "job_id = response.json()[\"id\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
