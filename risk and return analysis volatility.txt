structural breaks and volatility are signs of extreme values

chow test: identify statistical significance of a possible structural breakc
requires: pre-specified point of structural break

visual identifying a structural break in the data is not possible because of noise in the data.

alternative: examine volatility rather than trend
1. structural change often accompanied by greater uncertainty => volatility
2. large changes in volatility indicate possible structural break points
3. volatility can be used with the chow test to see if structural break are support by the data

examining volatility allows for a richer models to be considered
1. stochastic volatility models

Rolling window volatility
1. rolling window: compute volility over time and detect changes

rolling= portfolio_returns.rolling(30)
volatility = rolling.std().dropna()
vol_mean= volatility.resample("M").mean()

Extreme values

VaR,CVar finds the maximum loss for a particular confidence level

Visualize changes in maximum loss by plotting VaR

look at points in time where losses exceed some threshhold

example: VaR95 is maximum loss 95% of the time

losses should exceed the var95 threshhold 5% of the time

backtesting use previous data ex-post to see how risk estimate performs
1. used extensively in enterprise risk management

suppose we want to know daily loses that exceed 3%

Var95=0.03

around 5% of previous losses should exceed 3%
1. more than 5% distribution with wider (fatter) tails


>>>>>>>> volatility examining citi bank

# Find the time series of returns with and without Citibank
ret_with_citi = prices_with_citi.pct_change().dot(weights_with_citi)
ret_without_citi = prices_without_citi.pct_change().dot(weights_without_citi)

# Find the average 30-day rolling window volatility as the standard deviation
vol_with_citi = ret_with_citi.rolling(30).std().dropna().rename("With Citi")
vol_without_citi = ret_without_citi.rolling(30).std().dropna().rename("Without Citi")

# Combine two volatilities into one Pandas DataFrame
vol = pd.concat([vol_with_citi, vol_without_citi], axis=1)

# Plot volatilities over time
vol.plot().set_ylabel("Losses")
plt.show()


The visualizations show that Citibank's volatility alone was not responsible for the increase in portfolio volatility during the crisis.

>>>>>> 95% var - extreme values greater than var

# Compute the 95% VaR on 2009-2010 losses
VaR_95 = np.quantile(estimate_data, 0.95)

# Find backtest_data exceeding the 95% VaR
extreme_values = backtest_data[backtest_data > VaR_95]

# Compare the fraction of extreme values for 2007-2008 to the Var_95 estimate
print("VaR_95: ", VaR_95, "; Backtest: ", len(extreme_values) / len(backtest_data) )

# Plot the extreme values and look for clustering
plt.stem(extreme_values.index, extreme_values.values)
plt.ylabel("Extreme values > VaR_95"); plt.xlabel("Date")
plt.xticks(rotation=45)
plt.show()

 VaR_95:  0.04986983664383684 ; Backtest:  0.06547619047619048

Since the relative frequency of extreme events in 2007-2008 is higher than 5%, the estimate of the 95% VaR from 2009-2010 data is not robust across the possible structural break identified in the previous exercise



























