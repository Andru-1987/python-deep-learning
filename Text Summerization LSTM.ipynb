{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#https://medium.com/geekculture/neural-machine-translation-using-seq2seq-model-with-attention-9faea357d70b\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import optimizers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding,Flatten,Dropout, Dense, Concatenate, TimeDistributed, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer \n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from nltk.corpus import stopwords \n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tensorflow.keras.losses import sparse_categorical_crossentropy\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.python.keras.layers import Layer\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "\n",
    "class AttentionLayer(Layer):\n",
    "    \"\"\"\n",
    "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
    "    There are three sets of weights introduced W_a, U_a, and V_a\n",
    "     \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AttentionLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert isinstance(input_shape, list)\n",
    "        # Create a trainable weight variable for this layer.\n",
    "\n",
    "        self.W_a = self.add_weight(name='W_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.U_a = self.add_weight(name='U_a',\n",
    "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "        self.V_a = self.add_weight(name='V_a',\n",
    "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
    "                                   initializer='uniform',\n",
    "                                   trainable=True)\n",
    "\n",
    "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, inputs, verbose=False):\n",
    "        \"\"\"\n",
    "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
    "        \"\"\"\n",
    "        assert type(inputs) == list\n",
    "        encoder_out_seq, decoder_out_seq = inputs\n",
    "        if verbose:\n",
    "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
    "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
    "\n",
    "        def energy_step(inputs, states):\n",
    "            \"\"\" Step function for computing energy for a single decoder state\n",
    "            inputs: (batchsize * 1 * de_in_dim)\n",
    "            states: (batchsize * 1 * de_latent_dim)\n",
    "            \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
    "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
    "            de_hidden = inputs.shape[-1]\n",
    "\n",
    "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
    "            # <= batch size * en_seq_len * latent_dim\n",
    "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
    "\n",
    "            \"\"\" Computing hj.Ua \"\"\"\n",
    "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
    "            if verbose:\n",
    "                print('Ua.h>', U_a_dot_h.shape)\n",
    "\n",
    "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
    "            # <= batch_size*en_seq_len, latent_dim\n",
    "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
    "            if verbose:\n",
    "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
    "\n",
    "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
    "            # <= batch_size, en_seq_len\n",
    "            e_i = K.softmax(e_i)\n",
    "\n",
    "            if verbose:\n",
    "                print('ei>', e_i.shape)\n",
    "\n",
    "            return e_i, [e_i]\n",
    "\n",
    "        def context_step(inputs, states):\n",
    "            \"\"\" Step function for computing ci using ei \"\"\"\n",
    "\n",
    "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
    "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
    "\n",
    "            # <= batch_size, hidden_size\n",
    "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
    "            if verbose:\n",
    "                print('ci>', c_i.shape)\n",
    "            return c_i, [c_i]\n",
    "        \n",
    "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
    "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
    "\n",
    "        \"\"\" Computing energy outputs \"\"\"\n",
    "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
    "        last_out, e_outputs, _ = K.rnn(\n",
    "            energy_step, decoder_out_seq, [fake_state_e],\n",
    "        )\n",
    "        \"\"\" Computing context vectors \"\"\"\n",
    "        last_out, c_outputs, _ = K.rnn(\n",
    "            context_step, e_outputs, [fake_state_c],\n",
    "        )\n",
    "        print(c_outputs, e_outputs)\n",
    "\n",
    "        return c_outputs, e_outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        \"\"\" Outputs produced by the layer \"\"\"\n",
    "        return [\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
    "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
    "        ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n",
      "       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n",
      "      dtype='object')\n",
      "Review: I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most. \n",
      "\tSummary: Good Quality Dog Food \n",
      "\n",
      "Review: Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\". \n",
      "\tSummary: Not as Advertised \n",
      "\n",
      "Review: This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch. \n",
      "\tSummary: \"Delight\" says it all \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"Reviews.csv\",nrows=50)\n",
    "print(df.columns)\n",
    "df.drop_duplicates(subset=['Text'],inplace=True)  #dropping duplicates\\n\",\n",
    "df.dropna(axis=0,inplace=True)\n",
    " \n",
    "detail_sentences=[]\n",
    "summary_sentences=[]\n",
    "\n",
    "#print(max([len(x) for x in df['Text']]))\n",
    "#print(max([len(x) for x in df['Summary']]))\n",
    "for detail,summary in zip(df['Text'][:3],df['Summary'][:3]):\n",
    "    print(\"Review:\",detail,\"\\n\\tSummary:\",summary,\"\\n\")\n",
    "    \n",
    "\n",
    "for sent in df['Text']:\n",
    "    # Add sos and eos tokens using string.join\n",
    "    sent_new = \" \".join(['sos', sent, 'eos'])\n",
    "    detail_sentences.append(sent_new)\n",
    "\n",
    "for sent in df['Summary']:\n",
    "    # Add sos and eos tokens using string.join\n",
    "    sent_new = \" \".join(['sos', sent, 'eos'])\n",
    "    summary_sentences.append(sent_new)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1231 68\n"
     ]
    }
   ],
   "source": [
    "max_len_text= max([len(sentence) for sentence in detail_sentences])\n",
    "max_len_summary=max([len(sentence) for sentence in summary_sentences])\n",
    "latent_dim = 50 \n",
    "print(max_len_text,max_len_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(detail_sentences,summary_sentences,test_size=0.2,random_state=0,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "x_tokenizer = Tokenizer()\n",
    "x_tokenizer.fit_on_texts(list(X_train))\n",
    "\n",
    "#convert text sequences into integer sequences\n",
    "x_train    =   x_tokenizer.texts_to_sequences(X_train) \n",
    "x_test   =   x_tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "#print(x_tokenizer.sequences_to_texts(x_train))\n",
    "\n",
    "#padding zero upto maximum length\n",
    "x_train    =   pad_sequences(x_train,  maxlen=max_len_text, padding='post') \n",
    "x_test   =   pad_sequences(x_test, maxlen=max_len_text, padding='post')\n",
    "\n",
    "#reverse\n",
    "x_train=x_train[::-1]\n",
    "x_test=x_test[::-1]\n",
    "\n",
    "x_voc_size   =  len(x_tokenizer.word_index) +1\n",
    "\n",
    "#print(x_train)\n",
    "#print(x_tokenizer.sequences_to_texts(x_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(list(y_train))\n",
    "\n",
    "#convert summary sequences into integer sequences\n",
    "y_train    =   y_tokenizer.texts_to_sequences(y_train) \n",
    "y_test   =   y_tokenizer.texts_to_sequences(y_test) \n",
    "\n",
    "#padding zero upto maximum length\n",
    "y_train    =   pad_sequences(y_train, maxlen=max_len_summary, padding='post')\n",
    "y_test   =   pad_sequences(y_test, maxlen=max_len_summary, padding='post')\n",
    "\n",
    "#y_train=y_train[::-1]\n",
    "#y_test=y_test[::-1]\n",
    "\n",
    "y_voc_size  =   len(y_tokenizer.word_index) +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level = False)\n",
    "    x_tk.fit_on_texts(x)\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "\n",
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding = 'post')\n",
    "\n",
    "def preprocess_embedding(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "    # Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# [[[[[Encoder]]]]]\n",
    "latent_dim=256\n",
    "\n",
    "encoder_inputs = Input(shape=(max_len_text,)) \n",
    "enc_emb = Embedding(x_voc_size, 512)(encoder_inputs) \n",
    "#LSTM 1 \n",
    "encoder_lstm1 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True,name='lstm1')) \n",
    "encoder_output1,forw_state_h1,forw_state_c1, back_state_h1, back_state_c1 = encoder_lstm1(enc_emb) \n",
    "#LSTM 2 \n",
    "encoder_lstm2 = Bidirectional(LSTM(latent_dim,return_sequences=True,return_state=True,name='lstm2')) \n",
    "encoder_output2, forw_state_h2,forw_state_c2,back_state_h2, back_state_c2 = encoder_lstm2(encoder_output1) \n",
    "#LSTM 3 \n",
    "encoder_lstm3=Bidirectional(LSTM(latent_dim, return_state=True, return_sequences=True,name='lstm3')) \n",
    "encoder_outputs1,forw_state_h,forw_state_c, back_state_h, back_state_c= encoder_lstm3(encoder_output2) \n",
    "# Set up the [[[[[[[[decoder]]]]]]]]. \n",
    "\n",
    "#encoder_states = [state_h, state_c]\n",
    "\n",
    "final_enc_h = Concatenate()([forw_state_h,back_state_h])\n",
    "final_enc_c = Concatenate()([forw_state_c,back_state_c])\n",
    "\n",
    "#get context vector\n",
    "encoder_states = [final_enc_h,final_enc_c]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"attention_layer/transpose_5:0\", shape=(?, ?, 512), dtype=float32) Tensor(\"attention_layer/transpose_3:0\", shape=(?, ?, 1231), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1231)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 1231, 512)    366080      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 1231, 512),  1574912     embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) [(None, 1231, 512),  1574912     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) [(None, 1231, 512),  1574912     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 512)    52224       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           bidirectional_2[0][1]            \n",
      "                                                                 bidirectional_2[0][3]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 512)          0           bidirectional_2[0][2]            \n",
      "                                                                 bidirectional_2[0][4]            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, None, 512),  2099200     embedding_1[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AttentionLayer [(None, None, 512),  524800      bidirectional_2[0][0]            \n",
      "                                                                 lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 1024)   0           lstm[0][0]                       \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, None, 102)    104550      concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 7,871,590\n",
      "Trainable params: 7,871,590\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# decoder input and embedding\n",
    "\n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, 512) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "#LSTM using encoder_states as initial state\n",
    "decoder_lstm = LSTM(512, return_sequences=True, return_state=True) \n",
    "decoder_outputs,_,_ = decoder_lstm(dec_emb,initial_state=encoder_states) \n",
    "\n",
    "#[[attention layer]]\n",
    "attention_layer = AttentionLayer(name='attention_layer') \n",
    "attention_out, attention_weights = attention_layer([encoder_outputs1, decoder_outputs]) \n",
    "# Concat attention output and decoder LSTM output \n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attention_out])\n",
    "#Dense layer\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "decoder_outputs2 = decoder_dense(decoder_concat_input) \n",
    "\n",
    "# Define the model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs2) \n",
    "\n",
    "model.compile(loss = sparse_categorical_crossentropy, \n",
    "                 optimizer = 'rmsprop', \n",
    "                 metrics = ['acc'])\n",
    "    \n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "#https://github.com/thushv89/attention_keras/blob/master/src/examples/nmt_bidirectional/model.py\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='rmsprop', metrics=['acc'])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"give Your path to save check points\", monitor='val_accuracy')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5)\n",
    "callbacks_list = [checkpoint, early_stopping]\n",
    "\n",
    "encoder_input_data = x_train\n",
    "decoder_input_data = y_train[:,:-1]\n",
    "#decoder_target_data =  y_train[:,1:]\n",
    "#number of rows, sequence length, one step ahead not including sos\n",
    "decoder_target_data=y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:]\n",
    "#history=model.fit([x_train,y_train[:,:-1]], y_train.reshape(y_train.shape[0],y_train.shape[1], 1)[:,1:] ,epochs=50,batch_size=128)\n",
    "\n",
    "encoder_input_test = x_test\n",
    "decoder_input_test = y_test[:,:-1]\n",
    "decoder_target_test=  y_test[:,1:]\n",
    "\n",
    "history=model.fit([encoder_input_data ,decoder_input_data], decoder_target_data ,epochs=3,batch_size=128,callbacks=callbacks_list)\n",
    "\n",
    "#istory = model.fit([encoder_input_data, decoder_input_data],decoder_target_data, \n",
    "#                   epochs=epochs, \n",
    "#                   batch_size=128,\n",
    "#                   validation_data = ([encoder_input_test, decoder_input_test],decoder_target_test),\n",
    "#                   callbacks= callbacks_list)\n",
    "model.save_weights(\"lstm_model.h5\") # can give whole path to save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/geekculture/neural-machine-translation-using-seq2seq-model-with-attention-9faea357d70b\n",
    "#https://data-flair.training/blogs/machine-learning-text-summarization/\n",
    "model.load_weights(\"lstm_model.h5\")\n",
    "\n",
    "#[[[[[[[INFERENCE MODEL]]]]]]]\n",
    "# encoder Inference model\n",
    "#encoder_model = Model(encoder_inputs, outputs = [encoder_outputs1, final_enc_h, final_enc_c])\n",
    "#encoder_model = Model(encoder_inputs,encoder_states)\n",
    "\n",
    "en_outputs,state_h_enc,state_c_enc=model.layers[6].ouput\n",
    "\n",
    "en_states=[state_h_enc,state_c_enc]\n",
    "\n",
    "encoder_model = Model(model.input[0],[en_outputs]+en_states)\n",
    "\n",
    "# Decoder Inference\n",
    "decoder_state_h = Input(shape=(512,)) # This numbers has to be same as units of lstm's on which model is trained\n",
    "decoder_state_c = Input(shape=(512,))\n",
    "\n",
    "# we need hidden state for attention layer\n",
    "decoder_hidden_state_input = Input(shape=(max_len_text,512)) \n",
    "# get decoder states\n",
    "#decoder_states_inputs = [decoder_state_h, decoder_state_c]\n",
    "\n",
    "decoder_inputs=model.input[1]\n",
    "decoder_emb_layer=model.layers[5]\n",
    "decoder_lstm=model.layers[7]\n",
    "decoder_embedding=decoder_emb_layer(decoder_inputs)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2=dec(decoder_embedding,initial_state=[decoder_state_h,decoder_state_c])\n",
    "\n",
    "# embedding layer \n",
    "#dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "#decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
    "\n",
    "attention=model.layers[8]\n",
    "attn_out2=attend([decoder_outputs2,decoder_hidden_state_input])\n",
    "merge2=Concatenate(axis=-1)([decoder_outputs2,att_out2])\n",
    "# Attention inference\n",
    "#attention_result_inf, attention_weights_inf = attention_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "#decoder_concat_input_inf = Concatenate(axis=-1, name='concat_layer')([decoder_outputs2, attention_result_inf])\n",
    "\n",
    "decoder_dense=model.layers[10]\n",
    "decoder_output2=decoder_dense(merge2)\n",
    "#decoder_states2= [state_h2, state_c2]\n",
    "#decoder_outputs2 = decoder_dense(decoder_concat_input_inf)\n",
    "\n",
    "# get decoder model\n",
    "decoder_model= Model(\n",
    "                    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_h, decoder_state_c],\n",
    "                     [decoder_outputs2]+ decoder_states2)\n",
    "\n",
    "#decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2)\n",
    "\n",
    "print(decoder_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_index=y_tokenizer.index_word\n",
    "source_word_index=x_tokenizer.index_word\n",
    "source_index_word=x_tokenizer.word_index\n",
    "target_word_index=y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence=[\"\"\"sos Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\" eos\"\"\"]\n",
    "\n",
    "input_sentence    =   x_tokenizer.texts_to_sequences(sentence) \n",
    "input_sentence_seq    =   pad_sequences(input_sentence,  maxlen=max_len_text, padding='post') \n",
    "\n",
    "\n",
    "#print(max_len_text)\n",
    "#for i in input_sentence_seq:\n",
    "#    print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predicted_sentence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    enc_output, enc_h, enc_c = encoder_model.predict(input_seq)\n",
    "  \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1,1))\n",
    "    \n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0] = source_index_word['sos']\n",
    "    \n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    count=0\n",
    "    while not stop_condition:\n",
    "        count+=1\n",
    "        if count>1000:\n",
    "            print('count exceeded')\n",
    "            stop_condition=True\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [enc_output, enc_h, enc_c ])\n",
    "        #print(output_tokens)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        if sampled_token_index in target_word_index:\n",
    "            sampled_char = target_word_index[sampled_token_index]\n",
    "            decoded_sentence += ' '+sampled_char\n",
    "            print(decoded_sentence)\n",
    "        \n",
    "            if (sampled_char == 'eos' or len(decoded_sentence.split()) >= 512):\n",
    "                stop_condition = True\n",
    "        \n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        # Update states\n",
    "        enc_h, enc_c = h, c\n",
    "    \n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(input_sentence_seq)\n",
    "#print(x_test[0])\n",
    "#sentence=get_predicted_sentence(input_sentence_seq.reshape(1,max_len_text))[:-4]\n",
    "sentence=get_predicted_sentence(input_sentence_seq)\n",
    "print(\"done\",sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
