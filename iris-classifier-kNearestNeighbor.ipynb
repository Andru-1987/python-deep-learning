{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n",
      "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])\n",
      "features type:<class 'numpy.ndarray'>\n",
      "target type:<class 'numpy.ndarray'>\n",
      "(150, 4)\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0                5.1               3.5                1.4               0.2\n",
      "1                4.9               3.0                1.4               0.2\n",
      "2                4.7               3.2                1.3               0.2\n",
      "3                4.6               3.1                1.5               0.2\n",
      "4                5.0               3.6                1.4               0.2\n",
      "[1 1 0]\n",
      "      0    1    2    3  prediction\n",
      "0   6.9  3.1  5.1  2.3           2\n",
      "1   6.0  3.0  4.8  1.8           2\n",
      "2   6.4  2.8  5.6  2.1           2\n",
      "3   7.4  2.8  6.1  1.9           2\n",
      "4   6.6  2.9  4.6  1.3           1\n",
      "5   5.0  3.2  1.2  0.2           0\n",
      "6   6.7  3.1  4.4  1.4           1\n",
      "7   5.4  3.7  1.5  0.2           0\n",
      "8   4.9  3.1  1.5  0.1           0\n",
      "9   6.9  3.1  4.9  1.5           1\n",
      "10  5.5  3.5  1.3  0.2           0\n",
      "11  6.7  3.3  5.7  2.1           2\n",
      "12  5.7  4.4  1.5  0.4           0\n",
      "13  6.0  2.7  5.1  1.6           2\n",
      "14  7.2  3.6  6.1  2.5           2\n",
      "15  4.4  2.9  1.4  0.2           0\n",
      "16  4.9  3.1  1.5  0.2           0\n",
      "17  5.4  3.4  1.7  0.2           0\n",
      "18  5.7  2.8  4.1  1.3           1\n",
      "19  5.1  3.4  1.5  0.2           0\n",
      "20  6.7  3.0  5.2  2.3           2\n",
      "21  7.2  3.2  6.0  1.8           2\n",
      "22  6.3  2.9  5.6  1.8           2\n",
      "23  4.8  3.0  1.4  0.1           0\n",
      "24  6.0  2.9  4.5  1.5           1\n",
      "25  5.7  2.8  4.5  1.3           1\n",
      "26  5.5  2.4  3.8  1.1           1\n",
      "27  5.7  3.8  1.7  0.3           0\n",
      "28  5.4  3.9  1.7  0.4           0\n",
      "29  5.6  2.9  3.6  1.3           1\n",
      "30  7.7  3.0  6.1  2.3           2\n",
      "31  6.8  3.2  5.9  2.3           2\n",
      "32  4.4  3.0  1.3  0.2           0\n",
      "33  5.0  3.6  1.4  0.2           0\n",
      "34  7.0  3.2  4.7  1.4           1\n",
      "35  6.5  3.0  5.5  1.8           2\n",
      "36  5.9  3.0  5.1  1.8           2\n",
      "37  6.4  2.9  4.3  1.3           1\n",
      "38  4.9  2.4  3.3  1.0           1\n",
      "39  6.5  3.2  5.1  2.0           2\n",
      "40  6.6  3.0  4.4  1.4           1\n",
      "41  5.5  2.6  4.4  1.2           1\n",
      "42  4.5  2.3  1.3  0.3           0\n",
      "43  5.8  2.7  5.1  1.9           2\n",
      "44  5.5  2.5  4.0  1.3           1\n",
      "[[6.9, 3.1, 5.1, 2.3, 2.0], [6.0, 3.0, 4.8, 1.8, 2.0], [6.4, 2.8, 5.6, 2.1, 2.0], [7.4, 2.8, 6.1, 1.9, 2.0], [6.6, 2.9, 4.6, 1.3, 1.0], [5.0, 3.2, 1.2, 0.2, 0.0], [6.7, 3.1, 4.4, 1.4, 1.0], [5.4, 3.7, 1.5, 0.2, 0.0], [4.9, 3.1, 1.5, 0.1, 0.0], [6.9, 3.1, 4.9, 1.5, 1.0], [5.5, 3.5, 1.3, 0.2, 0.0], [6.7, 3.3, 5.7, 2.1, 2.0], [5.7, 4.4, 1.5, 0.4, 0.0], [6.0, 2.7, 5.1, 1.6, 2.0], [7.2, 3.6, 6.1, 2.5, 2.0], [4.4, 2.9, 1.4, 0.2, 0.0], [4.9, 3.1, 1.5, 0.2, 0.0], [5.4, 3.4, 1.7, 0.2, 0.0], [5.7, 2.8, 4.1, 1.3, 1.0], [5.1, 3.4, 1.5, 0.2, 0.0], [6.7, 3.0, 5.2, 2.3, 2.0], [7.2, 3.2, 6.0, 1.8, 2.0], [6.3, 2.9, 5.6, 1.8, 2.0], [4.8, 3.0, 1.4, 0.1, 0.0], [6.0, 2.9, 4.5, 1.5, 1.0], [5.7, 2.8, 4.5, 1.3, 1.0], [5.5, 2.4, 3.8, 1.1, 1.0], [5.7, 3.8, 1.7, 0.3, 0.0], [5.4, 3.9, 1.7, 0.4, 0.0], [5.6, 2.9, 3.6, 1.3, 1.0], [7.7, 3.0, 6.1, 2.3, 2.0], [6.8, 3.2, 5.9, 2.3, 2.0], [4.4, 3.0, 1.3, 0.2, 0.0], [5.0, 3.6, 1.4, 0.2, 0.0], [7.0, 3.2, 4.7, 1.4, 1.0], [6.5, 3.0, 5.5, 1.8, 2.0], [5.9, 3.0, 5.1, 1.8, 2.0], [6.4, 2.9, 4.3, 1.3, 1.0], [4.9, 2.4, 3.3, 1.0, 1.0], [6.5, 3.2, 5.1, 2.0, 2.0], [6.6, 3.0, 4.4, 1.4, 1.0], [5.5, 2.6, 4.4, 1.2, 1.0], [4.5, 2.3, 1.3, 0.3, 0.0], [5.8, 2.7, 5.1, 1.9, 2.0], [5.5, 2.5, 4.0, 1.3, 1.0]]\n",
      "score:0.9777777777777777\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#features: petal length, petal width, sepal length, sepal width\n",
    "#target species: versicolor, virginica, setsoa\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "iris=load_iris()\n",
    "\n",
    "#bunch lets you use a python dict like an object\n",
    "print(type(iris))\n",
    "print(iris.keys())\n",
    "\n",
    "#feature and target are numpy arrays\n",
    "print('features type:' + str(type(iris.data)))\n",
    "print('target type:' + str(type(iris.target)))\n",
    "print(iris.data.shape)\n",
    "\n",
    "X=iris.data\n",
    "y=iris.target\n",
    "\n",
    "df=pd.DataFrame(X,columns=iris.feature_names)\n",
    "print(df.head(5))\n",
    "\n",
    "#df.info()\n",
    "#df.describe()\n",
    "#pd.plotting.scatter_matrix(df,c=y)\n",
    "\n",
    "knn=KNeighborsClassifier(algorithm='auto',\n",
    "                         leaf_size=30,\n",
    "                         metric='minkowski',\n",
    "                         metric_params=None,\n",
    "                         n_jobs=1,\n",
    "                         n_neighbors=5,\n",
    "                         p=2,\n",
    "                         weights='uniform')\n",
    "\n",
    "knn.fit(iris['data'],iris['target'])\n",
    "\n",
    "#print(iris['data'])\n",
    "#print(iris['target'])\n",
    "\n",
    "X_new=np.array([[5.6,2.8,3.9,1.1],[5.7,2.6,3.8,1.3],[4.7,3.2,1.3,0.2]])\n",
    "prediction=knn.predict(X_new);\n",
    "print(prediction)\n",
    "\n",
    "#random_state seeds the random generator.  Returns 4 arrays. stratify is assigned the label target\n",
    "X_train, X_test, y_train, y_test= train_test_split(X,y,test_size=0.3, random_state=21, stratify=y)\n",
    "\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "output=pd.DataFrame(X_test)\n",
    "output['prediction']=y_pred\n",
    "print(output)\n",
    "\n",
    "list=output.values.tolist()\n",
    "print(list)\n",
    "\n",
    "\n",
    "#print(X_test)\n",
    "#print(y_pred)\n",
    "print(\"score:\"+str(knn.score(X_test,y_test)))\n",
    "\n",
    "\n",
    "neighbors = np.arange(1, 9)\n",
    "train_accuracy = np.empty(len(neighbors))\n",
    "test_accuracy = np.empty(len(neighbors))\n",
    "\n",
    "\n",
    "for index, k in enumerate(neighbors):\n",
    "    knn = KNeighborsClassifier(algorithm='auto',\n",
    "                         leaf_size=30,\n",
    "                         metric='minkowski',\n",
    "                         metric_params=None,\n",
    "                         n_jobs=1,\n",
    "                         n_neighbors=k,\n",
    "                         p=2,\n",
    "                         weights='uniform')\n",
    "    # Fit the classifier to the training data\n",
    "    knn.fit(X_train,y_train)\n",
    "    train_accuracy[index] = knn.score(X_train, y_train)\n",
    "\n",
    "    #Compute accuracy on the testing set\n",
    "    test_accuracy[index] = knn.score(X_test, y_test)    \n",
    "    \n",
    "plt.title('k-NN: Varying Number of Neighbors')\n",
    "plt.plot(neighbors, test_accuracy, label = 'Testing Accuracy')\n",
    "plt.plot(neighbors, train_accuracy, label = 'Training Accuracy')\n",
    "plt.legend()\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23  0  0]\n",
      " [ 0 19  0]\n",
      " [ 0  1 17]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       0.95      1.00      0.97        19\n",
      "           2       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.98      0.98      0.98        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(algorithm='auto',\n",
    "                         leaf_size=30,\n",
    "                         metric='minkowski',\n",
    "                         metric_params=None,\n",
    "                         n_jobs=1,\n",
    "                         n_neighbors=8,\n",
    "                         p=2,\n",
    "                         weights='uniform')\n",
    "\n",
    "#print(X)\n",
    "#print(y)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.4,random_state=42)\n",
    "knn.fit(X_train,y_train)\n",
    "y_pred=knn.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[0.96666667 1.         0.93333333 0.96666667 1.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnishimoto.BOISE\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:947: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.metrics import roc_curve\n",
    "#from sklearn.model_selection import cross_val_score\n",
    "\n",
    "logreg=LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='auto', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.4, random_state=42)\n",
    "\n",
    "logreg.fit(X_train,y_train)\n",
    "\n",
    "y_pred=logreg.predict(X_test)\n",
    "my_score=logreg.score(X_test,y_test)\n",
    "print(my_score)\n",
    "\n",
    "y_pred_prob=logreg.predict_proba(X_test)[:,1]\n",
    "#roc_auc_score(y_test,y_pred_prob)\n",
    "cv_scores=cross_val_score(logreg,X,y,cv=5)\n",
    "print(cv_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
