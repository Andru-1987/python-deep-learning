

# Print the information of ride_sharing
print(ride_sharing.info())

# Print summary statistics of user_type column
print(ride_sharing['user_type'].describe())


>>Sample

# Print the information of ride_sharing
print(ride_sharing.info())

# Print summary statistics of user_type column
print(ride_sharing['user_type'].describe())

# Convert user_type from integer to category
ride_sharing['user_type_cat'] = ride_sharing['user_type'].astype('category')

# Write an assert statement confirming the change
assert ride_sharing['user_type_cat'].dtype == 'category'

# Print new summary statistics 
print(ride_sharing['user_type_cat'].describe())

print(ride_sharing['user_type_cat'])

>>Sample

# Strip duration of minutes
ride_sharing['duration_trim'] = ride_sharing['duration'].str.strip('minutes') 

# Convert duration to integer
ride_sharing['duration_time'] = ride_sharing['duration_trim'].astype('int')

# Write an assert statement making sure of conversion
assert ride_sharing['duration_time'].dtype == 'int'

# Print formed columns and calculate average ride duration 
print(ride_sharing[['duration','duration_trim','duration_time']])
print(ride_sharing['duration_time'].mean())


>>>Data range constraints


import matplotlib.pyplot as plt
plt.hist(movies['avg_rating'])
plt.title('Average rating of movies (1-5)')

or signups in the future

import datetime as dt
today_date=dt.date.today()
user_signups[user_signups['subscription_date']> today_date]

>>>dealing with out of range data
1. drop the data
2. set custom minimums and maximums
3. treat a s missing and impute
4. Set custom value depending on business assumptions


>>> dropping data

movies.drop(movies[movies['avg_rating']>5].index, inplace=True)

assert movies['avg_rating'].max()<=5

>> Setting to a hard limit

movie.loc[movies['avg_rating']>5, 'avg rating']=5


user_signups.dtypes

ouput: subscription_date object

user_signups['subscription_date']= pd.to_datetime(user_signups['subscription_date'])

assert user_signups['subscriptions_date'].dtype == 'datetime64[ns]'

today_date=dt.date.today()

assert user_signups.subscription_date.max().date() <= today_date


>>>Sample  >>> convert to categorical

# Convert tire_sizes to integer
ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('int')

# Set all values above 27 to 27
ride_sharing.loc[ride_sharing.tire_sizes > 27,'tire_sizes'] = 27

# Reconvert tire_sizes back to categorical
ride_sharing['tire_sizes'] = ride_sharing['tire_sizes'].astype('category')

print(ride_sharing['tire_sizes'])
# Print tire size description
print(ride_sharing['tire_sizes'].describe())

>>>Sample  >>> convert to datetime

# Convert ride_date to datetime
ride_sharing['ride_dt'] = pd.to_datetime(ride_sharing['ride_date'])

# Save today's date
today = dt.date.today()

# Set all in the future to today's date
ride_sharing.loc[ride_sharing['ride_dt'] > today, 'ride_dt'] = today

# Print maximum of ride_dt column
print(ride_sharing['ride_dt'].max())



>>Sample

#Correct! Subsetting on metadata and keeping all duplicate records gives you a better bird-eye's view over your data and how to duplicate it!


# Find duplicates
duplicates = ride_sharing.duplicated('ride_id', keep=False)
print(duplicates)

# Sort your duplicated rides
duplicated_rides = ride_sharing[duplicates].sort_values('ride_id')

# Print relevant columns of duplicated_rides
print(duplicated_rides[['ride_id','duration','user_birth_year']])

>>Sample dropping duplicates

# Drop complete duplicates from ride_sharing
ride_dup = ride_sharing.drop_duplicates()

# Create statistics dictionary for aggregation function
statistics = {'user_birth_year': 'min', 'duration': 'mean'}

# Group by ride_id and compute new statistics
ride_unique = ride_dup.groupby('ride_id').agg(statistics).reset_index()

# Find duplicated values again
duplicates = ride_unique.duplicated(subset = 'ride_id', keep = False)
duplicated_rides = ride_unique[duplicates == True]

# Assert duplicates are processed
assert duplicated_rides.shape[0] == 0









 


