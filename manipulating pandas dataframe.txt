>>Indexing DataFrames


month 	eggs 	salt	spam
jan   	47	12	17
feb	110	50	31
mar	221	89	72
apr	77	87	20
may	132	nan	52
jun	205	60	55

import pandas as pd

df= pd.read_csv('sales.csv', index_col='month')

df['salt']['Jan']
12

df.eggs['Mar']
221


>>accessors
.loc and .iloc

df.loc['May','spam']
df.iloc[4,2]
52


df_new=df['salt','eggs']]

returns two columns of data where the column order has been swapped.

>>Sample

print(election.head())
# Assign the row position of election.loc['Bedford']: x
x = 4

# Assign the column position of election['winner']: y
y = 4

# Print the boolean equivalence
print(election.iloc[x, y] == election.loc['Bedford', 'winner'])


>>Sample

# Import pandas
import pandas as pd

# Read in filename and set the index: election
election = pd.read_csv(filename, index_col='county')

# Create a separate dataframe with the columns ['winner', 'total', 'voters']: results
results = election[['winner', 'total', 'voters']]

# Print the output of results.head()
print(results.head())

>>>slicing data
1. a series is a one dimensional array

df['eggs']

type(df['eggs'])
pandas.core.series.Series

df['eggs'][1:4]
110
221
77
rows 2 through 4 (exclude the last row)

df['eggs'][4] (include the last row) or the fifth row
132

df.loc[:, 'eggs':'salt'] #all rows and some columns


df.loc['Jan':'Apr',:] #some rows and all columns

df.loc['Mar':'May','salt':'spam']
df.iloc[2:5,1:]  #not including row 5


df.loc['Jan':'May',['eggs','spam']]
df.iloc[[0,4,5],0:2] #not including index=2 column

df[['eggs']] #returns a dataframe
whereas df['eggs'] #returns a data series


>>>>Sample


state   total      Obama     Romney  winner  voters
county                                                       
Adams        PA   41973  35.482334  63.112001  Romney   61156
Allegheny    PA  614671  56.640219  42.185820   Obama  924351
Armstrong    PA   28322  30.696985  67.901278  Romney   42147
Beaver       PA   80015  46.032619  52.637630  Romney  115157
Bedford      PA   21444  22.057452  76.986570  Romney   32189

print(election.head())

# Slice the columns from the starting column to 'Obama': left_columns
left_columns = election.loc[:,:'Obama']

# Print the output of left_columns.head()
print(left_columns.head())

# Slice the columns from 'Obama' to 'winner': middle_columns
middle_columns = election.loc[:,'Obama':'winner']

# Print the output of middle_columns.head()
print(middle_columns.head())

# Slice the columns from 'Romney' to the end: 'right_columns'
right_columns = election.loc[:,'Romney':]

# Print the output of right_columns.head()
print(right_columns.head())

>>>Sample

# Create the list of row labels: rows
rows = ['Philadelphia', 'Centre', 'Fulton']

# Create the list of column labels: cols
cols = ['winner', 'Obama', 'Romney']

# Create the new DataFrame: three_counties
three_counties = election.loc[rows,cols]

# Print the three_counties DataFrame
print(three_counties)

>>>Filtering DataFrames
1. filtering is a boolean series

df.salt>60


df[df.salt>60]

or

enough_salt_sold=df.salt>60

df[enough_salt_sold]

df[(df.salt>=50)&(df.eggs<200) ] #both condition

df[(df.salt>=50)|(df.eggs<200) ] #or condition

>>>>DataFrames with zeros and nans

df2= df.copy(
df2['bacon'] = [0,0,50,60.70,80]
df2

df2.loc[:,df2.all()]  #which columns have all non zero values

df2.loc[:, df2.any()] #which columns hav any non zero entries

df.loc[:, df.isnull().any()] #which columns have any nan

df.loc[:, df.notnull().all()] #which columns have no nan

df.dropna(how='any')  #drop all rows with nan

>>Filtering a column based on another 

df.eggs[df.salt>55]   #show the eggs where the salt is greater than 55

>>Modifying a column based on another

df.eggs[df.salt > 55] += 5


>>Sample

print(election.info())

# Create the boolean array: high_turnout
high_turnout = election.turnout>70

print

# Filter the election DataFrame with the high_turnout array: high_turnout_df
high_turnout_df = election[high_turnout]

# Print the high_turnout_results DataFrame
print(high_turnout_df)

>>>Sample

print(election.info())

# Create the boolean array: high_turnout
high_turnout = election.turnout>70


# Filter the election DataFrame with the high_turnout array: high_turnout_df
high_turnout_df = election[high_turnout]

# Print the high_turnout_results DataFrame
print(high_turnout_df)

>>>Sample titantic clearn

# Select the 'age' and 'cabin' columns: df
df = titanic.loc[:,['age','cabin']]

print(df.head())

# Print the shape of df
print(df.shape)

# Drop rows in df with how='any' and print the shape
print(df.dropna(how='any').shape)

# Drop rows in df with how='all' and print the shape
print(df.dropna(how='all').shape)

print(df.head)

# Drop columns in titanic with less than 1000 non-missing values
print(titanic.dropna(thresh=1000, axis='columns').info())

>>>Transforming Dataframes

DataFrame vectorized methods

df.floordiv(12)  #search every element in the data frame for the filtered value less than 12

np.floor_divid(df,12) #no loops

or
def dozens(n):
	return n//12

df.apply(dozens)

or

df.apply(lamdda n: n//12)

>>>>Storing a tranformation

df['dozens_of_eggs']=df.eggs.floordiv(12)

>>>The DataFrame Index

df.index  # produce a series of strings

df.index= df.index.str.upper()

or

df.index=df.index.map(str.lower)

>>>Defining columns using other columns

df['salty_eggs']=df.salt+df.dozen_of_eggs

>>>Sample

# Write a function to convert degrees Fahrenheit to degrees Celsius: to_celsius
def to_celsius(F):
    return 5/9*(F - 32)

# Apply the function over 'Mean TemperatureF' and 'Mean Dew PointF': df_celsius
df_celsius = weather[['Mean TemperatureF','Mean Dew PointF']].apply(to_celsius)

# Reassign the column labels of df_celsius
df_celsius.columns = ['Mean TemperatureC', 'Mean Dew PointC']

# Print the output of df_celsius.head()
print(df_celsius.head())


>>Sample

# Create the dictionary: red_vs_blue
red_vs_blue = {'Obama':'blue','Romney':'Red'}

# Use the dictionary to map the 'winner' column to the new column: election['color']
election['color'] = election['winner'].map(red_vs_blue)


# Print the output of election.head()
print(election.head())

>>Using vectorized functions

When performance is paramount, you should avoid using .apply() and .map() because those constructs perform Python for-loops over the data stored in a pandas Series or DataFrame. By using vectorized functions instead, you can loop over the data at the same speed as compiled code (C, Fortran, etc.)! NumPy, SciPy and pandas come with a variety of vectorized functions (called Universal Functions or UFuncs in NumPy).

You can even write your own vectorized functions, but for now we will focus on the ones distributed by NumPy and pandas.

In this exercise you're going to import the zscore function from scipy.stats and use it to compute the deviation in voter turnout in Pennsylvania from the mean in fractions of the standard deviation. In statistics, the z-score is the number of standard deviations by which an observation is above the mean - so if it is negative, it means the observation is below the mean.

Instead of using .apply() as you did in the earlier exercises, the zscore UFunc will take a pandas Series as input and return a NumPy array. You will then assign the values of the NumPy array to a new column in the DataFrame. You will be working with the election DataFrame - it has been pre-loaded for you.


>>>Sample

# Imporimport scipy.stats from zscore
from scipy.stats import zscore

# Call zscore with election['turnout'] as input: turnout_zscore
turnout_zscore = zscore(election['turnout'])

# Print the type of turnout_zscore
print(type(turnout_zscore))

# Assign turnout_zscore to a new column: election['turnout_zscore']
election['turnout_zscore']=turnout_zscore

# Print the output of election.head()
print(election.head())

>>DataFrames structures

#series, indexes, dataframes

index as immutable
slice indexes

df.index=zip


read_csv(filename,index_col=zip)































