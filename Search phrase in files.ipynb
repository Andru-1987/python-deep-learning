{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mC:\\Users\\dnishimoto\\python_files\\python_notes\\hyperparameters.txt\n",
      "\u001b[30m\n",
      "C:\\Users\\dnishimoto\\python_files\\python_notes\\hyperparameters.txt\n",
      "deeper understanding of the model\n",
      "\n",
      "30,000 users and 24 attributes\n",
      "\n",
      "log_reg_clf=LogisticRegression()\n",
      "log_reg_clf.fit(X_train,y_train)\n",
      "print(log_reg_clf.coef_)\n",
      "\n",
      "original_variables=list(X_train.columns)\n",
      "\n",
      "zipped_together=list(zip(original_variables,log_reg_clf.coef_[0]))\n",
      "coefs = [list(x) for x in zipped_together]\n",
      "\n",
      "coefs=pd.DataFrame(coefs, columns=['Variable','Coefficient'])\n",
      "\n",
      "print(coefs)\n",
      "\n",
      "coefs.sort_values(by=['Coefficient'], axis=0, inplace=True, ascending=False)\n",
      "\n",
      "Pay variable are how many months people have delayed their payments\n",
      "\n",
      "need to know how the classifier works\n",
      "\n",
      "Random forest has no coefficients\n",
      "\n",
      "rf_clf = RandomForestClassifier(max_depth=2)\n",
      "rf_clf.fit(X_train,y_train)\n",
      "\n",
      "chosen_tree=rf_clf.estimators_[7]\n",
      "\n",
      "split_column=chosen_tree.tree_.feature[1]\n",
      "split_column_name=X_train.columns[split_column]\n",
      "split_value=chosen_tree.tree_.threshold[1]\n",
      "print(split_column_name,split_value)\n",
      "\n",
      "\n",
      "       >sample    find the top 3 variables by coefficient values\n",
      "\n",
      "# Create a list of original variable names from the training DataFrame\n",
      "original_variables = X_train.columns\n",
      "\n",
      "# Extract the coefficients of the logistic regression estimator\n",
      "print(log_reg_clf.coef_)\n",
      "model_coefficients = log_reg_clf.coef_[0]\n",
      "\n",
      "# Create a dataframe of the variables and coefficients & print it out\n",
      "coefficient_df = pd.DataFrame({\"Variable\" : original_variables, \"Coefficient\": model_coefficients})\n",
      "print(coefficient_df)\n",
      "\n",
      "# Print out the top 3 positive variables\n",
      "top_three_df = coefficient_df.sort_values(by='Coefficient', axis=0, ascending=False)[0:3]\n",
      "print(top_three_df)\n",
      "\n",
      "\n",
      "    >  sample  > grab a node on the decision tree\n",
      "\n",
      "# Extract the 7th (index 6) tree from the random forest\n",
      "chosen_tree = rf_clf.estimators_[7]\n",
      "\n",
      "# Visualize the graph using the provided image\n",
      "imgplot = plt.imshow(tree_viz_image)\n",
      "plt.show()\n",
      "\n",
      "# Extract the parameters and level of the top (index 0) node\n",
      "split_column = chosen_tree.tree_.feature[0]\n",
      "split_column_name = X_train.columns[split_column]\n",
      "split_value = chosen_tree.tree_.threshold[0]\n",
      "\n",
      "# Print out the feature and level\n",
      "print(\"This node split on feature {}, at a value of {}\".format(split_column_name, split_value))\n",
      "\n",
      "output: This node split on feature LIMIT_BAL, at a value of 115000.0\n",
      "\n",
      "if\n",
      "chosen_tree = rf_clf.estimators_[6]\n",
      "\n",
      "This node split on feature PAY_AMT5, at a value of 1677.5\n",
      "\n",
      "        Hyper parameter overview\n",
      "\n",
      "RandomForestClassifier\n",
      "n_estimators (number of trees in the forest)\n",
      "criterion='entropy'\n",
      "\n",
      "important parameters:\n",
      "n_estimators (high values)\n",
      "max_features (how many features to consider before splitting)\n",
      "max_depth & min_sample_leaf (important to reduce overfitting)\n",
      "criterion (maybe)\n",
      "\n",
      "lr=LogisticRegression()\n",
      "C=1.0\n",
      "class_weight=None\n",
      "duel=False\n",
      "fit_intercept=True\n",
      "intercept_scaling=1\n",
      "max_iter=100,\n",
      "multi_class='warn'\n",
      "n_jobs=None\n",
      "penlty='l2'\n",
      "random_state=None\n",
      "solver='warn'\n",
      "tot=0.0001\n",
      "verbose=0\n",
      "warm_start=False\n",
      "\n",
      "\n",
      " >sample    increase the \n",
      "\n",
      "# Print out the old estimator, notice which hyperparameter is badly set\n",
      "print(rf_clf_old)\n",
      "\n",
      "# Get confusion matrix & accuracy for the old rf_model\n",
      "print(\"Confusion Matrix: \\n\\n {} \\n Accuracy Score: \\n\\n {}\".format(\n",
      "  \tconfusion_matrix(y_test, rf_old_predictions),  \n",
      "  \taccuracy_score(y_test, rf_old_predictions)))\n",
      "\n",
      "# Create a new random forest classifier with better hyperparamaters\n",
      "rf_clf_new = RandomForestClassifier(n_estimators=500)\n",
      "\n",
      "# Fit this to the data and obtain predictions\n",
      "rf_new_predictions = rf_clf_new.fit(X_train, y_train).predict(X_test)\n",
      "\n",
      "# Assess the new model (using new predictions!)\n",
      "print(\"Confusion Matrix: \\n\\n\", confusion_matrix(y_test, rf_new_predictions))\n",
      "print(\"Accuracy Score: \\n\\n\", accuracy_score(y_test, rf_new_predictions))\n",
      "\n",
      "\n",
      "   sample  > k nearest neighbor\n",
      "\n",
      "# Build a knn estimator for each value of n_neighbours\n",
      "knn_5 = KNeighborsClassifier(n_neighbors=5)\n",
      "knn_10 = KNeighborsClassifier(n_neighbors=10)\n",
      "knn_20 = KNeighborsClassifier(n_neighbors=20)\n",
      "\n",
      "# Fit each to the training data & produce predictions\n",
      "knn_5_predictions = knn_5.fit(X_train,y_train).predict(X_test)\n",
      "knn_10_predictions = knn_10.fit(X_train,y_train).predict(X_test)\n",
      "knn_20_predictions = knn_20.fit(X_train,y_train).predict(X_test)\n",
      "\n",
      "# Get an accuracy score for each of the models\n",
      "knn_5_accuracy = accuracy_score(y_test, knn_5_predictions)\n",
      "knn_10_accuracy = accuracy_score(y_test, knn_10_predictions)\n",
      "knn_20_accuracy = accuracy_score(y_test, knn_20_predictions)\n",
      "print(\"The accuracy of 5, 10, 20 neighbours was {}, {}, {}\".format(knn_5_accuracy, knn_10_accuracy, knn_20_accuracy))\n",
      "\n",
      "\n",
      "        Automating hyperparameters\n",
      "\n",
      "LogisticRegression\n",
      "\n",
      "some values of the parameter solver conflict with the penalty parameter\n",
      "\n",
      "\n",
      "neighbors_list=[3,5,10,20,50,75]\n",
      "\n",
      "for test_number in neighbors_list:\n",
      "\tmodel=KNeighborsClassifier(n_neighbors=test_number)\n",
      "\tpredictions=model.fit(X_train,y_train).predict(X_test)\n",
      "\taccuracy=accuracy_score(y_test,predictions)\n",
      "\taccuracy_list.append(accuracy)\n",
      "\n",
      "\n",
      "results_df=pd.DataFrame({neighbors':neighbors_list, 'accuracy':accuracy_list})\n",
      "\n",
      "    >Learning curve\n",
      "\n",
      "plt.(results_df['neighbors'],results_df['accuracy'])\n",
      "\n",
      "plt.gca().set(xlabel='n_neighbors', ylabel='Accuracy',title='Accuracy for different n_neighbors')\n",
      "\n",
      "plt.show()\n",
      "\n",
      "np.linspace(start,end, number of items)\n",
      "\n",
      "np.linspace(1,2,5)\n",
      "\n",
      "[1 1.25 1.5 1.75 2]\n",
      "\n",
      "  >sample  Gradient boost classifier    different learning rates\n",
      "\n",
      "# Set the learning rates & results storage\n",
      "learning_rates = [0.001, 0.01, 0.05, 0.1, 0.2, 0.5]\n",
      "results_list = []\n",
      "\n",
      "# Create the for loop to evaluate model predictions for each learning rate\n",
      "for learning_rate in learning_rates:\n",
      "    model = GradientBoostingClassifier(learning_rate=learning_rate)\n",
      "    predictions = model.fit(X_train,y_train).predict(X_test)\n",
      "    # Save the learning rate and accuracy score\n",
      "    results_list.append([learning_rate, accuracy_score(y_test, predictions)])\n",
      "\n",
      "# Gather everything into a DataFrame\n",
      "results_df = pd.DataFrame(results_list, columns=['learning_rate', 'accuracy'])\n",
      "print(results_df)\n",
      "\n",
      "output:\n",
      "learning_rate  accuracy\n",
      "0          0.001    0.7825\n",
      "1          0.010    0.8025\n",
      "2          0.050    0.8100\n",
      "3          0.100    0.7975\n",
      "4          0.200    0.7900\n",
      "5          0.500    0.7775\n",
      "\n",
      "\n",
      "  > sample  > plot the learning curve\n",
      "\n",
      "# Set the learning rates & accuracies list\n",
      "learn_rates = np.linspace(0.01, 2, num=30)\n",
      "accuracies = []\n",
      "\n",
      "# Create the for loop\n",
      "for learn_rate in learn_rates:\n",
      "  \t# Create the model, predictions & save the accuracies as before\n",
      "    model = GradientBoostingClassifier(learning_rate=learn_rate)\n",
      "    predictions = model.fit(X_train,y_train).predict(X_test)\n",
      "    accuracies.append(accuracy_score(y_test, predictions))\n",
      "\n",
      "# Plot results    \n",
      "plt.plot(learn_rates, accuracies)\n",
      "plt.gca().set(xlabel='learning_rate', ylabel='Accuracy', title='Accuracy for different learning_rates')\n",
      "plt.show()\n",
      "\n",
      "      Introducing Grid Search     >\n",
      "\n",
      "learn_rate_list=[0.001,0.01,0.1,0.2,0.3,0.4,0.5]\n",
      "max_depth_list=[4,6,8,10,12,15,20,25,30]\n",
      "subsample_list=[0.4,0.6,0.7,0.8,0.9]\n",
      "max_features_list=['auto','sqrt']\n",
      "\n",
      "  Sample gradient boost grid search\n",
      "\n",
      "# Create the function\n",
      "def gbm_grid_search(learn_rate, max_depth):\n",
      "\n",
      "\t# Create the model\n",
      "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth)\n",
      "    \n",
      "    # Use the model to make predictions\n",
      "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
      "    \n",
      "    # Return the hyperparameters and score\n",
      "    return([learn_rate, max_depth, accuracy_score(y_test, predictions)])\n",
      "\n",
      "\n",
      "# Create the relevant lists\n",
      "results_list = []\n",
      "learn_rate_list = [0.01, 0.1, 0.5]\n",
      "max_depth_list = [2, 4, 6]\n",
      "\n",
      "# Create the for loop\n",
      "for learn_rate in learn_rate_list:\n",
      "    for max_depth in max_depth_list:\n",
      "        results_list.append(gbm_grid_search(learn_rate,max_depth))\n",
      "\n",
      "# Print the results\n",
      "print(results_list) \n",
      "\n",
      "output:\n",
      "[[0.01, 2, 0.78], [0.01, 4, 0.78], [0.01, 6, 0.76], [0.1, 2, 0.74], [0.1, 4, 0.76], [0.1, 6, 0.75], [0.5, 2, 0.73], [0.5, 4, 0.74], [0.5, 6, 0.74]]\n",
      "\n",
      "\n",
      "  sample  add subsample parameter\n",
      "\n",
      "results_list = []\n",
      "learn_rate_list = [0.01, 0.1, 0.5]\n",
      "max_depth_list = [2,4,6]\n",
      "\n",
      "# Extend the function input\n",
      "def gbm_grid_search_extended(learn_rate, max_depth, subsample):\n",
      "\n",
      "\t# Extend the model creation section\n",
      "    model = GradientBoostingClassifier(learning_rate=learn_rate, max_depth=max_depth, subsample=subsample)\n",
      "    \n",
      "    predictions = model.fit(X_train, y_train).predict(X_test)\n",
      "    \n",
      "    # Extend the return part\n",
      "    return([learn_rate, max_depth, subsample, accuracy_score(y_test, predictions)])   \n",
      "\n",
      "\n",
      "results_list = []\n",
      "\n",
      "# Create the new list to test\n",
      "subsample_list =  [0.4 , 0.6]\n",
      "\n",
      "for learn_rate in learn_rate_list:\n",
      "    for max_depth in max_depth_list:\n",
      "    \n",
      "    \t# Extend the for loop\n",
      "        for subsample in subsample_list:\n",
      "        \t\n",
      "            # Extend the results to include the new hyperparameter\n",
      "            results_list.append(gbm_grid_search_extended(learn_rate, max_depth, subsample))\n",
      "            \n",
      "# Print results\n",
      "print(results_list)     \n",
      "\n",
      "output:\n",
      "[[0.01, 2, 0.4, 0.73], [0.01, 2, 0.6, 0.74], [0.01, 4, 0.4, 0.73], [0.01, 4, 0.6, 0.75], [0.01, 6, 0.4, 0.72], [0.01, 6, 0.6, 0.78], [0.1, 2, 0.4, 0.74], [0.1, 2, 0.6, 0.74], [0.1, 4, 0.4, 0.73], [0.1, 4, 0.6, 0.73], [0.1, 6, 0.4, 0.74], [0.1, 6, 0.6, 0.76], [0.5, 2, 0.4, 0.64], [0.5, 2, 0.6, 0.67], [0.5, 4, 0.4, 0.72], [0.5, 4, 0.6, 0.71], [0.5, 6, 0.4, 0.63], [0.5, 6, 0.6, 0.64]]\n",
      "\n",
      "\n",
      "      >Grid Search       \n",
      "\n",
      "Steps\n",
      "1. select an estimator\n",
      "2. select parameters to tune\n",
      "3. define parameter ranges\n",
      "4. setup a scoring scheme to see which model is best\n",
      "\n",
      "GridSearchCV\n",
      "inputs:\n",
      "1. estimator\n",
      "2. param_grid (dictionary of lists)\n",
      "3. cv\n",
      "4. scoring\n",
      "5. refit\n",
      "6. n_jobs\n",
      "7. return_train_score\n",
      "\n",
      "\n",
      "from sklearn import metrics\n",
      "print(sorted(metrics.SCORERS.keys()))\n",
      "\n",
      "['accuracy', 'adjusted_mutual_info_score', 'adjusted_rand_score', 'average_precision', 'balanced_accuracy', 'completeness_score', 'explained_variance', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'fowlkes_mallows_score', 'homogeneity_score', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted', 'max_error', 'mutual_info_score', 'neg_brier_score', 'neg_log_loss', 'neg_mean_absolute_error', 'neg_mean_gamma_deviance', 'neg_mean_poisson_deviance', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_median_absolute_error', 'neg_root_mean_squared_error', 'normalized_mutual_info_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'r2', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'roc_auc', 'roc_auc_ovo', 'roc_auc_ovo_weighted', 'roc_auc_ovr', 'roc_auc_ovr_weighted', 'v_measure_score']\n",
      "\n",
      "\n",
      "refit=true  (the gridsearchcv uses the best model for the fit so you don't need to train another model with the parameters)\n",
      "\n",
      "import os\n",
      "print(os.cpu_count())\n",
      "\n",
      "4 cores\n",
      "\n",
      "return_train_score\n",
      "\n",
      "1. logs statistics about the training runs\n",
      "\n",
      "parameter_grid={'max_depth':[2,4,6,8],'min_samples_leaf':[1,2,4,6]}\n",
      "\n",
      "rf_class= RandomForestClassifier(criterion='entropy', max_features='auto')\n",
      "\n",
      "\n",
      "grid_rf_class=GridSearchCV(\n",
      "    estimator=rf_clf,\n",
      "    param_grid=parameter_grid,\n",
      "    scoring='accuracy',\n",
      "    n_jobs=4,\n",
      "    cv=10,\n",
      "    refit=True,\n",
      "    return_train_score=True)\n",
      "\n",
      "\n",
      "   sample GridSearchCV\n",
      "\n",
      "# Create a Random Forest Classifier with specified criterion\n",
      "rf_class = RandomForestClassifier(criterion='entropy')\n",
      "\n",
      "# Create the parameter grid\n",
      "param_grid = {'max_depth': [2, 4, 8, 15], 'max_features': ['auto', 'sqrt']} \n",
      "\n",
      "# Create a GridSearchCV object\n",
      "grid_rf_class = GridSearchCV(\n",
      "    estimator=rf_class,\n",
      "    param_grid=param_grid,\n",
      "    scoring='roc_auc',\n",
      "    n_jobs=4,\n",
      "    cv=5,\n",
      "    refit=True, return_train_score=True)\n",
      "print(grid_rf_class)\n",
      "\n",
      "\n",
      "     >Understanding grid search output\n",
      "\n",
      "cv_results_\n",
      "best_index_\n",
      "best_params_\n",
      "best_score_\n",
      "\n",
      "Extra information\n",
      "scorer_\n",
      "n_splits_\n",
      "refit_time_\n",
      "\n",
      "cv_results_df=pd.DataFrame(grid_df_class.cv_results_)\n",
      "\n",
      "pd.set_option(\"display.max_colwidth\",-1)\n",
      "\n",
      "\n",
      "['mean_fit_time', \n",
      "'std_fit_time', \n",
      "'mean_score_time', \n",
      "'std_score_time',\n",
      "'param_max_depth', \n",
      "'param_min_samples_leaf', \n",
      "'params',\n",
      "'split0_test_score', \n",
      "'split1_test_score', \n",
      "'split2_test_score',\n",
      "'split3_test_score', \n",
      "'split4_test_score', \n",
      "'mean_test_score',\n",
      "'std_test_score', \n",
      "'rank_test_score', \n",
      "'split0_train_score',\n",
      "'split1_train_score', \n",
      "'split2_train_score', \n",
      "'split3_train_score',\n",
      "'split4_train_score', \n",
      "'mean_train_score', \n",
      "'std_train_score']\n",
      "\n",
      "\n",
      "print(cv_results_df.loc[:,\"params\"])\n",
      "\n",
      "cv_results_df=pd.DataFrame(grid_rf_class.cv_results_)\n",
      "\n",
      "best_row=cv_results_df[cv_results_df[\"rank_test_score\"]==1]\n",
      "\n",
      "print(best_row)\n",
      "\n",
      "\n",
      "the test_score columns are repeated for the training_scores\n",
      "\n",
      "\n",
      "print(type(grid_rf_class.best_estimator_))\n",
      "\n",
      "print(grid_rf_class.best_estimator_)\n",
      "\n",
      "\n",
      "   sample      best row\n",
      "\n",
      "# Read the cv_results property into a dataframe & print it out\n",
      "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
      "print(cv_results_df)\n",
      "\n",
      "# Extract and print the column with a dictionary of hyperparameters used\n",
      "column = cv_results_df.loc[:, ['params']]\n",
      "print(column)\n",
      "\n",
      "# Extract and print the row that had the best mean test score\n",
      "best_row = cv_results_df[cv_results_df['rank_test_score'] == 1 ]\n",
      "print(best_row)\n",
      "\n",
      "\n",
      "best_row=cv_results_df[cv_results_df[\"rank_test_score\"]==1]\n",
      "\n",
      "print(best_row.columns)\n",
      "print(best_row[['param_max_depth', 'param_min_samples_leaf']])\n",
      "\n",
      "or \n",
      "\n",
      "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
      "print(best_row[['param_max_depth', 'param_min_samples_leaf']])\n",
      "\n",
      "\n",
      "# Print out the ROC_AUC score from the best-performing square\n",
      "best_score = grid_rf_class.best_score_\n",
      "print(best_score)\n",
      "\n",
      "# Create a variable from the row related to the best-performing square\n",
      "cv_results_df = pd.DataFrame(grid_rf_class.cv_results_)\n",
      "best_row = cv_results_df.loc[[grid_rf_class.best_index_]]\n",
      "print(best_row)\n",
      "\n",
      "# Get the n_estimators parameter from the best-performing square and print\n",
      "best_n_estimators = grid_rf_class.best_params_[\"n_estimators\"]\n",
      "print(best_n_estimators)\n",
      "\n",
      "\n",
      "   > sample   > best_estimator_\n",
      "\n",
      "# See what type of object the best_estimator_ property is\n",
      "print(type(grid_rf_class.best_estimator_))\n",
      "\n",
      "# Create an array of predictions directly using the best_estimator_ property\n",
      "predictions = grid_rf_class.best_estimator_.predict(X_test)\n",
      "\n",
      "# Take a look to confirm it worked, this should be an array of 1's and 0's\n",
      "print(predictions[0:5])\n",
      "\n",
      "# Now create a confusion matrix \n",
      "print(\"Confusion Matrix \\n\", confusion_matrix(y_test, predictions))\n",
      "\n",
      "# Get the ROC-AUC score\n",
      "predictions_proba = grid_rf_class.best_estimator_.predict_proba(X_test)[:,1]\n",
      "print(\"ROC-AUC Score \\n\", roc_auc_score(y_test, predictions_proba))\n",
      "\n",
      "\n",
      "          Random Search        \n",
      "\n",
      "not every hyperparameter is as important\n",
      "probability\n",
      "\n",
      "\n",
      "100 squares\n",
      "we have 5 squares with the best performance\n",
      "then hitting a best square is 5 out 100\n",
      "or 0.05\n",
      "\n",
      "We have a 1-0.05^n chance to missing everything\n",
      "\n",
      "a hit would be (1-(1-0.05)**n)\n",
      "\n",
      "1-(1-0.05)**n)>0.95 gives n>=59\n",
      "\n",
      "\n",
      "how to create a random sample grid manually\n",
      "\n",
      "learn_rate_list=np.linspace(0.001,2,150)\n",
      "min_samples_left_list=list(range(1,51))\n",
      "\n",
      "#builds a cross product between the learning rate and the min sample leaf values\n",
      "\n",
      "for itertools import product\n",
      "combination_list=[list(x) for x in\n",
      "\tproduct(learn_rate_list, min_sample_leaf_list)]\n",
      "\n",
      "#select 100 models from our larger set\n",
      "\n",
      "random_combination_index= np.random.choice(\n",
      "\trange(0,len(combination_list)),100,\n",
      "\treplace=False)\n",
      "\n",
      "combination_random_chosen=[combinations_list[x] for x in random_combinations_index]\n",
      "\n",
      "\n",
      "  >sample  > how to random select different learning rate and min sample combinations\n",
      "\n",
      "# Create a list of values for the learning_rate hyperparameter\n",
      "learn_rate_list = list(np.linspace(0.01,1.5,200))\n",
      "\n",
      "# Create a list of values for the min_samples_leaf hyperparameter\n",
      "min_samples_list = list(range(10,41))\n",
      "\n",
      "# Combination list\n",
      "combinations_list = [list(x) for x in product(learn_rate_list, min_samples_list)]\n",
      "\n",
      "# Sample hyperparameter combinations for a random search.\n",
      "random_combinations_index = np.random.choice(range(0, len(combinations_list)), 250, replace=False)\n",
      "combinations_random_chosen = [combinations_list[x] for x in random_combinations_index]\n",
      "\n",
      "# Print the result\n",
      "print(combinations_random_chosen)\n",
      "\n",
      "\n",
      "   sample    > manually create a random combination choice between three features\n",
      "\n",
      "\n",
      "# Create lists for criterion and max_features\n",
      "criterion_list = ['gini','entropy']\n",
      "max_feature_list = ['auto','sqrt','Log2',None]\n",
      "\n",
      "# Create a list of values for the max_depth hyperparameter\n",
      "max_depth_list = list(range(3,56))\n",
      "\n",
      "# Combination list\n",
      "combinations_list = [list(x) for x in product(criterion_list,max_feature_list,max_depth_list)]\n",
      "\n",
      "# Sample hyperparameter combinations for a random search\n",
      "combinations_random_chosen = random.sample(combination_list, 150)\n",
      "\n",
      "# Print the result\n",
      "print(combinations_random_chosen)\n",
      "\n",
      "\n",
      "    sample\n",
      "\n",
      "# Confirm how many hyperparameter combinations & print\n",
      "number_combs = len(combinations_list)\n",
      "print(number_combs)\n",
      "\n",
      "# Sample and visualise specified combinations\n",
      "for x in [50, 500, 1500]:\n",
      "    sample_and_visualize_hyperparameters(x)\n",
      "    \n",
      "# Sample all the hyperparameter combinations & visualise\n",
      "sample_and_visualize_hyperparameters(number_combs)\n",
      "\n",
      "\n",
      "         >Random Search CV\n",
      "\n",
      "\n",
      "RandonSearchCV\n",
      "inputs:\n",
      "1. estimator\n",
      "2. param_distributions (how to sample)\n",
      "3. fit_params\n",
      "4. cv\n",
      "5. scoring\n",
      "6. n_jobs\n",
      "7. return_train_score\n",
      "8. pre_dispatch\n",
      "9. verbose\n",
      "10. random_state\n",
      "11. n_iter (number of samples for the random search to take from your grid)\n",
      "\n",
      "\n",
      "learn_rate_list=np.linspace(0.001,2,150)\n",
      "min_samples_leaf_list=list(range(1,51))\n",
      "\n",
      "parameter_grid={\n",
      "\t'learning_rate':learn_rate_list,\n",
      "\t'min_samples_leaf': min_samples_leaf_list\n",
      "}\n",
      "\n",
      "number_models=10\n",
      "random_GBM_class=RandomizedSearchCV(\n",
      "\testimator=GradientBoostingClassifier(),\n",
      "\tparam_distributions=parameter_grid,\n",
      "\tn_iter=number_models,\n",
      "\tscoring='accuracy',\n",
      "\tn_jobs=4,\n",
      "\tcv=10,\n",
      "\trefit=True,\n",
      "\treturn_train_score=True)\n",
      "\n",
      "random_GBM_class.fit(X_train,y_train)\n",
      "predictions=random_GBM_class.predict(X_test)\n",
      "\n",
      "print(accuracy_score(y_test,predictions));\n",
      "print(grid_rf_class.best_params_)\n",
      "print(grid_rf_class.best_score_)\n",
      "\n",
      "rand_x = list(random_GBM_class.cv_results_['param_learning_rate'])\n",
      "rand_y = list(random_GBM_class.cv_results_['param_min_samples_leaf'])\n",
      "\n",
      "x_lims=[np.min(learn_rate_list), np.max(learn_rate_list)]\n",
      "y_lims=[np.min(min_samples_leaf_list), np.max(min_samples_leaf_list)]\n",
      "\n",
      "plt.scatter(rand_y,rand_x,c=['blue']*10)\n",
      "plt.gca().set(xlabel='learn_rate', ylabel='min_sample_leaf', title='Random Search Hyperparameters')\n",
      "plt.show()\n",
      "\n",
      "\n",
      "  > sample     randomSearchCV()   gradientboostclassifier\n",
      "\n",
      "\n",
      "# Create the parameter grid\n",
      "param_grid = {'learning_rate': np.linspace(.1,2,150), 'min_samples_leaf': list(range(20,65))} \n",
      "\n",
      "# Create a random search object\n",
      "random_GBM_class = RandomizedSearchCV(\n",
      "    estimator = GradientBoostingClassifier(),\n",
      "    param_distributions= param_grid,\n",
      "    n_iter = 10,\n",
      "    scoring='accuracy', n_jobs=4, cv = 5, refit=True, return_train_score = True)\n",
      "\n",
      "# Fit to the training data\n",
      "random_GBM_class.fit(X_train, y_train)\n",
      "\n",
      "# Print the values used for both hyperparameters\n",
      "print(random_GBM_class.cv_results_['param_learning_rate'])\n",
      "print(random_GBM_class.cv_results_['param_min_samples_leaf'])\n",
      "\n",
      "\n",
      "    sample random SEarch CV   randomforestclassifier \n",
      "\n",
      "# Create the parameter grid\n",
      "param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto' , 'sqrt']} \n",
      "\n",
      "# Create a random search object\n",
      "random_rf_class = RandomizedSearchCV(\n",
      "    estimator = RandomForestClassifier (n_estimators=80),\n",
      "    param_distributions = param_grid, n_iter = 5, return_train_score = True )\n",
      "\n",
      "# Fit to the training data\n",
      "random_rf_class.fit(X_train, y_train)\n",
      "\n",
      "# Print the values used for both hyperparameters\n",
      "print(random_rf_class.cv_results_['param_max_depth'])\n",
      "print(random_rf_class.cv_results_['param_max_features'])\n",
      "\n",
      "  > sample  > randomSearchCV()    randomForestClassifier\n",
      "\n",
      "# Create the parameter grid\n",
      "param_grid = {'max_depth': list(range(5,26)), 'max_features': ['auto' , 'sqrt']} \n",
      "\n",
      "# Create a random search object\n",
      "random_rf_class = RandomizedSearchCV(\n",
      "    estimator = RandomForestClassifier(n_estimators=80),\n",
      "    param_distributions = param_grid, n_iter = 5,\n",
      "    scoring='roc_auc', n_jobs=4, cv = 3, refit=True, return_train_score = True)\n",
      "\n",
      "# Fit to the training data\n",
      "random_rf_class.fit(X_train, y_train)\n",
      "\n",
      "# Print the values used for both hyperparameters\n",
      "print(random_rf_class.cv_results_['param_max_depth'])\n",
      "print(random_rf_class.cv_results_['param_max_features'])\n",
      "\n",
      "\n",
      "        >Comparing Grid and Random search\n",
      "\n",
      " > sample\n",
      "\n",
      "\n",
      "# Sample grid coordinates\n",
      "grid_combinations_chosen = combinations_list[0:300]\n",
      "\n",
      "# Create a list of sample indexes\n",
      "sample_indexes = list(range(0,len(combinations_list)))\n",
      "\n",
      "# Randomly sample 300 indexes\n",
      "random_indexes = np.random.choice(sample_indexes, 300, replace=False)\n",
      "\n",
      "# Use indexes to create random sample\n",
      "random_combinations_chosen = [combinations_list[index] for index in random_indexes ]\n",
      "\n",
      "# Call the function to produce the visualization\n",
      "visualize_search(grid_combinations_chosen, random_combinations_chosen)\n",
      "\n",
      "\n",
      "    >Informed Search   Coarse to fine\n",
      "\n",
      "Learn while the hyperparameter is searching\n",
      "One model -> Measure -> Learn\n",
      "\n",
      "Process:\n",
      "1. Start with a random search\n",
      "2. Find Promising areas\n",
      "3. Undertake a grid search in the smaller area\n",
      "4. Continue the process until an optimal score is obtained or the area has become to small\n",
      "\n",
      "\n",
      "max_depth_list between 1 and 65\n",
      "min_sample_list between 3 and 17\n",
      "learn_rate_list 150 value between 0.01 and 150\n",
      "\n",
      "combinations_list=[list(x) from x in product(max_depth_list, min_sample_list, learn_rate_list)]\n",
      "\n",
      "print(len(combinations_list))\n",
      "\n",
      "output: 134400\n",
      "\n",
      "max_depth better between 8 and 30\n",
      "min_samples_leaf better below 8\n",
      "visualize coarse to fine using max_depth and accuracy scoring\n",
      "\n",
      "\n",
      "others are learn rate (worst above 1.3\n",
      "\n",
      "\n",
      " >sample   > max_depth, min_samples_leaf, learn rate\n",
      "\n",
      "1000 samples\n",
      "\n",
      "# Confirm the size of the combinations_list\n",
      "print(len(combinations_list))\n",
      "\n",
      "print(results_df.columns)\n",
      "# Sort the results_df by accuracy and print the top 10 rows\n",
      "print(results_df.sort_values(by='accuracy', ascending=False).head(10))\n",
      "\n",
      "# Confirm which hyperparameters were used in this search\n",
      "print(results_df.columns)\n",
      "\n",
      "# Call visualize_hyperparameter() with each hyperparameter in turn\n",
      "visualize_hyperparameter('max_depth')\n",
      "visualize_hyperparameter('min_samples_leaf')\n",
      "visualize_hyperparameter('learn_rate')\n",
      "\n",
      "   sample     max depth and learn rate\n",
      "\n",
      "# Create some combinations lists & combine\n",
      "max_depth_list = list(range(1, 20))\n",
      "learn_rate_list = np.linspace(0.001, 1, 50)\n",
      "\n",
      "                      >Bayesian Statistics\n",
      "\n",
      "bayes rule:\n",
      "\n",
      "1. iteratively update our beliefs about some outcome\n",
      "\n",
      "\n",
      "P(A|B) = P(B|A)P(A)/P(B)\n",
      "\n",
      "LHS= the probability of A, given B has occurred.  B is some evidence.\n",
      "\n",
      "P(A) is the prior. The initial hypothesis about the event.  It is different to P(A|B), the P(A|B) is the probability given new evidence.\n",
      "\n",
      "P(B) is the marginal likelihood and it is the probability of observing this new evidence.\n",
      "\n",
      "\n",
      "P(B|A) is the likelihood which the probability of observing the evidence, given the event we care about\n",
      "\n",
      "\n",
      "5% of people in the general population have a certain disease P(D)\n",
      "\n",
      "10% of people are predisposed\n",
      "\n",
      "      >Hyperopt\n",
      "\n",
      "process:\n",
      "1. set the domain of our grid\n",
      "2. set the optimization algorithm\n",
      "3. objective function to minimize\n",
      "\n",
      "\n",
      "space={\n",
      "\t'max_depth':hp.quniform('max_depth,2,10,2),\n",
      "\t'min_samples_lear': hp.quniform('min_samples_leaf',2,8,2),\n",
      "\t'learning_rate': hp.uniform('learning_rate',0.01,1,55)\n",
      "}\n",
      "\n",
      "quniform means quantified or percentiled by the 3rd number\n",
      "\n",
      "def objective(params):\n",
      "\tparams={'max_depth': int(params['max_depth']),\n",
      "\t'min_samples_leaf': int(params['min_samples_leaf']),\n",
      "\t'learning_rate': params['learning_rate']}\n",
      "\tgbm_clf=GradientBoostingClassifier(n_estimators=500,**params)\n",
      "\tbest_score=cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=10, n_jobs=2).mean()\n",
      "\n",
      "loss=1-best_score\n",
      "return loss\n",
      "\n",
      "\n",
      "        sample closing out accounts\n",
      "\n",
      "7% (0.07) of people are likely to close their account next month\n",
      "15% (0.15) of people with accounts are unhappy with your product (you don't know who though!)\n",
      "35% (0.35) of people who are likely to close their account are unhappy with your product\n",
      "\n",
      "# Assign probabilities to variables \n",
      "p_unhappy = 0.15\n",
      "p_unhappy_close = 0.35\n",
      "\n",
      "# Probabiliy someone will close\n",
      "p_close = 0.07\n",
      "\n",
      "# Probability unhappy person will close\n",
      "p_close_unhappy = (p_unhappy_close * p_close) / p_unhappy\n",
      "\n",
      "print(p_close_unhappy)\n",
      "\n",
      "output:\n",
      "0.16333333333333336\n",
      "\n",
      "\n",
      "There's a 16.3% chance that a customer, given that they are unhappy, will close their account.\n",
      "\n",
      "\n",
      "   sample    hyper opt\n",
      "\n",
      "# Set up space dictionary with specified hyperparameters\n",
      "space = {'max_depth': hp.quniform('max_depth',2,10,2),'learning_rate': hp.uniform('learning_rate',0.001,0.9)}\n",
      "\n",
      "# Set up objective function\n",
      "def objective(params):\n",
      "    params = {'max_depth': int(params['max_depth']),'learning_rate': params['learning_rate']}\n",
      "    gbm_clf = GradientBoostingClassifier(n_estimators=100, **params) \n",
      "    best_score = cross_val_score(gbm_clf, X_train, y_train, scoring='accuracy', cv=2, n_jobs=4).mean()\n",
      "    loss = 1 - best_score\n",
      "    return loss\n",
      "\n",
      "# Run the algorithm\n",
      "best = fmin(fn=objective,space=space, max_evals=20, rstate=np.random.RandomState(42), algo=tpe.suggest)\n",
      "print(best)\n",
      "\n",
      "output:\n",
      "\n",
      "0%|          | 0/20 [00:00<?, ?it/s, best loss: ?]\n",
      "  5%|5         | 1/20 [00:00<00:04,  4.68it/s, best loss: 0.26759418985474637]\n",
      " 10%|#         | 2/20 [00:00<00:03,  4.63it/s, best loss: 0.2549063726593165] \n",
      " 15%|#5        | 3/20 [00:00<00:03,  4.83it/s, best loss: 0.2549063726593165]\n",
      " 20%|##        | 4/20 [00:00<00:03,  5.07it/s, best loss: 0.2549063726593165]\n",
      " 25%|##5       | 5/20 [00:01<00:03,  3.84it/s, best loss: 0.2549063726593165]\n",
      " 30%|###       | 6/20 [00:01<00:03,  3.96it/s, best loss: 0.2549063726593165]\n",
      " 35%|###5      | 7/20 [00:01<00:02,  4.39it/s, best loss: 0.2549063726593165]\n",
      " 40%|####      | 8/20 [00:01<00:02,  4.62it/s, best loss: 0.2549063726593165]\n",
      " 45%|####5     | 9/20 [00:01<00:02,  4.91it/s, best loss: 0.2549063726593165]\n",
      " 50%|#####     | 10/20 [00:02<00:01,  5.20it/s, best loss: 0.2549063726593165]\n",
      " 55%|#####5    | 11/20 [00:02<00:01,  5.42it/s, best loss: 0.2549063726593165]\n",
      " 60%|######    | 12/20 [00:02<00:01,  5.04it/s, best loss: 0.2549063726593165]\n",
      " 65%|######5   | 13/20 [00:02<00:01,  4.40it/s, best loss: 0.2549063726593165]\n",
      " 70%|#######   | 14/20 [00:03<00:02,  2.78it/s, best loss: 0.2525688142203555]\n",
      " 75%|#######5  | 15/20 [00:03<00:01,  3.30it/s, best loss: 0.2525688142203555]\n",
      " 80%|########  | 16/20 [00:03<00:01,  3.63it/s, best loss: 0.2525688142203555]\n",
      " 85%|########5 | 17/20 [00:04<00:01,  2.72it/s, best loss: 0.24246856171404285]\n",
      " 90%|######### | 18/20 [00:04<00:00,  3.18it/s, best loss: 0.24246856171404285]\n",
      " 95%|#########5| 19/20 [00:04<00:00,  3.57it/s, best loss: 0.24246856171404285]\n",
      "100%|##########| 20/20 [00:05<00:00,  3.87it/s, best loss: 0.24246856171404285]\n",
      "100%|##########| 20/20 [00:05<00:00,  3.95it/s, best loss: 0.24246856171404285]\n",
      "{'learning_rate': 0.11310589268581149, 'max_depth': 6.0}\n",
      "\n",
      "\n",
      "    Informed Search Genetic algorithms\n",
      "\n",
      "genetics:\n",
      "1. surviving creatures exist\n",
      "2. strong creatures survive\n",
      "3. crossover occurrs with offspring\n",
      "4. there are random mutations\n",
      "\n",
      "hypertuning:\n",
      "1. create some models\n",
      "2. pick the best by scoring function\n",
      "a. these are the ones to survive\n",
      "3. create new models \n",
      "4. has some advantage of randomness\n",
      "\n",
      "        >TPOT\n",
      "\n",
      "TPOT is a python automated machine learning tool.\n",
      "\n",
      "\n",
      "generations: iterations to run training\n",
      "population_size: the number of models to keep after each iteration\n",
      "offspring_size: number of models to produce in each iteration\n",
      "mutation_rate: the proportion of pipelines to apply randomness\n",
      "crossover_rate: the proportion of pipelines to breed each iteration\n",
      "scoring: the function to determine the best models\n",
      "cv: cross-validation strategy to use\n",
      "\n",
      "from tpot import TPOTClassifier\n",
      "\n",
      "tpot=TPOTClassifier(generations=3, population_size=5, verbosity=2, offspring_size=10, scoring='accuracy', cv=5)\n",
      "\n",
      "tpot.fit(X_train,y_train)\n",
      "\n",
      "print(tpot.score(X_test,y_test))\n",
      "\n",
      "\n",
      "      sample    tpotclassifier\n",
      "\n",
      "# Assign the values outlined to the inputs\n",
      "number_generations = 3\n",
      "population_size = 4\n",
      "offspring_size = 3\n",
      "scoring_function = 'accuracy'\n",
      "\n",
      "# Create the tpot classifier\n",
      "tpot_clf = TPOTClassifier(generations=number_generations, population_size=population_size,\n",
      "                          offspring_size=offspring_size, scoring=scoring_function,\n",
      "                          verbosity=2, random_state=2, cv=2)\n",
      "\n",
      "# Fit the classifier to the training data\n",
      "tpot_clf.fit(X_train,y_train)\n",
      "\n",
      "# Score on the test set\n",
      "print(tpot_clf.score(X_test, y_test))\n",
      "\n",
      "output:\n",
      "Best pipeline: BernoulliNB(input_matrix, alpha=0.1, fit_prior=True)\n",
      "0.76\n",
      "\n",
      "Nice work! You can see in the output the score produced by the chosen model (in this case a version of Naive Bayes) over each generation, and then the final accuracy score with the hyperparameters chosen for the final model. This is a great first example of using TPOT for automated hyperparameter tuning. You can now extend on this on your own and build great machine learning models!\n",
      "\n",
      "  >sample  decisiontreeclassifier\n",
      "\n",
      "# Create the tpot classifier \n",
      "tpot_clf = TPOTClassifier(generations=2, population_size=4, offspring_size=3, scoring='accuracy', cv=2,\n",
      "                          verbosity=2, random_state=42)\n",
      "\n",
      "# Fit the classifier to the training data\n",
      "tpot_clf.fit(X_train, y_train)\n",
      "\n",
      "# Score on the test set\n",
      "print(tpot_clf.score(X_test, y_test))\n",
      "\n",
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n",
      "Generation 1 - Current best internal CV score: 0.7675066876671917\n",
      "Generation 2 - Current best internal CV score: 0.7675066876671917\n",
      "\n",
      "Best pipeline: KNeighborsClassifier(MaxAbsScaler(input_matrix), n_neighbors=57, p=1, weights=distance)\n",
      "0.75\n",
      "\n",
      "\n",
      "Randomstate=122\n",
      "\n",
      "\n",
      "Warning: xgboost.XGBClassifier is not available and will not be used by TPOT.\n",
      "Generation 1 - Current best internal CV score: 0.8075326883172079\n",
      "Generation 2 - Current best internal CV score: 0.8075326883172079\n",
      "\n",
      "random_state=99\n",
      "\n",
      "Best pipeline: RandomForestClassifier(SelectFwe(input_matrix, alpha=0.033), bootstrap=False, criterion=gini, max_features=1.0, min_samples_leaf=19, min_samples_split=10, n_estimators=100)\n",
      "0.78\n",
      "\n",
      "\n",
      "You can see that TPOT is quite unstable when only running with low generations, population size and offspring. The first model chosen was a Decision Tree, then a K-nearest Neighbor model and finally a Random Forest. Increasing the generations, population size and offspring and running this for a long time will assist to produce better models and more stable results. Don't hesitate to try it yourself on your own machine!\n",
      "\n",
      "\n",
      "Best pipeline: MLPClassifier(PCA(LogisticRegression(SelectPercentile(input_matrix, percentile=37), C=20.0, dual=False, penalty=l2), iterated_power=1, svd_solver=randomized), alpha=0.1, learning_rate_init=0.001)\n",
      "0.8207777777777778\n",
      "\u001b[31mC:\\Users\\dnishimoto\\python_files\\python_notes\\logistic and linear regression.txt\n",
      "\u001b[30m\n",
      "C:\\Users\\dnishimoto\\python_files\\python_notes\\logistic and linear regression.txt\n",
      "  Linear Regression\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import sklearn.dataset\n",
      "\n",
      "reg=LinearRegression()\n",
      "reg.fit(X_rooms,y)\n",
      "prediction_space=np.linspace(min(X_rooms),max(X_rooms)).reshape(-1,1)\n",
      "plt.scatter(X_rooms,y)\n",
      "#X_train, X_test,y_train,y_test=train_test_split(X_rooms,y,test_size=0.3,random_state=42)\n",
      "plt.ylabel('house price in $1000s')\n",
      "plt.xlabel('number of rooms')\n",
      "plt.plot(prediction_space, reg.predict(prediction_space),color='black', linewidth=3)\n",
      "plt.show()\n",
      "#regression.score(X_test,y_test)\n",
      "\n",
      "\n",
      " > Logistic Regression\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "import sklearn.datasets\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "\n",
      "wine=sklearn.datasets.load_wine()\n",
      "reg=LogisticRegression()\n",
      "\n",
      "print(wine.feature_names)\n",
      "X=wine.data\n",
      "y=wine.target\n",
      "X_train, X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=42)\n",
      "\n",
      "reg.fit(X_train,y_train)\n",
      "print(reg.score(X,y))\n",
      "row1=np.array(X_train[:1])\n",
      "print (reg.predict_proba(alcohol))\n",
      "#prediction_space=np.linspace(min(alcohol),max(alcohol)).reshape(-1,1)\n",
      "\n",
      "\n",
      " Linear SVC\n",
      "\n",
      "svm=LinearSVC()\n",
      "svm.fit(X_train,y_train)\n",
      "print(svm.score(X_train,y_train))\n",
      "\n",
      " non linear SVM\n",
      "\n",
      "svm=SVC()\n",
      "svm.fit(X_train,y_train)\n",
      "print(svm.score(X_train,y_train))\n",
      "\n",
      "\n",
      "# Instantiate logistic regression and train\n",
      "lr = LogisticRegression()\n",
      "lr.fit(X, y)\n",
      "\n",
      "# Predict sentiment for a glowing review\n",
      "review1 = \"LOVED IT! This movie was amazing. Top 10 this year.\"\n",
      "review1_features = get_features(review1)\n",
      "print(review1_features)\n",
      "print(\"Review:\", review1)\n",
      "print(\"Probability of positive review:\", lr.predict_proba(review1_features)[0,1])\n",
      "\n",
      "# Predict sentiment for a poor review\n",
      "review2 = \"Total junk! I'll never watch a film by that director again, no matter how good the reviews.\"\n",
      "review2_features = get_features(review2)\n",
      "print(review2_features)\n",
      "print(\"Review:\", review2)\n",
      "print(\"Probability of positive review:\", lr.predict_proba(review2_features)[0,1])\n",
      "\n",
      "\n",
      " classification \n",
      "\n",
      "1. when the y values are categories\n",
      "2. decision boundaries are surfaces separating different predicted classes\n",
      "3. linear classifier learns linear decisions boundaries\n",
      "4. linear separable if it can be perfectly explained by a linear classifier\n",
      "5. multi class classification has three or more categories\n",
      "\n",
      "\n",
      " plotting the linear boundaries\n",
      "\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.svm import SVC, LinearSVC\n",
      "from sklearn.neighbors import KNeighborsClassifier\n",
      "\n",
      "# Define the classifiers\n",
      "classifiers = [LogisticRegression(), LinearSVC(),\n",
      "               SVC(), KNeighborsClassifier()]\n",
      "\n",
      "# Fit the classifiers\n",
      "for c in classifiers:\n",
      "    c.fit(X, y)\n",
      "\n",
      "# Plot the classifiers\n",
      "plot_4_classifiers(X, y, classifiers)\n",
      "plt.show()\n",
      "\n",
      "\n",
      " Logistic regression: Positive or negative to determine what side of the boundary your on\n",
      "\n",
      "lr.coef_\n",
      "lr.intercept_\n",
      "\n",
      "raw model output (negative or positive) predicting either 0 or 1\n",
      "\n",
      "changing the intercept change the y intercept of the boundary\n",
      "changing the coefficients change the slope of the boundary\n",
      "\n",
      " change the y intercept and the slope of the boundary\n",
      "\n",
      "# Set the coefficients\n",
      "model.coef_ = np.array([[-1,1]])\n",
      "model.intercept_ = np.array([-3])\n",
      "\n",
      "# Plot the data and decision boundary\n",
      "plot_classifier(X,y,model)\n",
      "\n",
      "# Print the number of errors\n",
      "num_err = np.sum(y != model.predict(X))\n",
      "print(\"Number of errors:\", num_err)\n",
      "\n",
      " Loss functions\n",
      "\n",
      "LinearRegression used a minimize loss function\n",
      "loss function tells us how poorly the model is doing at predicting on the training data\n",
      "fit is running code to minimize the loss\n",
      "\n",
      "A natural loss for classification problems it the number of errors made\n",
      "0-1 loss  0 for a correct prediction and 1 for and incorrect prediction\n",
      "\n",
      "from scipy.optimize import minimize\n",
      "minimize(np.square,0).x\n",
      "\n",
      "what coefficients make my squared error as small as possible\n",
      "\n",
      "\n",
      "# The squared error, summed over training examples\n",
      "def my_loss(w):\n",
      "    s = 0\n",
      "    for i in range(y.size):\n",
      "        # Get the true and predicted target values for example 'i'\n",
      "        y_i_true = y[i]\n",
      "        y_i_pred = w@X[i]\n",
      "        s = s + (y_i_true - y_i_pred)**2\n",
      "    return s\n",
      "\n",
      "# Returns the w that makes my_loss(w) smallest\n",
      "w_fit = minimize(my_loss, X[0]).x\n",
      "print(w_fit)\n",
      "\n",
      "# Compare with scikit-learn's LinearRegression coefficients\n",
      "lr = LinearRegression(fit_intercept=False).fit(X,y)\n",
      "print(lr.coef_)\n",
      "\n",
      " Loss is the difference between the true and the predicted\n",
      "1. sin products a raw model in either positive or negative halves\n",
      "a. raw model -1 (incorrect) predict +1 (correct)\n",
      "\n",
      "logistic loss diagram\n",
      "1. loss decreases as the corrections are predicted correctly\n",
      "\n",
      "hinge loss in svm\n",
      "\n",
      "# Mathematical functions for logistic and hinge losses\n",
      "def log_loss(raw_model_output):\n",
      "   return np.log(1+np.exp(-raw_model_output))\n",
      "def hinge_loss(raw_model_output):\n",
      "   return np.maximum(0,1-raw_model_output)\n",
      "\n",
      "# Create a grid of values and plot\n",
      "grid = np.linspace(-2,2,1000)\n",
      "plt.plot(grid, log_loss(grid), label='logistic')\n",
      "plt.plot(grid, hinge_loss(grid), label='hinge')\n",
      "plt.legend()\n",
      "plt.show()\n",
      "\n",
      " log loss\n",
      "\n",
      "# The logistic loss, summed over training examples\n",
      "def my_loss(w):\n",
      "    s = 0\n",
      "    for i in range(y.size):\n",
      "        raw_model_output = w@X[i]\n",
      "        s = s + log_loss(raw_model_output * y[i])\n",
      "    return s\n",
      "\n",
      "# Returns the w that makes my_loss(w) smallest\n",
      "w_fit = minimize(my_loss, X[0]).x\n",
      "print(w_fit)\n",
      "\n",
      "# Compare with scikit-learn's LogisticRegression\n",
      "lr = LogisticRegression(fit_intercept=False, C=1000000).fit(X,y)\n",
      "print(lr.coef_)\n",
      "\n",
      " regularization combats overfitting by making the coeffients smaller\n",
      "\n",
      "coefficient value by coefficient index\n",
      "small c means more regularization\n",
      "large c means less regularization\n",
      "\n",
      "lr_weak_reg=LogisticRegression(C=100)\n",
      "lr_strong_reg=LogisticRegression(C=0.01)\n",
      "\n",
      "lr_weak_reg.fit(X_train,y_train)\n",
      "lr_strong_reg.fit(X_train,y_train)\n",
      "\n",
      "lr_weak_reg.score(X_train,y_train)\n",
      "lr_strong_reg.score(X_train,y_train)\n",
      "\n",
      "regularization penalizes large values of the coefficients\n",
      "regularized loss= original loss + large coeffient penalty\n",
      "\n",
      "* more regularization equals lower training accuracy\n",
      "\n",
      "regularizing causes you to fit less reducing overfitting of the data.\n",
      "\n",
      "lasso = linear regression with L1 regularization\n",
      "ridge= linear regression with L2 regularization\n",
      "\n",
      "L1 helps with feature selection\n",
      "\n",
      "  \n",
      "\n",
      "lr_L1 = LogisticRegression(penalty='l1')\n",
      "lr_l2 =LogisticRegression()\n",
      "\n",
      "lr_L1.fit(X_train,y_train)\n",
      "lr_L2.fit(X_train,y_train)\n",
      "\n",
      "plt.plot(lr_L1.coef_.flatten())\n",
      "plt.plot(lr_L2.coef_.flatten())\n",
      "\n",
      " \n",
      "\n",
      "# Train and validaton errors initialized as empty list\n",
      "train_errs = list()\n",
      "valid_errs = list()\n",
      "\n",
      "# Loop over values of C_value\n",
      "for C_value in [0.001, 0.01, 0.1, 1, 10, 100, 1000]:\n",
      "    # Create LogisticRegression object and fit\n",
      "    lr = LogisticRegression(C=C_value)\n",
      "    lr.fit(X_train, y_train)\n",
      "    \n",
      "    # Evaluate error rates and append to lists\n",
      "    train_errs.append( 1.0 - lr.score(X_train, y_train) )\n",
      "    valid_errs.append( 1.0 - lr.score(X_valid, y_valid) )\n",
      "    \n",
      "# Plot results\n",
      "plt.semilogx(C_values, train_errs, C_values, valid_errs)\n",
      "plt.legend((\"train\", \"validation\"))\n",
      "plt.show()\n",
      "\n",
      " Lasso\n",
      "\n",
      "# Specify L1 regularization\n",
      "lr = LogisticRegression(penalty='l1')\n",
      "\n",
      "# Instantiate the GridSearchCV object and run the search\n",
      "searcher = GridSearchCV(lr, {'C':[0.001, 0.01, 0.1, 1, 10]})\n",
      "searcher.fit(X_train, y_train)\n",
      "\n",
      "# Report the best parameters\n",
      "print(\"Best CV params\", searcher.best_params_)\n",
      "\n",
      "# Find the number of nonzero coefficients (selected features)\n",
      "best_lr = searcher.best_estimator_\n",
      "coefs = best_lr.coef_\n",
      "print(\"Total number of features:\", coefs.size)\n",
      "print(\"Number of selected features:\", np.count_nonzero(coefs))\n",
      "\n",
      "\n",
      " coefficents\n",
      "\n",
      "# Get the indices of the sorted cofficients\n",
      "inds_ascending = np.argsort(lr.coef_.flatten()) \n",
      "inds_descending = inds_ascending[::-1]\n",
      "\n",
      "# Print the most positive words\n",
      "print(\"Most positive words: \", end=\"\")\n",
      "for i in range(5):\n",
      "    print(vocab[inds_descending], end=\", \")\n",
      "print(\"\\n\")\n",
      "\n",
      "# Print most negative words\n",
      "print(\"Most negative words: \", end=\"\")\n",
      "for i in range(5):\n",
      "    print(vocab[inds_ascending], end=\", \")\n",
      "print(\"\\n\")\n",
      "\n",
      " Logistic regression as a probablity\n",
      "\n",
      "1. The decision boundary is 0.5  red is >= 0.5 and blue is <0.5\n",
      "\n",
      "when regularization is turned on C=1 then the model coefficients are closer to .5\n",
      "\n",
      "old\n",
      "model coeffients=[[1.55,1.57]] and model intercept[-0.64]\n",
      "\n",
      "new\n",
      "model coeffients=[[0.45,0.64]] and model intercept[-0.26]\n",
      "\n",
      "two features equates to two coefficients\n",
      "the magnitude give us our confidence level\n",
      "the coefficients give the slope of the line\n",
      "\n",
      "The sigmoid function squashes the raw model output to be between 0 and 1 and .5 we are at the boundary\n",
      "\n",
      "\n",
      " \n",
      "# Set the regularization strength\n",
      "model = LogisticRegression(C=1)\n",
      "\n",
      "# Fit and plot\n",
      "model.fit(X,y)\n",
      "plot_classifier(X,y,model,proba=True)\n",
      "\n",
      "# Predict probabilities on training points\n",
      "prob = model.predict_proba(X)\n",
      "print(\"Maximum predicted probability\", np.max(prob))\n",
      "\n",
      " \n",
      "# Set the regularization strength\n",
      "model = LogisticRegression(C=0.1)\n",
      "\n",
      "# Fit and plot\n",
      "model.fit(X,y)\n",
      "plot_classifier(X,y,model,proba=True)\n",
      "\n",
      "# Predict probabilities on training points\n",
      "prob = model.predict_proba(X)\n",
      "print(\"Maximum predicted probability\", np.max(prob))\n",
      "\n",
      " \n",
      "\n",
      "lr = LogisticRegression()\n",
      "lr.fit(X,y)\n",
      "\n",
      "# Get predicted probabilities\n",
      "proba = lr.predict_proba(X)\n",
      "\n",
      "# Sort the example indices by their maximum probability\n",
      "proba_inds = np.argsort(np.max(proba,axis=1))\n",
      "\n",
      "# Show the most confident (least ambiguous) digit\n",
      "show_digit(proba_inds[-1], lr)\n",
      "\n",
      "# Show the least confident (most ambiguous) digit\n",
      "show_digit(proba_inds[0], lr)\n",
      "\n",
      "\n",
      " multi class classifiers\n",
      "\n",
      "lr0.fit(X,y==0)\n",
      "lr1.fit(X,y==1)\n",
      "lr2.fit(X,y==2)\n",
      "\n",
      "lr0.decision_function(X)[0]\n",
      "lr1.decision_function(X)[0]\n",
      "lr2.decision_function(X)[0]\n",
      "\n",
      "or\n",
      "\n",
      "lr.fit(X,y)\n",
      "lr.predict(X)[0]\n",
      "\n",
      "one vs rest\n",
      "\n",
      "Multinomial or softmax\n",
      "\n",
      "\n",
      " one-vs-rest\n",
      "lr_ovr=LogisticRegression()\n",
      "lr_ovr.fit(X,y)\n",
      "lr_ovr.coef_.shape\n",
      "\n",
      " \n",
      "lr_mn=LogisticRegression(\n",
      "multi_class=\"multinomial\",\n",
      "solver=\"lbfgs\")\n",
      "lr_mn.fit(X,y)\n",
      "\n",
      "lrmmn.coef_shape\n",
      "\n",
      " \n",
      "\n",
      "# Fit one-vs-rest logistic regression classifier\n",
      "lr_ovr = LogisticRegression()\n",
      "lr_ovr.fit(X_train, y_train)\n",
      "\n",
      "print(\"OVR training accuracy:\", lr_ovr.score(X_train, y_train))\n",
      "print(\"OVR test accuracy    :\", lr_ovr.score(X_test, y_test))\n",
      "\n",
      "# Fit softmax classifier\n",
      "lr_mn = LogisticRegression(multi_class=\"multinomial\", solver=\"lbfgs\")\n",
      "lr_mn.fit(X_train, y_train)\n",
      "\n",
      "print(\"Softmax training accuracy:\", lr_mn.score(X_train, y_train))\n",
      "print(\"Softmax test accuracy    :\", lr_mn.score(X_test, y_test))\n",
      "\n",
      " \n",
      "# Print training accuracies\n",
      "print(\"Softmax     training accuracy:\", lr_mn.score(X_train, y_train))\n",
      "print(\"One-vs-rest training accuracy:\", lr_ovr.score(X_train, y_train))\n",
      "\n",
      "# Create the binary classifier (class 1 vs. rest)\n",
      "lr_class_1 = LogisticRegression(C=100)\n",
      "lr_class_1.fit(X_train, y_train==1)\n",
      "\n",
      "# Plot the binary classifier (class 1 vs. rest)\n",
      "plot_classifier(X_train, y_train==1, lr_class_1)\n",
      "\n",
      "  Non-linear classification\n",
      "\n",
      "# We'll use SVC instead of LinearSVC from now on\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "# Create/plot the binary classifier (class 1 vs. rest)\n",
      "svm_class_1 = SVC()\n",
      "svm_class_1.fit(X_train, y_train==1)\n",
      "plot_classifier(X_train, y_train==1, svm_class_1)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[31mC:\\Users\\dnishimoto\\python_files\\python_notes\\svm (support vector machine).txt\n",
      "\u001b[30m\n",
      "C:\\Users\\dnishimoto\\python_files\\python_notes\\svm (support vector machine).txt\n",
      " Classifications using linear SVC\n",
      "\n",
      "from sklearn.svm import LinearSVC\n",
      "\n",
      "wine=sklearn.datasets.load_wine()\n",
      "\n",
      "svm= LinearSVC()\n",
      "svm.fit(wine.data, wine.target)\n",
      "svm.score(wine.date,wine.target)\n",
      "\n",
      "\n",
      "\n",
      "svm use the hinge less and l2 regularization\n",
      "\n",
      "Support vectors: a training example not in the flat part of the loss diagram\n",
      "\n",
      "support vectors include incorrectly classified examples or correctly classified examples that are close to the boundary.\n",
      "\n",
      "support vectors contribute to the fit\n",
      "\n",
      "all data points matter to the fit\n",
      "\n",
      "the length from the support vector to the boundary line is called the margin\n",
      "\n",
      "all incorrectly classified vectors are support vectors\n",
      "\n",
      "Support vectors are defined as training examples that influence the decision boundary.\n",
      "\n",
      "\n",
      " \n",
      "# Train a linear SVM\n",
      "svm = SVC(kernel=\"linear\")\n",
      "svm.fit(X,y)\n",
      "plot_classifier(X, y, svm, lims=(11,15,0,6))\n",
      "\n",
      "# Make a new data set keeping only the support vectors\n",
      "print(\"Number of original examples\", len(X))\n",
      "print(\"Number of support vectors\", len(svm.support_))\n",
      "X_small = X[svm.support_]\n",
      "y_small = y[svm.support_]\n",
      "\n",
      "# Train a new SVM using only the support vectors\n",
      "svm_small = SVC(kernel=\"linear\")\n",
      "svm_small.fit(X_small,y_small)\n",
      "plot_classifier(X_small, y_small, svm_small, lims=(11,15,0,6))\n",
      "\n",
      "\n",
      " Kernel SVMs rbf kernel\n",
      "\n",
      "from sklearn.svm import SVC\n",
      "\n",
      "svm=SVC(gamma=1)  #gamma controls the boundary smoothness\n",
      "svm=SVC(gamma=0.01)\n",
      "\n",
      " >\n",
      "\n",
      "# Instantiate an RBF SVM\n",
      "svm = SVC()\n",
      "\n",
      "# Instantiate the GridSearchCV object and run the search\n",
      "parameters = {'C':[0.1, 1, 10], 'gamma':[0.00001, 0.0001, 0.001, 0.01, 0.1]}\n",
      "searcher = GridSearchCV(svm, parameters)\n",
      "searcher.fit(X_train, y_train)\n",
      "\n",
      "# Report the best parameters and the corresponding score\n",
      "print(\"Best CV params\", searcher.best_params_)\n",
      "print(\"Best CV accuracy\", searcher.best_score_)\n",
      "\n",
      "# Report the test accuracy using these best parameters\n",
      "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n",
      "\n",
      " Comparing Logistic Regression and SVM\n",
      "\n",
      "logistic regression and support vector machines are a linear classifiers, both can be used with kernels, both can be extended to multiclass\n",
      "in logistic regression all data affect the fit\n",
      "in svm only support vectors affect fit\n",
      "logistic regression can use L1 and L2 penalty\n",
      "\n",
      "logistic regression\n",
      "1. linear_model.LogisticRegression\n",
      "2. C hyper parameter (inverse regularization strength)\n",
      "3. penalty (type of regularization)\n",
      "4. multi-class using multinomial or softmax and solver =lbfgs\n",
      "\n",
      "SVM\n",
      "1. svm.LinearSVC and svm.SVC #Kernel SVM\n",
      "2. C hyper parameter (inverse regularization strength)\n",
      "3. kernel (type of kernel)\n",
      "4. gamma (inverse RBF smoothness)\n",
      "\n",
      "SGDClassifier: stocastic gradient descent\n",
      "\n",
      "logreg= SGDClassifier(loss='log')\n",
      "linsvm= SGDClassifier(loss='hinge')\n",
      "\n",
      "regularization is called alpha and is like 1/c\n",
      "a big alpha means more regularization\n",
      "\n",
      " >\n",
      "\n",
      "# We set random_state=0 for reproducibility \n",
      "linear_classifier = SGDClassifier(random_state=0)\n",
      "\n",
      "# Instantiate the GridSearchCV object and run the search\n",
      "parameters = {'alpha':[0.00001, 0.0001, 0.001, 0.01, 0.1, 1], \n",
      "             'loss':['hinge','log'], 'penalty':['l1','l2']}\n",
      "searcher = GridSearchCV(linear_classifier, parameters, cv=10)\n",
      "searcher.fit(X_train, y_train)\n",
      "\n",
      "# Report the best parameters and the corresponding score\n",
      "print(\"Best CV params\", searcher.best_params_)\n",
      "print(\"Best CV accuracy\", searcher.best_score_)\n",
      "print(\"Test accuracy of best grid search hypers:\", searcher.score(X_test, y_test))\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "import subprocess\n",
    "from colorama import Fore, Back, Style\n",
    "import codecs\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "#,'apple', 'orange', 'banana'\n",
    "search=['gridsearchcv']\n",
    "search=list(map(lambda x: x.upper(),search))\n",
    "path=os.path.expanduser('~\\python_files\\\\python_notes')\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        filename=path + \"\\\\\" +filename\n",
    "        #if filename==r\"C:\\Users\\dnishimoto.BOISE\\python\\decision tree machine learning.txt\":\n",
    "        with open(filename) as fin:\n",
    "            text=(fin.read())\n",
    "            text=text.replace('>>',' ')\n",
    "                #print(text)\n",
    "            mywords=text.split(' ')\n",
    "            mywords=map(lambda x: x.upper(),mywords)\n",
    "            mywords=[x.replace('\\n','') for x in mywords if x]\n",
    "            #print(mywords)\n",
    "            if any([x in search  for x in mywords]):\n",
    "                print(Fore.RED+filename)\n",
    "                print(Fore.BLACK)\n",
    "                print(\"{}\\n{}\".format(filename,text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pattern=\"(\\s{1}airlines.csv\\s{1})\"\n",
    "pattern=\"(gridsearchcv)\"\n",
    "path= 'C:\\\\Users\\\\dnishimoto\\\\python_files'  \n",
    "for filename in [item for item in os.listdir(path) if item.endswith(\".txt\")  ]:\n",
    "    if os.access(path + \"\\\\\" + filename, os.R_OK):\n",
    "        with open(path + \"\\\\\" + filename,\"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if re.search(pattern,line):\n",
    "                    print(filename)\n",
    "                    print(\"\\t{}\".format(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readJupyterNotesFnc(path,phrase):\n",
    "    pySource=\"\"\n",
    "    count=0\n",
    "    path=os.path.expanduser(path)\n",
    "    for filename in [item for item in os.listdir(path) if item.endswith(\".ipynb\")  ]:\n",
    "        if os.access(path + \"\\\\\" + filename, os.R_OK):\n",
    "            with open(path + \"\\\\\" + filename,\"r\", encoding=\"utf8\") as f:\n",
    "                source = f.read()\n",
    "                y = json.loads(source)\n",
    "                #print(y)\n",
    "                doc=[]\n",
    "                found=False\n",
    "                for x in y['cells']:\n",
    "                    for line in x['source']:\n",
    "                    #print(line)\n",
    "                        if phrase in line:\n",
    "                            doc.append(line)\n",
    "                            found=True\n",
    "                if found==True:\n",
    "                    print(\"{}\\n\".format(filename))\n",
    "                    for item in doc:\n",
    "                        print(\"\\t{}\".format(item))\n",
    "                count+=1\n",
    "\n",
    "path= 'C:\\\\Users\\\\dnishimoto\\\\python_files\\\\python-deep-learning-master'               \n",
    "readJupyterNotesFnc(path,\"gridsearchcv\")                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
