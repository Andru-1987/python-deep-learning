Zach deane-Mayer


from keras.layers import Input

input_tensor= Input(shape=(1,))

print(input_tensor)

#outputs are usually a single dense layer
output_layer=Dense(1)
print(output_layer)

output_tensor=output_layer(input_tensor)

>>

# Load layers
from keras.layers import Input, Dense

# Input layer (from previous exercise)
input_tensor = Input(shape=(1,))

# Create a dense layer
output_layer = Dense(1)

# Connect the dense layer to the input_tensor
output_tensor = output_layer(input_tensor)

or

output_tensor = Dense(1)(input_tensor)

>>

# Load layers
from keras.layers import Input, Dense
import matplotlib.image as img
from scipy.cluster.vq import kmeans, vq, whiten
import seaborn as sns, pandas as pd
from matplotlib import pyplot as plt
from PIL import Image
from keras.models import Sequential
import tensorflow as tf
from keras.models import Model
from keras.utils import plot_model

model= Model(input_tensor, output_tensor)

model.compile(optimizer='adam',loss='mae')

#mae = mean absolute error
#mse = mean squared error

model.summary

y=mx+b

#m is the weight of the dense layer
#b is the bias

>>
input_tensor= Input(shape(1,))
output_layer= Dense(1, name="Predicted-Score-Diff")
output_tensor= output_layer(input_tensor)
model= Model(input_tensor, output_tensor)

model.compile(optimizer='adam',loss='mae')

plot_model(model, to_file='model.png')

img=plt.imread('model.png')
plt.imshow(img)
plt.show()

>> fit the data to the model

games_tourney=pd.read_csv('datasets/games_tourney.csv')

games_tourney.head()


# a negative seed difference is indictive of a positive score difference

model.fit(games['seed_diff'],
games[score_diff'],
batch_size=64,
validation_split=.20,
verbose=True)

#batch_size - how many rows to train on for stocastic descent
#validation_split - return metrics on accuracy
#verbose - keras creates a log on training

model.evaluate(games_test['seed_diff'],
games_test['score_diff'])


>>>

# Now fit the model
model.fit(games_tourney_train['seed_diff'], games_tourney_train['score_diff'],
          epochs=128,
          batch_size=64,
          validation_split=0.10,
          verbose=True)


# Load the X variable from the test data
X_test = games_tourney_test['seed_diff']

# Load the y variable from the test data
y_test = games_tourney_test['score_diff']

# Evaluate the model on the test data
print(model.evaluate(X_test, y_test, verbose=False))

>>>Category embeddings
1) input = integers
2) output= floats
3) increased dimensionality : output layer flattens back to 2d

embedding layer

from keras.layers import Flatten

input_tensor= Input(shape(1,))
n_teams=10887  # represents each teams unique id, covers 30 years of data.

embed_layer=Embedding(input_dim=n_teams,
input_length=1
output_dim=1,
name='Team-Strength-Lookup')

embed_tensor=embed_layer(input_tensor)

#embedding increase the dimensionality of your data
#embedding adds a third dimension

flatten_tensor= Flatten()(embed_tensor)

#flattening can reduce multiple dimensions back to 2 dimensions
#useful for time based data, text data and images

model=Model(input_tensor, flatten_tensor)

>>  Example of embedding categories

# Imports
from keras.layers import Embedding
from numpy import unique

# Count the unique number of teams
n_teams = unique(games_season['team_1']).shape[0]

book = Input(name = 'book', shape = [1])
link = Input(name = 'link', shape = [1])

# Embedding the book (shape will be (None, 1, 50))
book_embedding = Embedding(name = 'book_embedding',
                           input_dim = len(book_index),
                           output_dim = embedding_size)(book)

# Embedding the link (shape will be (None, 1, 50))
link_embedding = Embedding(name = 'link_embedding',
                           input_dim = len(link_index),
                           output_dim = embedding_size)(link)


# Merge the layers with a dot product along the second axis (shape will be (None, 1, 1))

merged = Dot(name = 'dot_product', normalize = True, axes = 2)([book_embedding, link_embedding])

# Reshape to be a single number (shape will be (None, 1))
merged = Reshape(target_shape = [1])(merged)

 Output neuron
out = Dense(1, activation = 'sigmoid')(merged)
model = Model(inputs = [book, link], outputs = out)

# Minimize binary cross entropy
model.compile(optimizer = 'Adam', loss = 'binary_crossentropy', metrics = ['accuracy'])


>>> Shared Layers (two inputs sharing the same embedding layer)

# Imports
from keras.layers import Input, Embedding, Flatten
from keras.models import Model

# Create an input layer for the team ID
teamid_in = Input(shape=(1,))

# Create an embedding layer
team_lookup = Embedding(input_dim=n_teams,
                        output_dim=1,
                        input_length=1,
                        name='Team-Strength')

# Lookup the input in the team strength embedding layer
strength_lookup = team_lookup(teamid_in)

# Flatten the output
strength_lookup_flat = Flatten()(strength_lookup)

# Combine the operations into a single, re-usable model
team_strength_model = Model(teamid_in, strength_lookup_flat, name='Team-Strength-Model')

input layers -> shared layer -> output layers

input_tensor_1 = Input((1,), Name='Team-1-In')
input_tensor_2 = Input((1,), Name='Team-2-In')

shared_layer=Dense(1)
output_tensor_1=shared_layer(input_tensor_1)
output_tensor_2=shared_layer(input_tensor_2)

or

output_tensor_1=model(input_tensor_1)
oupput_tensor_2=model(input_tensor_2)

# Lookup team 1 in the team strength model
team_1_strength = team_strength_model(team_in_1)

# Lookup team 2 in the team strength model
team_2_strength = team_strength_model(team_in_2)

>>merge layers
1. add, subtract, multiply, concatenate (append)

in_tensor_1=Input((1,))
in_tensor_2=Input((1,))
out_tensor=Add()([in_tensor_1,in_tensor_2])

from keras.models import Model
model=Model([in_tensor_1,in_tensor_2],out_tensor)

model.compile(optimizer='adam', loss='mean_absolute_error')

>>

# Import the Subtract layer from keras
from keras.layers import Subtract

# Create a subtract layer using the inputs from the previous exercise
# Imports
from keras.layers import Subtract
from keras.models import Model

# Subtraction layer from previous exercise
score_diff = Subtract()([team_1_strength, team_2_strength])

# Create the model
model = Model([team_in_1, team_in_2], score_diff)

# Compile the model
model.compile(optimizer='adam', loss='mean_absolute_error')

>>fitting with multiple inputs

model.fit([data_1,data_2], target)

>>predicting with multiple inputs on ADD

model.predict([np.array([[1]]),np.array([[2]])])

#output
array.array([[3]], dtype=float32)

model.predict([np.array([[42]),np.array([[119]])])

#output
array.array([[161]], dtype=float32)

>>evaluating with multiple inputs

model.evaluate([np.array([[-1]]),np.array([[-2]])], nparray([[-3]]))

output is 0


>>

input_1 = games_season['team_1']

# Get the team_2 column from the regular season data
input_2 = games_season['team_2']

# Fit the model to input 1 and 2, using score diff as a target
model.fit([input_1, input_2],
          games_season['score_diff'],
          epochs=1,
          batch_size=2048,
          validation_split=0.10,
          verbose=True)

#print(games_tourney.head())
# Get team_1 from the tournament data
input_1 = games_tourney['team_1']

# Get team_2 from the tournament data
input_2 = games_tourney['team_2']

# Evaluate the model using these inputs
print(model.evaluate([input_1,input_2], games_tourney['score_diff'], verbose=False))

>>>

from keras.layers import Input, Concatenate, Dense

in_tensor_1=Input(shape=(1,))
in_tensor_2=Input(shape=(1,))
in_tensor_3=Input(shape=(1,))
out_tensor=Concatenate()([in_tensor_1,in_tensor_2,in_tensor_3])
output_tensor=Dense(1)(out_tensor)

>>

shared_layer = Dense(1)
shared_tensor_1=shared_layer(in_tensor_1)
shared_tensor_2=shared_layer(in_tensor_1)
out_tensor=Concatenate()([shared_tensor_1,shared_tensor_2,in_tensor_3])
out_tensor=Dense(1)(out_tensor)

model =Model([in_tensor_1, in_tensor_2, in_tensor_3], out_tensor)
model.compile(loss='mae', optimizer='adam')

model.fit([[train['col1'], train['col2'],train['col3']],
train_data['target'])

model.evaluate([[test['col1'],test['col2'],test['col3']],
test['target'])



https://praison.com/category/data-science/keras/

>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>Final Model>>>>>>>>>>>>>>>>>>>>>>
#Define Model

n_teams = unique(games_season['team_1']).shape[0]

# Create an embedding layer
team_lookup = Embedding(input_dim=n_teams,
                        output_dim=1,
                        input_length=1,
                        name='Team-Strength')

# Lookup the input in the team strength embedding layer
strength_lookup = team_lookup(teamid_in)

# Flatten the output
strength_lookup_flat = Flatten()(strength_lookup)

# Combine the operations into a single, re-usable model
team_strength_model = Model(teamid_in, strength_lookup_flat, name='Team-Strength-Model')


# Create an Input for each team
#Defining two inputs
team_in_1 = Input(shape=(1,), name='Team-1-In')
team_in_2 = Input(shape=(1,), name='Team-2-In')

# Create an input for home vs away
home_in = Input(shape=(1,), name='Home-In')

# Lookup the team inputs in the team strength model
team_1_strength = team_strength_model(team_in_1)
team_2_strength = team_strength_model(team_in_2)

from keras.layers import Subtract

#score_diff= Subtract() ([team_1_strength, team_2_strength])


# Combine the team strengths with the home input using a Concatenate layer, then add a Dense layer
out = Concatenate()([team_1_strength, team_2_strength, home_in])
out = Dense(1)(out)

# Import the model class
from keras.models import Model

# Make a Model
model = Model([team_in_1, team_in_2, home_in], out)

# Compile the model
model.compile(optimizer="adam", loss="mean_absolute_error")

model.fit([games_season['team_1'], games_season['team_2'], games_season['home']],
          games_season['score_diff'],
          epochs=1,
          verbose=True,
          validation_split=.10,
          batch_size=2048)

# Evaluate the model on the games_tourney dataset
print(model.evaluate([games_tourney['team_1'], games_tourney['team_2'], games_tourney['home']],
               games_tourney['score_diff'], verbose=False))


# Imports
import matplotlib.pyplot as plt
from keras.utils import plot_model

# Plot the model
plot_model(model, to_file='model.png')

# Display the image
data = plt.imread('model.png')
plt.imshow(data)
plt.show()

games_tourney['pred'] = model.predict([games_tourney['team_1'],games_tourney['team_2'],games_tourney['home']])


>> using the train_test_split

X_train, X_test, y_train, y_test = train_test_split(games_tourney_train['seed_diff'],

 Now fit the model
model.fit(X_train, y_train,
          epochs=1,
          batch_size=128,
          validation_split=.10,
          verbose=True)

>>>Define multiple outputs

# Define the input
input_tensor = Input((2,))

# Define the output
output_tensor = Dense(2)(input_tensor)

# Create a model
model = Model(input_tensor, output_tensor)

# Compile the model
model.compile(optimizer='adam', loss='mean_absolute_error')

# Fit the model
model.fit(games_tourney_train[['seed_diff', 'pred']],
  		  games_tourney_train[['score_1', 'score_2']],
  		  verbose=False,
  		  epochs=1000,
  		  batch_size=64)

in_data_1=games_tourney['team_1']
in_data_2=games_tourney['team_2']
in_data_3=games_tourney['home']
pred= model.predict([in_data_1,in_data_2,in_data_3])
games_tourney['pred']=pred

>>
1. Shared Models work the same as shared layers


>>Model Stacking with the goal to build accurate models
tourney seed behaves like a team_strength

The games_tourney['home','seed_diff','pred']]
becomes and input layer of the regular session with pure numeric data (3 inputs)

from keras.layers import Input, Dense
in_tensor=Input(shape=(3,))
out_tensor=Dense(1)(in_tensor)

from keras.models import Model
model=Model(in_tensor, out_tensor)
model.compile(optimizer='adam', loss='mae')
train_X=train_data[['home,'seed_diff','pred']]
train_y=train_data['score_diff']
model.fit(train_X,train_y, epochs=10, validation_split=0.10)

test_X=test_data[['home,'seed_diff','pred']]
test_y=test_data['score_diff']
model.evaluate(test_X,test_y)

>>>

games_tourney['pred'] = model.predict([games_tourney['team_1'],
                                             games_tourney['team_2'],
                                             games_tourney['home']])

# Create an input layer with 3 columns
input_tensor = Input(shape=(3,))

# Pass it to a Dense layer with 1 unit
output_tensor = Dense(1)(input_tensor)

# Create a model
model = Model(input_tensor, output_tensor)

# Compile the model
model.compile(optimizer="adam", loss="mean_absolute_error")

model.fit(games_tourney_train[['home', 'seed_diff', 'pred']],
          games_tourney_train['score_diff'],
          epochs=1,
         verbose=True)

print(model.evaluate(games_tourney_test[['home', 'seed_diff', 'prediction']],
               games_tourney_test['score_diff'], verbose=False))

>>Two output model
1. classifier and regressor

from keras.layers import Input, Concatenate, Dense

input_tensor=Input(shape=(1,))
output_tensor=Dense(2) (input_tensor)
model=Model(input_tensor, output_tensor)
model.compile(optimizer='adam', loss='mean_absolute_error')

X=games_tourney_train[['seed_diff']]
y=games_tourney_train[['score_1','score_2']]
model.fit(X,y,epochs=500)

model.get_weights()

X=games_tourney_test[['seed_diff']]
y=games_tourney_test[['score_1','score_2']]
model.evaluate(X,y)


>>>
input_tensor=Input(shape=(2,))
output_tensor=Dense(2) (input_tensor)
model=Model(input_tensor, output_tensor)
model.compile(optimizer='adam', loss='mean_absolute_error')

# Fit the model
model.fit(games_tourney_train[['seed_diff', 'pred']],
  		  games_tourney_train[['score_1', 'score_2']],
  		  verbose=True,
  		 batch_size=16384,
  		  epochs=100)

# Print the model's weights
print(model.get_weights())

# Print the column means of the training data
print(games_tourney_train.mean())


print(model.evaluate(games_tourney_test[['seed_diff', 'pred']],
               games_tourney_test[['score_1', 'score_2']], verbose=False))

>>single model for classification and regression outputs

from keras.layers import Input, Dense

input_tensor=Input(shape=(1,))
output_tensor_regression=Dense(1)(input_tensor)

output_tensor_class=Dense(1, activation='sigmoid')(output_tensor_regression)

model= Model(input_tensor,[ouput_tensor_regression, ouput_tensor_class])
model.compile(loss=['mean_absolute_error','binary_crossentropy'],optimizer='adam')

X= game_tourney_train[['seed_diff]]
y_reg =game_tourney_train[['score_diff]]
y_class= game_tourney_train[['won']]

model.fit(X,[y_reg,y_class], epochs=100)

model.get_weights()

from scipy.special import expit as sigmoid
model.get_weights()

print(sigmoid(1 *0.1387069 + 000734114))

Dense 1 Weight= 1.2371823
Dense 2 Weight= -0.05451894
Dense 3 Weight= 0.13870609 (last layer)
Bias Weight=  0.00734114

1 times the weight of the final layer in the model
sigmoid(1*0.13870609+0.00734114)

.53

split the model into two targets: regression and classification targets

X= game_tourney_test[['seed_diff]]
y_reg =game_tourney_test[['score_diff]]
y_class= game_tourney_test[['won']]
model.evaluate(X,[y_reg,y_class])

[9.86,9.2,0.58]

a. the first element is the loss function of the model=sum of all the output losses
b. the second element is the loss function of the regression part of the model
c. the third element is the loss function of the classification part of the model



>>how to split the data into training and test

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(games_tourney_train['seed_diff'], games_tourney_train['score_diff'])


>>>

# Create an input layer with 2 columns
input_tensor=Input(shape=(2,))

# Create the first output
output_tensor_1 = Dense(1, activation='linear', use_bias=False)(input_tensor)

# Create the second output (use the first output as input here)
output_tensor_2 = Dense(1, activation='sigmoid', use_bias=False)(output_tensor_1)

# Create a model with 2 outputs
model = Model(input_tensor, [output_tensor_1, output_tensor_2])

# Import the Adam optimizer
from keras.layers import Input, Dense
from keras.optimizers import Adam

# Compile the model with 2 losses and the Adam optimzer with a higher learning rate
model.compile(loss=['mean_absolute_error', 'binary_crossentropy'], optimizer=Adam(0.01))

# Fit the model to the tournament training data, with 2 inputs and 2 outputs
model.fit(games_tourney_train[['seed_diff', 'pred']],
          [games_tourney_train[['score_diff']], games_tourney_train[['won']]],
          epochs=10,
          verbose=True,
          batch_size=16384)

# Import the sigmoid function from scipy
from scipy.special import expit as sigmoid

# Weight from the model
weight = 0.14

# Print the approximate win probability predicted close game
print(sigmoid(1 * weight))

# Print the approximate win probability predicted blowout game
print(sigmoid(10 * weight))

print(model.evaluate(games_tourney_test[['seed_diff', 'pred']],
               [games_tourney_test[['score_diff']], games_tourney_test[['won']]], verbose=False))








































