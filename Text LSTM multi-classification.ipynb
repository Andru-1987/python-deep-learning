{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense,SpatialDropout1D\n",
    "from keras.layers import LSTM, Embedding\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv('https://raw.githubusercontent.com/kushalchauhan98/bcn-cnn-text-classification/master/hm_train.csv')\n",
    "#df.to_csv('hm_train.csv')\n",
    "df=pd.read_csv('hm_train.csv')\n",
    "#https://towardsdatascience.com/multi-class-text-classification-with-lstm-1590bee1bd17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (43354, 7)\n",
      "       achievement  affection  bonding  enjoy_the_moment  exercise  leisure  \\\n",
      "0                0          1        0                 0         0        0   \n",
      "1                0          1        0                 0         0        0   \n",
      "2                0          0        0                 0         1        0   \n",
      "4                0          1        0                 0         0        0   \n",
      "5                0          0        0                 0         0        1   \n",
      "...            ...        ...      ...               ...       ...      ...   \n",
      "60315            0          0        0                 0         0        1   \n",
      "60316            0          0        1                 0         0        0   \n",
      "60317            0          0        1                 0         0        0   \n",
      "60318            1          0        0                 0         0        0   \n",
      "60319            1          0        0                 0         0        0   \n",
      "\n",
      "       nature  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "4           0  \n",
      "5           0  \n",
      "...       ...  \n",
      "60315       0  \n",
      "60316       0  \n",
      "60317       0  \n",
      "60318       0  \n",
      "60319       0  \n",
      "\n",
      "[43354 rows x 7 columns]\n",
      "['achievement', 'affection', 'bonding', 'enjoy_the_moment', 'exercise', 'leisure', 'nature']\n"
     ]
    }
   ],
   "source": [
    "filter=df['cleaned_hm'].str.len()<=100\n",
    "df=df[filter]\n",
    "#rint(df)\n",
    "#y=df['predicted_category']\n",
    "\n",
    "y = pd.get_dummies(df['predicted_category']).values\n",
    "print('Shape of label tensor:', y.shape)\n",
    "\n",
    "LABELS=sorted(df['predicted_category'].unique())\n",
    "#LABELS=['achievement','affection','bonding','enjoy_the_moment','exercise','leisure','nature']\n",
    "\n",
    "print(pd.get_dummies(df['predicted_category']))\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (43354, 250)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each complaint.\n",
    "MAX_SEQUENCE_LENGTH = 250\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def filter_stop_words(train_sentences, stop_words):\n",
    "    for i, sentence in enumerate(train_sentences):\n",
    "        new_sent = [word for word in sentence.split() if word not in stop_words]\n",
    "        train_sentences[i] = ' '.join(new_sent)\n",
    "    return train_sentences\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "sentences = filter_stop_words(df['cleaned_hm'].values, stop_words)\n",
    "\n",
    "#word_tokens = word_tokenize(example_sent)\n",
    "#filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
    "#filtered_sentence = []\n",
    "#for w in word_tokens:\n",
    "#    if w not in stop_words:\n",
    "#        filtered_sentence.append(w)\n",
    "        \n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "X = tokenizer.texts_to_sequences(sentences)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.10, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(len(LABELS), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 35116 samples, validate on 3902 samples\n",
      "Epoch 1/5\n",
      "   64/35116 [..............................] - ETA: 8:58 - loss: 1.9389 - accuracy: 0.2500"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "history = model.fit(X_train, Y_train, epochs=epochs, batch_size=batch_size,validation_split=0.1,callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accr = model.evaluate(X_test,Y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def GetCategory(pred,LABELS):\n",
    "#    returnVal=[]\n",
    "#    curr_index=0\n",
    "#    curr_val=0\n",
    "#    for item in pred:\n",
    "#        val=max(item)\n",
    "#        index=list(item).index(val)\n",
    "#        #print(val,LABELS[index])\n",
    "#        if val>curr_val:\n",
    "#            curr_index=index\n",
    "#            curr_val=val\n",
    "            \n",
    "       \n",
    "for key,item in df.iterrows():\n",
    "    data=[]\n",
    "    data.append(item['cleaned_hm'])\n",
    "    sentences = filter_stop_words(data, stop_words)\n",
    "    #seq = tokenizer.texts_to_sequences(data)\n",
    "    seq = tokenizer.texts_to_sequences(sentences)\n",
    "    padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    pred = model.predict(padded)\n",
    "    print(pred)\n",
    "    category=LABELS[np.argmax(pred)]\n",
    "    #category=GetCategory(pred,LABELS)\n",
    "    print(data, \"[predicted category]\", category, \"[actual category]\",item['predicted_category'])\n",
    "    #break\n",
    "    #print(pred, LABELS[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
